{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, UZH 2018, Group Project\n",
    "### Group 2: Barbara Capl, Mathias LÃ¼thi, Pamela Matias, Stefanie Rentsch\n",
    "##       \n",
    "##    \n",
    "# 4. Collection of all Pipes\n",
    "\n",
    "###        \n",
    "In this section we use the data we prepared in chapter 1.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide unnecessary warnings (\"depreciation\" of packages etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "## 4.1. Pipe 1 (P1)\n",
    "\n",
    "#### Feature Selection: In-Pipe with RandomForestClassifier or PCA\n",
    "#### Scaling : In-Pipe with StandardScaler\n",
    "#### Classification: SVM\n",
    "#### Additional Classification: RandomForestClassifier, LogisticRegression\n",
    "###      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.0.  (i) DATA SETTINGS (P1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Dataset Version you want\n",
    "##### Whole Feature Matrices (Features not pre-selected)\n",
    "VERSION = 1; Feature Matrix with only ratios                                  \n",
    "VERSION = 2;  Feature Matrix with ratios + saisonality + other market data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chose which dataset version you want the selection of features and the prediction to be based on \n",
    "VERSION = 1\n",
    "\"\"\"\n",
    "INSERT NUMBER 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "# Defining sel_state variable for easier printing out    \n",
    "if VERSION == 1: sel_version = 'Whole original Dataset with only the Ratios as predicive Features.'\n",
    "elif VERSION == 2: sel_version = 'Whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features.'\n",
    "else: raise ValueError('VERSION must be either 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 1: Whole original Dataset with only the Ratios as predicive Features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print status\n",
    "briefing_data='SUMMARY DATA SETTINGS:'+'\\n'+'Selected Version ' + str(VERSION) + ': ' + str(sel_version)+'\\n'\n",
    "print(briefing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary Data and impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "if VERSION == 1: \n",
    "# features not pre-selected, only ratios\n",
    "    X = pd.read_csv('Data/generated_datasets/features_ratios_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "elif VERSION == 2: \n",
    "# features not pre-selected, ratios + seasonality + market data\n",
    "    X = pd.read_csv('Data/generated_datasets/features_additional_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "else: raise ValueError('VERSION value must be either 1 or 2')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split, into 20% test size and 80% train size because it is a relatively small dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Use a median fill for train\n",
    "imp = Imputer(missing_values=np.nan, strategy = 'median' , axis=0)\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_train))\n",
    "imputed_dataset.columns = X_train.columns\n",
    "imputed_dataset.index = X_train.index\n",
    "X_train = imputed_dataset\n",
    "\n",
    "# Use a median fill for the test set\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_test))\n",
    "imputed_dataset.columns = X_test.columns\n",
    "imputed_dataset.index = X_test.index\n",
    "X_test = imputed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.0. (ii) PIPING SETTINGS (P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: rbf.\n",
      "Selected In-Pipe Feature Selecter: <class 'sklearn.decomposition.pca.PCA'>.\n",
      "Additional Classifier: <class 'sklearn.linear_model.logistic.LogisticRegression'>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Kernel\n",
    "set_kernel = 'rbf'\n",
    "\"\"\"\n",
    "Select 'poly', 'linear' or 'rbf'\n",
    "\"\"\"\n",
    "\n",
    "# Choose In-Pipe Feature Selection Method\n",
    "set_feature_selecter = PCA\n",
    "\"\"\"\n",
    "Select RandomForestClassifier or PCA\n",
    "\"\"\"\n",
    "\n",
    "# Choose Classifier\n",
    "set_classifier = LogisticRegression\n",
    "\"\"\"\n",
    "Select LogisticRegression or RandomForestClassifier\n",
    "\"\"\"\n",
    "\n",
    "# Print result of settings\n",
    "briefing_pipe='SUMMARY PIPE SETTINGS:'+'\\n'+'Selected kernel: '+str(set_kernel)+'.'+'\\n'+'Selected In-Pipe Feature Selecter: '+str(feature_selecter)+'.'+'\\n'+'Additional Classifier: '+str(classifier)+'.'+'\\n'\n",
    "print(briefing_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Piping (P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set conditions so according to choices under \"settings\", the methods are going to be used automatically\n",
    "if feature_selecter == PCA: \n",
    "    feat_sel_function = PCA(n_components=10)\n",
    "elif feature_selecter == RandomForestClassifier: \n",
    "    feat_sel_function = SelectFromModel(RandomForestClassifier(),threshold='median')\n",
    "else: raise ValueError('feature_selecter must be either PCA or RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 1: Whole original Dataset with only the Ratios as predicive Features.\n",
      "\n",
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: rbf.\n",
      "Selected In-Pipe Feature Selecter: <class 'sklearn.decomposition.pca.PCA'>.\n",
      "Additional Classifier: <class 'sklearn.linear_model.logistic.LogisticRegression'>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler, Feature Selecter and SVC estimator\n",
    "# Standardscaler standardizes the input variables\n",
    "pipe1 = Pipeline([('scaler', StandardScaler()), \n",
    "                  (str(set_feature_selecter), feat_sel_function), \n",
    "                  ('classification', SVC(kernel=set_kernel, random_state=0))])\n",
    "pipe1.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "# print settings\n",
    "print(briefing_data+'\\n'+briefing_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 19, 1, 77895, tzinfo=tzutc()), 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd38f56fd560d4b2b8426ad27e33d2b48']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 19, 1, 77895, tzinfo=tzutc()), 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd38f56fd560d4b2b8426ad27e33d2b48'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 19, 1, 77895, tzinfo=tzutc()), 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-51-5e03ce7b7391>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fb1a0268ba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fb16f31cdb0, file \"<ipython-input-51-5e03ce7b7391>\", line 16>\n        result = <ExecutionResult object at 7fb1a0268ba8, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fb16f31cdb0, file \"<ipython-input-51-5e03ce7b7391>\", line 16>, result=<ExecutionResult object at 7fb1a0268ba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fb16f31cdb0, file \"<ipython-input-51-5e03ce7b7391>\", line 16>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/andy/barbara/github_ml_uzh/Machine_Learning_in_Finance_Group_Project/<ipython-input-51-5e03ce7b7391> in <module>()\n     11 param_grid_1 = {'svm_poly__C': [100],\n     12               'svm_poly__degree': [1, 2, 3]}\n     13 \n     14 # Run grid search\n     15 grid1 = GridSearchCV(pipe1, param_grid=param_grid_1, cv=5, n_jobs=-1)\n---> 16 grid1.fit(X_train, y_train)\n     17 \n     18 estimator.get_params().keys()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns]\n        y =       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Apr 13 00:19:01 2018\nPID: 3525                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0mTraceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/andy/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Apr 13 00:19:01 2018\nPID: 3525                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Apr 13 00:19:01 2018\nPID: 3525                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5e03ce7b7391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Run grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgrid1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 19, 1, 77895, tzinfo=tzutc()), 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd38f56fd560d4b2b8426ad27e33d2b48']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 19, 1, 77895, tzinfo=tzutc()), 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd38f56fd560d4b2b8426ad27e33d2b48'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 19, 1, 77895, tzinfo=tzutc()), 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'a55c590f2ce0493e8f74395c6712e257', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# Define parameter grid\\nparam_grid1 = [{'scaler'...(X_train, y_train)\\n\\nestimator.get_params().keys()\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-51-5e03ce7b7391>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fb1a0268ba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fb16f31cdb0, file \"<ipython-input-51-5e03ce7b7391>\", line 16>\n        result = <ExecutionResult object at 7fb1a0268ba8, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fb16f31cdb0, file \"<ipython-input-51-5e03ce7b7391>\", line 16>, result=<ExecutionResult object at 7fb1a0268ba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fb16f31cdb0, file \"<ipython-input-51-5e03ce7b7391>\", line 16>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/andy/barbara/github_ml_uzh/Machine_Learning_in_Finance_Group_Project/<ipython-input-51-5e03ce7b7391> in <module>()\n     11 param_grid_1 = {'svm_poly__C': [100],\n     12               'svm_poly__degree': [1, 2, 3]}\n     13 \n     14 # Run grid search\n     15 grid1 = GridSearchCV(pipe1, param_grid=param_grid_1, cv=5, n_jobs=-1)\n---> 16 grid1.fit(X_train, y_train)\n     17 \n     18 estimator.get_params().keys()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns]\n        y =       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Apr 13 00:19:01 2018\nPID: 3525                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid1 = [{'scaler': [StandardScaler()],\n",
    "               'classifier': [SVC(kernel=set_kernel)],\n",
    "               'classifier__gamma': [1, 10],\n",
    "               'classifier__C': [10, 100]},\n",
    "              {'scaler': [StandardScaler(), None],\n",
    "               'classifier': [set_classifier()],\n",
    "               'classifier__C': [10, 100]}]\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_1 = {'svm_poly__C': [100],\n",
    "              'svm_poly__degree': [1, 2, 3]}\n",
    "\n",
    "# Run grid search\n",
    "grid1 = GridSearchCV(pipe1, param_grid=param_grid_1, cv=5, n_jobs=-1)\n",
    "grid1.fit(X_train, y_train)\n",
    "\n",
    "estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 16, 54, 816241, tzinfo=tzutc()), 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd38f56fd560d4b2b8426ad27e33d2b48']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 16, 54, 816241, tzinfo=tzutc()), 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd38f56fd560d4b2b8426ad27e33d2b48'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 16, 54, 816241, tzinfo=tzutc()), 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-50-86cf8aabf42b>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fb1a026f4e0, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fb16f31c780, file \"<ipython-input-50-86cf8aabf42b>\", line 5>\n        result = <ExecutionResult object at 7fb1a026f4e0, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fb16f31c780, file \"<ipython-input-50-86cf8aabf42b>\", line 5>, result=<ExecutionResult object at 7fb1a026f4e0, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fb16f31c780, file \"<ipython-input-50-86cf8aabf42b>\", line 5>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/andy/barbara/github_ml_uzh/Machine_Learning_in_Finance_Group_Project/<ipython-input-50-86cf8aabf42b> in <module>()\n      1 \n      2 \n      3 # Run grid search\n      4 grid1 = GridSearchCV(pipe1, param_grid=param_grid_1, cv=5, n_jobs=-1)\n----> 5 grid1.fit(X_train, y_train)\n      6 \n      7 # Print results\n      8 #print('Best CV accuracy: {:.2f}'.format(grid.best_score_))\n      9 #print('Test score:       {:.2f}'.format(grid.score(X_test_bal, y_test_bal)))\n     10 #print('Best parameters: {}'.format(grid.best_params_))\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns]\n        y =       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Apr 13 00:16:54 2018\nPID: 3503                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0mTraceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/andy/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Apr 13 00:16:54 2018\nPID: 3503                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Apr 13 00:16:54 2018\nPID: 3503                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-86cf8aabf42b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Run grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrid1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fb1ad661660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 16, 54, 816241, tzinfo=tzutc()), 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd38f56fd560d4b2b8426ad27e33d2b48']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 16, 54, 816241, tzinfo=tzutc()), 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd38f56fd560d4b2b8426ad27e33d2b48'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 12, 22, 16, 54, 816241, tzinfo=tzutc()), 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'session': 'd38f56fd560d4b2b8426ad27e33d2b48', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a33961391fa4458b550c6a246e6e1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"\\n\\n# Run grid search\\ngrid1 = GridSearchCV(pipe1, ...('Best parameters: {}'.format(grid.best_params_))\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-50-86cf8aabf42b>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fb1a026f4e0, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fb16f31c780, file \"<ipython-input-50-86cf8aabf42b>\", line 5>\n        result = <ExecutionResult object at 7fb1a026f4e0, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fb16f31c780, file \"<ipython-input-50-86cf8aabf42b>\", line 5>, result=<ExecutionResult object at 7fb1a026f4e0, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fb16f31c780, file \"<ipython-input-50-86cf8aabf42b>\", line 5>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('Selected Version ' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + '; ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V... + str(VERSION) + ' = ' + str(sel_version), '\\\\n')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Set Kernel\\nset_kernel = \\'poly\\'\\n\"\"\"\\nSelect \\'pol...dditional Classifier: \\'+str(classifier)+\\'.\\'+\\'\\\\n\\')', '# Create pipeline object with standard scaler, F...rain).score(X_test, y_test)\\n\\nprint(briefing_pipe)', '# hide unnecessary warnings (\"depreciation\" of p...svm import SVC\\nplt.style.use(\\'seaborn-whitegrid\\')', \"### Chose which dataset version you want the sel...raise ValueError('VERSION must be either 1 or 2')\", \"# print status\\nprint('SUMMARY:'+'\\\\n'+'Selected V...' + str(VERSION) + ': ' + str(sel_version), '\\\\n')\", \"# Import Data\\nif VERSION == 1: \\n# features not p...ueError('VERSION value must be either 1 or 2')   \", '# Train/test split, into 20% test size and 80% t...set.index = X_test.index\\nX_test = imputed_dataset', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SelectFromModel': <class 'sklearn.feature_selection.from_model.SelectFromModel'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/andy/barbara/github_ml_uzh/Machine_Learning_in_Finance_Group_Project/<ipython-input-50-86cf8aabf42b> in <module>()\n      1 \n      2 \n      3 # Run grid search\n      4 grid1 = GridSearchCV(pipe1, param_grid=param_grid_1, cv=5, n_jobs=-1)\n----> 5 grid1.fit(X_train, y_train)\n      6 \n      7 # Print results\n      8 #print('Best CV accuracy: {:.2f}'.format(grid.best_score_))\n      9 #print('Test score:       {:.2f}'.format(grid.score(X_test_bal, y_test_bal)))\n     10 #print('Best parameters: {}'.format(grid.best_params_))\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns]\n        y =       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Apr 13 00:16:54 2018\nPID: 3503                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]),        CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns],       0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], {'score': <function _passthrough_scorer>}, array([ 533,  535,  536, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), 0, {'svm_poly__C': 100, 'svm_poly__degree': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), X=       CAPEI     bm     evm  pe_op_basic  pe_op_...1.861           1.562  \n\n[2836 rows x 71 columns], y=      0\n1530  0\n1397  1\n2238  0\n3170  1\n2244  1\n...\n1653  1\n2607  1\n2732  1\n\n[2836 rows x 1 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 533,  535,  536, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    598, 600, 602, 603, 604, 605, 606, 607, 612]), verbose=0, parameters={'svm_poly__C': 100, 'svm_poly__degree': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'svm_poly__C': 100, 'svm_poly__degree': 1}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'svm_poly__C': 100, 'svm_poly__degree': 1})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'svm_poly'\n        self = Pipeline(memory=None,\n     steps=[('scaler', Sta...0, shrinking=True,\n  tol=0.001, verbose=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter svm_poly for estimator Pipeline(memory=None,\n     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), (\"<class 'sklearn.decomposition.pca.PCA'>\", PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Print results\n",
    "#print('Best CV accuracy: {:.2f}'.format(grid.best_score_))\n",
    "#print('Test score:       {:.2f}'.format(grid.score(X_test_bal, y_test_bal)))\n",
    "#print('Best parameters: {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "## 4.3. Pipe 2: \n",
    "#### Feature Selection:  before Pipe with RandomForestClassifier or PCA (Chapter 2.A and 2.B)\n",
    "#### Scaling : In-Pipe with StandardScaler\n",
    "#### Classification: SVM\n",
    "#### additional Classification: RandomForestClassifier, LogisticRegression\n",
    "###      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "## 4.3. Pipe 3: \n",
    "### Feature Selection:  none\n",
    "### Classification: SVM\n",
    "### additional Classification: RandomForestClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
