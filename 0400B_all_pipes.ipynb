{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, UZH 2018, Group Project\n",
    "### Group 2: Barbara Capl, Mathias LÃ¼thi, Pamela Matias, Stefanie Rentsch\n",
    "##       \n",
    "##    \n",
    "# 4. Collection of all Pipes\n",
    "\n",
    "###        \n",
    "In this section we use the data we prepared in chapter 1.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide unnecessary warnings (\"depreciation\" of packages etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "## 4.1. Pipe 1 (P1)\n",
    "\n",
    "#### Feature Selection: In-Pipe with RandomForestClassifier or PCA\n",
    "#### Scaling : In-Pipe with StandardScaler\n",
    "#### Classification: SVM\n",
    "#### Additional Classification: RandomForestClassifier, LogisticRegression\n",
    "###      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.0.  (i) DATA SETTINGS (P1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Dataset Version you want\n",
    "##### Whole Feature Matrices (Features not pre-selected)\n",
    "VERSION = 1; Feature Matrix with only ratios                                  \n",
    "VERSION = 2;  Feature Matrix with ratios + saisonality + other market data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chose which dataset version you want the selection of features and the prediction to be based on \n",
    "VERSION = 1\n",
    "\"\"\"\n",
    "INSERT NUMBER 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "# Defining sel_state variable for easier printing out    \n",
    "if VERSION == 1: sel_version = 'Whole original Dataset with only the Ratios as predicive Features.'\n",
    "elif VERSION == 2: sel_version = 'Whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features.'\n",
    "else: raise ValueError('VERSION must be either 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 1: Whole original Dataset with only the Ratios as predicive Features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print status\n",
    "briefing_data='SUMMARY DATA SETTINGS:'+'\\n'+'Selected Version ' + str(VERSION) + ': ' + str(sel_version)+'\\n'\n",
    "print(briefing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary Data and impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "if VERSION == 1: \n",
    "# features not pre-selected, only ratios\n",
    "    X = pd.read_csv('Data/generated_datasets/features_ratios_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "elif VERSION == 2: \n",
    "# features not pre-selected, ratios + seasonality + market data\n",
    "    X = pd.read_csv('Data/generated_datasets/features_additional_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "else: raise ValueError('VERSION value must be either 1 or 2')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split, into 20% test size and 80% train size because it is a relatively small dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Use a median fill for train\n",
    "imp = Imputer(missing_values=np.nan, strategy = 'median' , axis=0)\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_train))\n",
    "imputed_dataset.columns = X_train.columns\n",
    "imputed_dataset.index = X_train.index\n",
    "X_train = imputed_dataset\n",
    "\n",
    "# Use a median fill for the test set\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_test))\n",
    "imputed_dataset.columns = X_test.columns\n",
    "imputed_dataset.index = X_test.index\n",
    "X_test = imputed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.0. (ii) PIPING SETTINGS (P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: rbf.\n",
      "Selected In-Pipe Feature Selecter: <class 'sklearn.ensemble.forest.RandomForestClassifier'>.\n",
      "Additional Classifier: <class 'sklearn.linear_model.logistic.LogisticRegression'>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Kernel\n",
    "set_kernel = 'rbf'\n",
    "\"\"\"\n",
    "Select 'poly', 'linear' or 'rbf'\n",
    "\"\"\"\n",
    "\n",
    "# Choose In-Pipe Feature Selection Method\n",
    "set_feature_selecter = RandomForestClassifier\n",
    "\"\"\"\n",
    "Select RandomForestClassifier or PCA\n",
    "\"\"\"\n",
    "\n",
    "# Choose Classifier\n",
    "set_classifier = LogisticRegression\n",
    "\"\"\"\n",
    "Select LogisticRegression or RandomForestClassifier\n",
    "\"\"\"\n",
    "\n",
    "# Print result of settings\n",
    "briefing_pipe='SUMMARY PIPE SETTINGS:'+'\\n'+'Selected kernel: '+str(set_kernel)+'.'+'\\n'+'Selected In-Pipe Feature Selecter: '+str(set_feature_selecter)+'.'+'\\n'+'Additional Classifier: '+str(set_classifier)+'.'+'\\n'\n",
    "print(briefing_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Piping (P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 1: Whole original Dataset with only the Ratios as predicive Features.\n",
      "\n",
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: rbf.\n",
      "Selected In-Pipe Feature Selecter: <class 'sklearn.ensemble.forest.RandomForestClassifier'>.\n",
      "Additional Classifier: <class 'sklearn.linear_model.logistic.LogisticRegression'>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set conditions so according to choices under \"settings\", the methods are going to be used automatically\n",
    "\n",
    "# For Loop defining paremeters for Feature Selecter\n",
    "if set_feature_selecter == PCA: \n",
    "    feat_sel_function = PCA()\n",
    "    fs_attr1  ='fs__n_components'\n",
    "    fs_attr1_par = [8, 10, 15, 20, 30, 40]\n",
    "    fs_attr2 = 'fs__random_state'\n",
    "    fs_attr2_par = [0, 10, 20, 50, 100]  \n",
    "\n",
    "elif set_feature_selecter == RandomForestClassifier: \n",
    "    feat_sel_function = SelectFromModel(estimator=RandomForestClassifier(), threshold = 'median')\n",
    "    fs_attr1 = 'fs__estimator__n_estimators'\n",
    "    fs_attr1_par = [3, 6, 8, 10, 15, 20, 30, 40]\n",
    "    fs_attr2 = 'fs__estimator__random_state'\n",
    "    fs_attr2_par = [0, 10, 20, 50, 100]\n",
    "else: raise ValueError('feature_selecter must be either PCA or RandomForestClassifier')\n",
    "\n",
    "# For Loop defining paremeters for additional Classifier\n",
    "if set_classifier == RandomForestClassifier: \n",
    "    classifier_function = RandomForestClassifier()\n",
    "    cl_attr1 = 'cl__n_estimators'\n",
    "    cl_attr1_par = [6, 8, 10, 15, 20, 30, 40]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par = [0, 10, 20, 50, 100]\n",
    "elif set_classifier == LogisticRegression: \n",
    "    classifier_function = LogisticRegression()\n",
    "    cl_attr1 = 'cl__C'\n",
    "    cl_attr1_par = [1, 10, 100]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par = [0, 10, 20, 50, 100]\n",
    "else: raise ValueError('feature_selecter must be either PCA or RandomForestClassifier')\n",
    "\n",
    "#display(fs_attr1, fs_attr1_par)\n",
    "#display(fs_attr2, fs_attr2_par)\n",
    "#display(cl_attr1, cl_attr1_par)\n",
    "#display(cl_attr2, cl_attr2_par)\n",
    "\n",
    "# print settings\n",
    "print(briefing_data+'\\n'+briefing_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6225352112676056"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6225352112676056"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler, chosen Feature Selecter and SVC estimator\n",
    "# Standardscaler standardizes the input variables\n",
    "pipe1_a = Pipeline([('scaler', StandardScaler()), \n",
    "                  ('fs', feat_sel_function), \n",
    "                  ('cl', SVC(kernel=set_kernel, random_state=0))])\n",
    "pipe1_b = Pipeline([('scaler', StandardScaler()), \n",
    "                  ('fs', feat_sel_function), \n",
    "                  ('cl', classifier_function)])\n",
    "\n",
    "# Display scores from resulting pipes\n",
    "display(pipe1_a.fit(X_train, y_train).score(X_test, y_test))\n",
    "display(pipe1_b.fit(X_train, y_train).score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "\n",
    "# First part: scaling with StandardScaler, \n",
    "# Feature Selection with selected method, \n",
    "# Classification with SVC with selected kernel\n",
    "\n",
    "# Second part:  scaling with StandardScaler,\n",
    "# Feature Selection with selected method, \n",
    "# Classification with selected 'additional classifier' method\n",
    "\n",
    "param_grid1 = [{'scaler': [StandardScaler()],\n",
    "               'fs': [feat_sel_function],\n",
    "                fs_attr1: fs_attr1_par,\n",
    "                fs_attr2: fs_attr2_par,                \n",
    "               'cl': [SVC(kernel=set_kernel)],\n",
    "               'cl__C': [10, 100]},\n",
    "               {'scaler': [StandardScaler()],\n",
    "                'fs': [feat_sel_function],\n",
    "                cl_attr1: cl_attr1_par,\n",
    "                cl_attr2: cl_attr2_par, \n",
    "                'cl': [classifier_function],\n",
    "                cl_attr1: cl_attr1_par,\n",
    "                cl_attr2: cl_attr2_par}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "grid1_a = GridSearchCV(pipe1_a, param_grid1, cv=5, n_jobs=-1)\n",
    "grid1_a.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1_b = GridSearchCV(pipe1_b, param_grid1, cv=5, n_jobs=-1)\n",
    "grid1_b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Print results\n",
    "#print('Best CV accuracy: {:.2f}'.format(grid.best_score_))\n",
    "#print('Test score:       {:.2f}'.format(grid.score(X_test_bal, y_test_bal)))\n",
    "#print('Best parameters: {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "## 4.3. Pipe 2: \n",
    "#### Feature Selection:  before Pipe with RandomForestClassifier or PCA (Chapter 2.A and 2.B)\n",
    "#### Scaling : In-Pipe with StandardScaler\n",
    "#### Classification: SVM\n",
    "#### additional Classification: RandomForestClassifier, LogisticRegression\n",
    "###      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "## 4.3. Pipe 3: \n",
    "### Feature Selection:  none\n",
    "### Classification: SVM\n",
    "### additional Classification: RandomForestClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
