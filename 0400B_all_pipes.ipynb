{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, UZH 2018, Group Project\n",
    "### Group 2: Barbara Capl, Mathias Lüthi, Pamela Matias, Stefanie Rentsch\n",
    "##       \n",
    "##    \n",
    "# 4. Collection of all Pipes\n",
    "\n",
    "###        \n",
    "In this section we use the data we prepared in chapter 1.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide unnecessary warnings (\"depreciation\" of packages etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "# 4.1. PIPE 1\n",
    "\n",
    "#### Feature Selection: In-Pipe with RandomForestClassifier or PCA\n",
    "#### Scaling : In-Pipe with StandardScaler\n",
    "#### Classification: SVM\n",
    "#### Additional Classification: RandomForestClassifier, LogisticRegression\n",
    "###      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1. DATA SETTINGS (P1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Dataset Version you want\n",
    "##### Whole Feature Matrices (Features not pre-selected)\n",
    "VERSION = 1; Feature Matrix with only ratios                                  \n",
    "VERSION = 2;  Feature Matrix with ratios + saisonality + other market data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chose which dataset version you want the selection of features and the prediction to be based on \n",
    "VERSION = 1\n",
    "\"\"\"\n",
    "INSERT NUMBER 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "# Defining sel_state variable for easier printing out    \n",
    "if VERSION == 1: sel_version = 'Whole original Dataset with only the Ratios as predicive Features.'\n",
    "elif VERSION == 2: sel_version = 'Whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features.'\n",
    "else: raise ValueError('VERSION must be either 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 1: Whole original Dataset with only the Ratios as predicive Features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print status\n",
    "briefing_data='SUMMARY DATA SETTINGS:'+'\\n'+'Selected Version ' + str(VERSION) + ': ' + str(sel_version)+'\\n'\n",
    "print(briefing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary Data and impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "if VERSION == 1: \n",
    "# features not pre-selected, only ratios\n",
    "    X = pd.read_csv('Data/generated_datasets/features_ratios_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "elif VERSION == 2: \n",
    "# features not pre-selected, ratios + seasonality + market data\n",
    "    X = pd.read_csv('Data/generated_datasets/features_additional_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "else: raise ValueError('VERSION value must be either 1 or 2')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>dpr</th>\n",
       "      <th>...</th>\n",
       "      <th>sale_nwc</th>\n",
       "      <th>rd_sale</th>\n",
       "      <th>adv_sale</th>\n",
       "      <th>staff_sale</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>PEG_trailing</th>\n",
       "      <th>divyield</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>20.773</td>\n",
       "      <td>0.547</td>\n",
       "      <td>10.644</td>\n",
       "      <td>15.468</td>\n",
       "      <td>15.633</td>\n",
       "      <td>18.484</td>\n",
       "      <td>18.484</td>\n",
       "      <td>3.703</td>\n",
       "      <td>9.957</td>\n",
       "      <td>0.623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4240</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1.811</td>\n",
       "      <td>1.181</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>13.678</td>\n",
       "      <td>5.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>25.089</td>\n",
       "      <td>0.461</td>\n",
       "      <td>9.246</td>\n",
       "      <td>17.203</td>\n",
       "      <td>17.296</td>\n",
       "      <td>39.232</td>\n",
       "      <td>39.232</td>\n",
       "      <td>0.689</td>\n",
       "      <td>8.509</td>\n",
       "      <td>2.175</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9910</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>1.521</td>\n",
       "      <td>5.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>12.337</td>\n",
       "      <td>0.911</td>\n",
       "      <td>12.474</td>\n",
       "      <td>9.135</td>\n",
       "      <td>9.209</td>\n",
       "      <td>13.062</td>\n",
       "      <td>13.062</td>\n",
       "      <td>2.034</td>\n",
       "      <td>1.993</td>\n",
       "      <td>0.337</td>\n",
       "      <td>...</td>\n",
       "      <td>5.8105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.038</td>\n",
       "      <td>1.076</td>\n",
       "      <td>3.048</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.380</td>\n",
       "      <td>2.248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CAPEI     bm     evm  pe_op_basic  pe_op_dil  pe_exi  pe_inc     ps  \\\n",
       "1530  20.773  0.547  10.644       15.468     15.633  18.484  18.484  3.703   \n",
       "1397  25.089  0.461   9.246       17.203     17.296  39.232  39.232  0.689   \n",
       "2238  12.337  0.911  12.474        9.135      9.209  13.062  13.062  2.034   \n",
       "\n",
       "        pcf    dpr       ...        sale_nwc  rd_sale  adv_sale  staff_sale  \\\n",
       "1530  9.957  0.623       ...          1.4240    0.136     0.058       0.000   \n",
       "1397  8.509  2.175       ...          4.9910    0.031     0.000       0.000   \n",
       "2238  1.993  0.337       ...          5.8105    0.000     0.024       0.291   \n",
       "\n",
       "      accrual    ptb  PEG_trailing  divyield  PEG_1yrforward  PEG_ltgforward  \n",
       "1530    0.048  1.811         1.181    0.0354          13.678           5.963  \n",
       "1397    0.047  2.189         0.668    0.0398           1.521           5.702  \n",
       "2238    0.038  1.076         3.048    0.0268           0.380           2.248  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2836, 71)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>dpr</th>\n",
       "      <th>...</th>\n",
       "      <th>sale_nwc</th>\n",
       "      <th>rd_sale</th>\n",
       "      <th>adv_sale</th>\n",
       "      <th>staff_sale</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>PEG_trailing</th>\n",
       "      <th>divyield</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>20.983</td>\n",
       "      <td>0.254</td>\n",
       "      <td>8.585</td>\n",
       "      <td>16.127</td>\n",
       "      <td>16.224</td>\n",
       "      <td>16.224</td>\n",
       "      <td>16.224</td>\n",
       "      <td>3.318</td>\n",
       "      <td>10.484</td>\n",
       "      <td>0.287</td>\n",
       "      <td>...</td>\n",
       "      <td>6.768</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.084</td>\n",
       "      <td>4.189</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>21.663</td>\n",
       "      <td>0.235</td>\n",
       "      <td>13.619</td>\n",
       "      <td>16.311</td>\n",
       "      <td>16.489</td>\n",
       "      <td>18.555</td>\n",
       "      <td>18.555</td>\n",
       "      <td>2.379</td>\n",
       "      <td>7.709</td>\n",
       "      <td>0.199</td>\n",
       "      <td>...</td>\n",
       "      <td>7.169</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.039</td>\n",
       "      <td>4.281</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>1.737</td>\n",
       "      <td>1.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>16.327</td>\n",
       "      <td>0.513</td>\n",
       "      <td>6.716</td>\n",
       "      <td>9.520</td>\n",
       "      <td>9.520</td>\n",
       "      <td>15.681</td>\n",
       "      <td>15.550</td>\n",
       "      <td>3.293</td>\n",
       "      <td>8.490</td>\n",
       "      <td>0.792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.286</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>2.198</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>6.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CAPEI     bm     evm  pe_op_basic  pe_op_dil  pe_exi  pe_inc     ps  \\\n",
       "817   20.983  0.254   8.585       16.127     16.224  16.224  16.224  3.318   \n",
       "2592  21.663  0.235  13.619       16.311     16.489  18.555  18.555  2.379   \n",
       "1475  16.327  0.513   6.716        9.520      9.520  15.681  15.550  3.293   \n",
       "\n",
       "         pcf    dpr       ...        sale_nwc  rd_sale  adv_sale  staff_sale  \\\n",
       "817   10.484  0.287       ...           6.768    0.031     0.006       0.000   \n",
       "2592   7.709  0.199       ...           7.169    0.000     0.000       0.195   \n",
       "1475   8.490  0.792       ...           1.286    0.162     0.054       0.000   \n",
       "\n",
       "      accrual    ptb  PEG_trailing  divyield  PEG_1yrforward  PEG_ltgforward  \n",
       "817     0.084  4.189         1.022    0.0187           1.414           1.330  \n",
       "2592    0.039  4.281         1.147    0.0122           1.737           1.572  \n",
       "1475    0.077  2.198         1.022    0.0343          -0.973           6.149  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(710, 71)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "1530  0\n",
       "1397  1\n",
       "2238  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2836, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "817   1\n",
       "2592  0\n",
       "1475  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(710, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train/test split, into 20% test size and 80% train size because it is a relatively small dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Use a median fill for train\n",
    "imp = Imputer(missing_values=np.nan, strategy = 'median' , axis=0)\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_train))\n",
    "imputed_dataset.columns = X_train.columns\n",
    "imputed_dataset.index = X_train.index\n",
    "X_train = imputed_dataset\n",
    "\n",
    "# Use a median fill for the test set\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_test))\n",
    "imputed_dataset.columns = X_test.columns\n",
    "imputed_dataset.index = X_test.index\n",
    "X_test = imputed_dataset\n",
    "\n",
    "display(X_train.head(3), X_train.shape)\n",
    "display(X_test.head(3), X_test.shape)\n",
    "display(y_train.head(3), y_train.shape)\n",
    "display(y_test.head(3), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2. PIPING SETTINGS (P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: linear.\n",
      "Selected In-Pipe Feature Selecter: RF.\n",
      "Additional Classifier: RF.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Kernel\n",
    "set_kernel = 'linear'\n",
    "\"\"\"\n",
    "Select 'poly', 'linear' or 'rbf'\n",
    "\"\"\"\n",
    "\n",
    "# Choose In-Pipe Feature Selection Method\n",
    "set_feature_selecter = 'RF'\n",
    "\"\"\"\n",
    "Select 'RF' for RandomForestClassifier \n",
    "Select 'PCA' for Principal Component Analysis\n",
    "\"\"\"\n",
    "\n",
    "# Choose Classifier\n",
    "set_classifier = 'RF'\n",
    "\"\"\"\n",
    "Select 'LR' (for LogisticRegression) or 'RF' (for RandomForestClassifier)\n",
    "\"\"\"\n",
    "\n",
    "# Print result of settings\n",
    "briefing_pipe='SUMMARY PIPE SETTINGS:'+'\\n'+'Selected kernel: '+str(set_kernel)+'.'+'\\n'+'Selected In-Pipe Feature Selecter: '+str(set_feature_selecter)+'.'+'\\n'+'Additional Classifier: '+str(set_classifier)+'.'+'\\n'\n",
    "print(briefing_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3. Piping (P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 1: Whole original Dataset with only the Ratios as predicive Features.\n",
      "\n",
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: linear.\n",
      "Selected In-Pipe Feature Selecter: RF.\n",
      "Additional Classifier: RF.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set conditions so according to choices under \"settings\", the methods are going to be used automatically\n",
    "\n",
    "# For Loop defining paremeters for Feature Selecter\n",
    "if set_feature_selecter == 'PCA': \n",
    "    feat_sel_function = PCA()\n",
    "    fs_attr1  ='fs__n_components'\n",
    "    fs_attr1_par = [10, 20, 30]\n",
    "    fs_attr2 = 'fs__random_state'\n",
    "    fs_attr2_par = [0, 10, 20]  \n",
    "\n",
    "elif set_feature_selecter == 'RF': \n",
    "    feat_sel_function = SelectFromModel(estimator=RandomForestClassifier(), threshold = 'median')\n",
    "    fs_attr1 = 'fs__estimator__n_estimators'\n",
    "    fs_attr1_par = [10, 20, 30]\n",
    "    fs_attr2 = 'fs__estimator__random_state'\n",
    "    fs_attr2_par = [0, 10, 20]  \n",
    "else: raise ValueError('feature_selecter must be either PCA,or RF.')\n",
    "\n",
    "# For Loop defining paremeters for additional Classifier\n",
    "if set_classifier == 'RF': \n",
    "    classifier_function = RandomForestClassifier()\n",
    "    cl_attr1 = 'cl__n_estimators'\n",
    "    cl_attr1_par = [10, 20, 30]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par =  [0, 10, 20]\n",
    "elif set_classifier == 'LR': \n",
    "    classifier_function = LogisticRegression()\n",
    "    cl_attr1 = 'cl__C'\n",
    "    cl_attr1_par = [1, 50, 100]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par =  [0, 10, 20]\n",
    "else: raise ValueError('feature_selecter must be either PCA or RandomForestClassifier')\n",
    "\n",
    "#display(fs_attr1, fs_attr1_par)\n",
    "#display(fs_attr2, fs_attr2_par)\n",
    "#display(cl_attr1, cl_attr1_par)\n",
    "#display(cl_attr2, cl_attr2_par)\n",
    "\n",
    "# print settings\n",
    "print(briefing_data+'\\n'+briefing_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold='median')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler, chosen Feature Selecter and SVC estimator\n",
    "# Standardscaler standardizes the input variables\n",
    "pipe1_a = Pipeline([('scaler', StandardScaler()), \n",
    "                    ('fs', feat_sel_function), \n",
    "                  ('cl', SVC(kernel=set_kernel, random_state=0))])\n",
    "pipe1_b = Pipeline([('scaler', StandardScaler()), \n",
    "                  ('fs', feat_sel_function), \n",
    "                  ('cl', classifier_function)])\n",
    "\n",
    "\n",
    "# print used parameters\n",
    "display(feat_sel_function, classifier_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Pipe 1a = 0.6281690140845071   vs.   Ratio of \"UP\" (Test) = 0.5704225352112676\n",
      "Score Pipe 1b = 0.5140845070422535   vs.   Ratio of \"UP\" (Test) = 0.5704225352112676\n"
     ]
    }
   ],
   "source": [
    "# Display scores from resulting pipes\n",
    "score1_a = pipe1_a.fit(X_train, y_train).score(X_test, y_test)\n",
    "score1_b = pipe1_b.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "print('Score Pipe 1a = '+str(score1_a)+'   vs.   Ratio of \"UP\" (Test) = '+str(y_test['0'].sum()/len(y_test['0'])))\n",
    "print('Score Pipe 1b = '+str(score1_b)+'   vs.   Ratio of \"UP\" (Test) = '+str(y_test['0'].sum()/len(y_test['0'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4. Grid Search (P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Feature Selection Method: RF\n",
      "fs__estimator__n_estimators: [10, 20, 30]\n",
      "fs__estimator__random_state: [0, 10, 20]\n",
      "\n",
      "Chosen additional Classification Method (beside SVM): RF\n",
      "cl__n_estimators: [10, 20, 30]\n",
      "cl__random_state: [0, 10, 20]\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "\n",
    "# First part: scaling with StandardScaler, \n",
    "# Feature Selection with selected method, \n",
    "# Classification with SVC with selected kernel\n",
    "\n",
    "# Second part:  scaling with StandardScaler,\n",
    "# Feature Selection with selected method, \n",
    "# Classification with selected 'additional classifier' method\n",
    "\n",
    "param_grid1 = [{'scaler': [StandardScaler()],\n",
    "               'fs': [feat_sel_function],\n",
    "                fs_attr1: fs_attr1_par,\n",
    "                fs_attr2: fs_attr2_par,                \n",
    "               'cl': [SVC(kernel=set_kernel)],\n",
    "               'cl__C': [10, 100]},\n",
    "               {'scaler': [StandardScaler()],\n",
    "                'fs': [feat_sel_function],\n",
    "                fs_attr1: fs_attr1_par,\n",
    "                fs_attr2: fs_attr2_par, \n",
    "                'cl': [classifier_function],\n",
    "                cl_attr1: cl_attr1_par,\n",
    "                cl_attr2: cl_attr2_par}]\n",
    "\n",
    "# display chosen attributes\n",
    "show_attributes = 'yes' # if not 'yes', assumed 'no'\n",
    "if show_attributes == 'yes':\n",
    "    print(str('Chosen Feature Selection Method: '+str(set_feature_selecter)+'\\n'+fs_attr1+': '+str(fs_attr1_par)+'\\n'+fs_attr2+': '+str(fs_attr2_par))+'\\n')\n",
    "    print(str('Chosen additional Classification Method (beside SVM): '+str(set_classifier)+'\\n'+cl_attr1+': '+str(cl_attr1_par)+'\\n'+cl_attr2+': '+str(cl_attr2_par)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid Search for pipe1_a\n",
    "### Paatieeence (this can take some minutes)\n",
    "grid1_a = GridSearchCV(pipe1_a, param_grid1, cv=5, n_jobs=-1)\n",
    "grid1_a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(grid1_a.best_score_)+'\\n')\n",
    "print('Test score:       {:.2f}'.format(grid1_a.score(X_test, y_test))+'\\n')\n",
    "print('Best parameters: {}'.format(grid1_a.best_params_)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('fs', SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_i...nalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True)], 'fs': [SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0,...1,\n",
       "          verbose=0, warm_start=False)], 'cl__C': [1, 50, 100], 'cl__random_state': [0, 10, 20]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search for pipe1_b\n",
    "### Paatieeence (this can take some minutes)\n",
    "grid1_b = GridSearchCV(pipe1_b, param_grid1, cv=5, n_jobs=-1)\n",
    "grid1_b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.63\n",
      "\n",
      "Test score:       0.63\n",
      "\n",
      "Best parameters: {'cl': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'cl__C': 100, 'cl__random_state': 0, 'fs': SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=20, verbose=0, warm_start=False),\n",
      "        norm_order=1, prefit=False, threshold='median'), 'fs__estimator__n_estimators': 10, 'fs__estimator__random_state': 20, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(grid1_b.best_score_)+'\\n')\n",
    "print('Test score:       {:.2f}'.format(grid1_b.score(X_test, y_test))+'\\n')\n",
    "print('Best parameters: {}'.format(grid1_b.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###     \n",
    "###     \n",
    "# 4.2. PIPE 2\n",
    "#### Feature Selection:  before Pipe with RandomForestClassifier or PCA (Chapter 2.A and 2.B)\n",
    "#### Scaling : In-Pipe with StandardScaler\n",
    "#### Classification: SVM\n",
    "#### additional Classification: RandomForestClassifier, LogisticRegression\n",
    "###      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1. DATA SETTINGS (P2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Dataset Version you want\n",
    "##### Reduced Feature Matrix (Features pre-selected)\n",
    "VERSION = 1.1; Reduced Feature Matrix with only ratios                                  \n",
    "VERSION = 2.1;  Reduced Feature Matrix with ratios + saisonality + other market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chose which dataset version you want the selection of features and the prediction to be based on \n",
    "VERSION = 2.1\n",
    "\"\"\"\n",
    "INSERT NUMBER 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "# Defining sel_state variable for easier printing out    \n",
    "if VERSION == 1.1: sel_version = 'Reduced Dataset with only the Ratios as predicive Features.'\n",
    "elif VERSION == 2.1: sel_version = 'Reduced Dataset with Ratios + Seasonality + other Market Data as predictive Features.'\n",
    "else: raise ValueError('VERSION must be either 1.1 or 2.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose with which method you want to have the features been pre-selected /reduced\n",
    "\n",
    "##### You have the choice between:\n",
    "SELECTION  = RF ; Features pre-selected with Random Forest Classifier                                                           \n",
    "SELECTION = PCA; Features pre-selected with Principal Component Analysis (PCA)                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You chose SELECTION method Random Forest (RF).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Choose whether you want the datasets with features selected with RF or PCA or the original file\n",
    "SELECTION = 'RF'\n",
    "\"\"\"\n",
    "INSERT WISHED METHOD 'RF', 'PCA'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# This is the control loop. If something has been chosen wrong, it returns an error with explanation.\n",
    "if SELECTION is not 'RF' and SELECTION is not 'PCA': raise ValueError('SELECTION must be set as either RF or PCA.')\n",
    "# Defining of sel_feat (Selected Feature Selection Method) variable and briefing for later.   \n",
    "if SELECTION == 'RF':\n",
    "    sel_feat = 'Random Forest (RF)'\n",
    "    briefing = ('You chose dataset VERSION '+str(VERSION)+' and SELECTION method '+str(SELECTION)+'.'+'\\n'+'Features therefore pre-selected with '+str(sel_feat)+'.')\n",
    "elif SELECTION == 'PCA':\n",
    "    sel_feat = 'Principal Component Analysis (PCA)'\n",
    "    briefing = ('You chose dataset VERSION '+str(VERSION)+' and SELECTION method '+str(SELECTION)+'.'+'\\n'+'Features therefore pre-selected with '+str(sel_feat)+'.')\n",
    "else: raise ValueError('SELECTION must be chosen as either RF or PCA')\n",
    "print('You chose SELECTION method '+str(sel_feat)+'.'+'\\n')\n",
    "#print(sel_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 2.1: Reduced Dataset with Ratios + Seasonality + other Market Data as predictive Features.\n",
      "Pre-Selected with Random Forest (RF).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print status\n",
    "briefing_data='SUMMARY DATA SETTINGS:'+'\\n'+'Selected Version ' + str(VERSION) + ': ' + str(sel_version)+'\\n'+'Pre-Selected with '+str(sel_feat)+'.'+'\\n'    \n",
    "print(briefing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary Data. Imputing not necessary because already done (Data Importet as Results from Chapter 2.A and 2.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "if VERSION == 1.1: \n",
    "    if SELECTION == 'RF':\n",
    "        X_train = pd.read_csv('Data/generated_splits/features_selected_randomforest/X1_train_f.csv', sep=',', header=0)\n",
    "        y_train = pd.read_csv('Data/generated_splits/features_selected_randomforest/y1_train_f.csv', sep=',', header=0)\n",
    "        X_test = pd.read_csv('Data/generated_splits/features_selected_randomforest/X1_test_f.csv', sep=',', header=0)\n",
    "        y_test = pd.read_csv('Data/generated_splits/features_selected_randomforest/y1_test_f.csv', sep=',', header=0)\n",
    "    if SELECTION == 'PCA':\n",
    "        X_train = pd.read_csv('Data/generated_splits/features_selected_pca/X1_train_p.csv', sep=',', header=0)\n",
    "        y_train = pd.read_csv('Data/generated_splits/features_selected_pca/y1_train_p.csv', sep=',', header=0)\n",
    "        X_test = pd.read_csv('Data/generated_splits/features_selected_pca/X1_test_p.csv', sep=',', header=0)\n",
    "        y_test = pd.read_csv('Data/generated_splits/features_selected_pca/y1_test_p.csv', sep=',', header=0)\n",
    "elif VERSION == 2.1: \n",
    "    if SELECTION == 'RF':\n",
    "        X_train = pd.read_csv('Data/generated_splits/features_selected_randomforest/X2_train_f.csv', sep=',', header=0)\n",
    "        y_train = pd.read_csv('Data/generated_splits/features_selected_randomforest/y2_train_f.csv', sep=',', header=0)\n",
    "        X_test = pd.read_csv('Data/generated_splits/features_selected_randomforest/X2_test_f.csv', sep=',', header=0)\n",
    "        y_test = pd.read_csv('Data/generated_splits/features_selected_randomforest/y2_test_f.csv', sep=',', header=0)\n",
    "    if SELECTION == 'PCA':\n",
    "        X_train = pd.read_csv('Data/generated_splits/features_selected_pca/X2_train_p.csv', sep=',', header=0)\n",
    "        y_train = pd.read_csv('Data/generated_splits/features_selected_pca/y2_train_p.csv', sep=',', header=0)\n",
    "        X_test = pd.read_csv('Data/generated_splits/features_selected_pca/X2_test_p.csv', sep=',', header=0)\n",
    "        y_test = pd.read_csv('Data/generated_splits/features_selected_pca/y2_test_p.csv', sep=',', header=0)\n",
    "else: raise ValueError('VERSION value must be either 1.1 or 2.1, SELECTION must be either \"RF\" or \"PCA\".')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ewretd</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>vwretd</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>SHRENDDT</th>\n",
       "      <th>ALTPRCDT</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RETX</th>\n",
       "      <th>RET</th>\n",
       "      <th>divyield</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <th>ps</th>\n",
       "      <th>SEASON_07</th>\n",
       "      <th>pcf</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.038183</td>\n",
       "      <td>0.040186</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>20140929.0</td>\n",
       "      <td>20140829.0</td>\n",
       "      <td>15.633</td>\n",
       "      <td>20.773</td>\n",
       "      <td>15.468</td>\n",
       "      <td>4611190.0</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>18.484</td>\n",
       "      <td>5.963</td>\n",
       "      <td>3.703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.957</td>\n",
       "      <td>13.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.013012</td>\n",
       "      <td>-0.015631</td>\n",
       "      <td>-0.017055</td>\n",
       "      <td>-0.015039</td>\n",
       "      <td>-0.014999</td>\n",
       "      <td>20130730.0</td>\n",
       "      <td>20130628.0</td>\n",
       "      <td>17.296</td>\n",
       "      <td>25.089</td>\n",
       "      <td>17.203</td>\n",
       "      <td>1296447.0</td>\n",
       "      <td>-0.066454</td>\n",
       "      <td>-0.057168</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>39.232</td>\n",
       "      <td>5.702</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.509</td>\n",
       "      <td>1.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044257</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>0.043937</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.043117</td>\n",
       "      <td>20140330.0</td>\n",
       "      <td>20140228.0</td>\n",
       "      <td>9.209</td>\n",
       "      <td>12.337</td>\n",
       "      <td>9.135</td>\n",
       "      <td>3473222.0</td>\n",
       "      <td>0.026373</td>\n",
       "      <td>0.026373</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>13.062</td>\n",
       "      <td>2.248</td>\n",
       "      <td>2.034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.993</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ewretd    ewretx    vwretx    vwretd    sprtrn    SHRENDDT    ALTPRCDT  \\\n",
       "0  0.033697  0.032156  0.038183  0.040186  0.037655  20140929.0  20140829.0   \n",
       "1 -0.013012 -0.015631 -0.017055 -0.015039 -0.014999  20130730.0  20130628.0   \n",
       "2  0.044257  0.042687  0.043937  0.046173  0.043117  20140330.0  20140228.0   \n",
       "\n",
       "   pe_op_dil   CAPEI  pe_op_basic        VOL      RETX       RET  divyield  \\\n",
       "0     15.633  20.773       15.468  4611190.0  0.024042  0.024042    0.0354   \n",
       "1     17.296  25.089       17.203  1296447.0 -0.066454 -0.057168    0.0398   \n",
       "2      9.209  12.337        9.135  3473222.0  0.026373  0.026373    0.0268   \n",
       "\n",
       "   pe_inc  PEG_ltgforward     ps  SEASON_07    pcf  PEG_1yrforward  \n",
       "0  18.484           5.963  3.703        0.0  9.957          13.678  \n",
       "1  39.232           5.702  0.689        0.0  8.509           1.521  \n",
       "2  13.062           2.248  2.034        0.0  1.993           0.380  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2836, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ewretd</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>vwretd</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>SHRENDDT</th>\n",
       "      <th>ALTPRCDT</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RETX</th>\n",
       "      <th>RET</th>\n",
       "      <th>divyield</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <th>ps</th>\n",
       "      <th>SEASON_07</th>\n",
       "      <th>pcf</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.044988</td>\n",
       "      <td>-0.046891</td>\n",
       "      <td>-0.026823</td>\n",
       "      <td>-0.025129</td>\n",
       "      <td>-0.015514</td>\n",
       "      <td>20141009.0</td>\n",
       "      <td>20140930.0</td>\n",
       "      <td>16.224</td>\n",
       "      <td>20.983</td>\n",
       "      <td>16.127</td>\n",
       "      <td>15283673.0</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>16.224</td>\n",
       "      <td>1.330</td>\n",
       "      <td>3.318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.484</td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051828</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>0.035682</td>\n",
       "      <td>0.037477</td>\n",
       "      <td>0.029749</td>\n",
       "      <td>20131030.0</td>\n",
       "      <td>20130930.0</td>\n",
       "      <td>16.489</td>\n",
       "      <td>21.663</td>\n",
       "      <td>16.311</td>\n",
       "      <td>746229.0</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>18.555</td>\n",
       "      <td>1.572</td>\n",
       "      <td>2.379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.709</td>\n",
       "      <td>1.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011388</td>\n",
       "      <td>-0.012292</td>\n",
       "      <td>-0.038109</td>\n",
       "      <td>-0.037096</td>\n",
       "      <td>-0.036974</td>\n",
       "      <td>20100225.0</td>\n",
       "      <td>20100129.0</td>\n",
       "      <td>9.520</td>\n",
       "      <td>16.327</td>\n",
       "      <td>9.520</td>\n",
       "      <td>10148052.0</td>\n",
       "      <td>0.025838</td>\n",
       "      <td>0.025838</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>15.550</td>\n",
       "      <td>6.149</td>\n",
       "      <td>3.293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.490</td>\n",
       "      <td>-0.973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ewretd    ewretx    vwretx    vwretd    sprtrn    SHRENDDT    ALTPRCDT  \\\n",
       "0 -0.044988 -0.046891 -0.026823 -0.025129 -0.015514  20141009.0  20140930.0   \n",
       "1  0.051828  0.049754  0.035682  0.037477  0.029749  20131030.0  20130930.0   \n",
       "2 -0.011388 -0.012292 -0.038109 -0.037096 -0.036974  20100225.0  20100129.0   \n",
       "\n",
       "   pe_op_dil   CAPEI  pe_op_basic         VOL      RETX       RET  divyield  \\\n",
       "0     16.224  20.983       16.127  15283673.0 -0.017073 -0.017073    0.0187   \n",
       "1     16.489  21.663       16.311    746229.0  0.050202  0.050202    0.0122   \n",
       "2      9.520  16.327        9.520  10148052.0  0.025838  0.025838    0.0343   \n",
       "\n",
       "   pe_inc  PEG_ltgforward     ps  SEASON_07     pcf  PEG_1yrforward  \n",
       "0  16.224           1.330  3.318        0.0  10.484           1.414  \n",
       "1  18.555           1.572  2.379        0.0   7.709           1.737  \n",
       "2  15.550           6.149  3.293        0.0   8.490          -0.973  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(710, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2836, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(710, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.head(3), X_train.shape)\n",
    "display(X_test.head(3), X_test.shape)\n",
    "display(y_train.head(3), y_train.shape)\n",
    "display(y_test.head(3), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.2. PIPING SETTINGS (P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: rbf.\n",
      "Selected In-Pipe Feature Selecter: RF.\n",
      "Additional Classifier: LR.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Kernel\n",
    "set_kernel = 'rbf'\n",
    "\"\"\"\n",
    "Select 'poly', 'linear' or 'rbf'\n",
    "\"\"\"\n",
    "\n",
    "# Choose In-Pipe Feature Selection Method\n",
    "set_feature_selecter = 'RF'\n",
    "\"\"\"\n",
    "Select 'RF' (for RandomForestClassifier) or 'PCA' (for Principal Component Analysis)\n",
    "\"\"\"\n",
    "\n",
    "# Choose Classifier\n",
    "set_classifier = 'LR'\n",
    "\"\"\"\n",
    "Select 'LR' (for LogisticRegression) or 'RF' (for RandomForestClassifier)\n",
    "\"\"\"\n",
    "\n",
    "# Print result of settings\n",
    "briefing_pipe='SUMMARY PIPE SETTINGS:'+'\\n'+'Selected kernel: '+str(set_kernel)+'.'+'\\n'+'Selected In-Pipe Feature Selecter: '+str(set_feature_selecter)+'.'+'\\n'+'Additional Classifier: '+str(set_classifier)+'.'+'\\n'\n",
    "print(briefing_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.3. Piping (P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 2.1: Reduced Dataset with Ratios + Seasonality + other Market Data as predictive Features.\n",
      "Pre-Selected with Random Forest (RF).\n",
      "\n",
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: rbf.\n",
      "Selected In-Pipe Feature Selecter: RF.\n",
      "Additional Classifier: LR.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set conditions so according to choices under \"settings\", the methods are going to be used automatically\n",
    "\n",
    "\n",
    "# For Loop defining paremeters for additional Classifier\n",
    "if set_classifier == 'RF': \n",
    "    classifier_function = RandomForestClassifier()\n",
    "    cl_attr1 = 'cl__n_estimators'\n",
    "    cl_attr1_par = [10, 20, 30]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par =  [0, 10, 20]\n",
    "elif set_classifier == 'LR': \n",
    "    classifier_function = LogisticRegression()\n",
    "    cl_attr1 = 'cl__C'\n",
    "    cl_attr1_par = [1, 50, 100]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par =  [0, 10, 20]\n",
    "else: raise ValueError('feature_selecter must be either PCA or RandomForestClassifier')\n",
    "\n",
    "#display(fs_attr1, fs_attr1_par)\n",
    "#display(fs_attr2, fs_attr2_par)\n",
    "#display(cl_attr1, cl_attr1_par)\n",
    "#display(cl_attr2, cl_attr2_par)\n",
    "\n",
    "# print settings\n",
    "print(briefing_data+'\\n'+briefing_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=20, verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold='median')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler, chosen Feature Selecter and SVC estimator\n",
    "# Standardscaler standardizes the input variables\n",
    "pipe2_a = Pipeline([('scaler', StandardScaler()), ('cl', SVC(kernel=set_kernel, random_state=0))])\n",
    "pipe2_b = Pipeline([('scaler', StandardScaler()), ('cl', classifier_function)])\n",
    "\n",
    "\n",
    "# print used parameters\n",
    "display(feat_sel_function, classifier_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Pipe 2a = 0.6676056338028169   vs.   Ratio of \"UP\" (Test) = 0.5704225352112676\n",
      "Score Pipe 2b = 0.6197183098591549   vs.   Ratio of \"UP\" (Test) = 0.5704225352112676\n"
     ]
    }
   ],
   "source": [
    "# Display scores from resulting pipes\n",
    "score2_a = pipe2_a.fit(X_train, y_train).score(X_test, y_test)\n",
    "score2_b = pipe2_b.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "print('Score Pipe 2a = '+str(score2_a)+'   vs.   Ratio of \"UP\" (Test) = '+str(y_test['0'].sum()/len(y_test['0'])))\n",
    "print('Score Pipe 2b = '+str(score2_b)+'   vs.   Ratio of \"UP\" (Test) = '+str(y_test['0'].sum()/len(y_test['0'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.4. Grid Search (P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Feature Selection Method: RF\n",
      "fs__estimator__n_estimators: [10, 20, 30]\n",
      "fs__estimator__random_state: [0, 10, 20]\n",
      "\n",
      "Chosen additional Classification Method (beside SVM): LR\n",
      "cl__C: [1, 50, 100]\n",
      "cl__random_state: [0, 10, 20]\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "\n",
    "# First part: scaling with StandardScaler, \n",
    "# Feature Selection with selected method, \n",
    "# Classification with SVC with selected kernel\n",
    "\n",
    "# Second part:  scaling with StandardScaler,\n",
    "# Feature Selection with selected method, \n",
    "# Classification with selected 'additional classifier' method\n",
    "\n",
    "param_grid2 = [{'scaler': [StandardScaler()],                \n",
    "               'cl': [SVC(kernel=set_kernel)],\n",
    "               'cl__C': [10, 100]},\n",
    "               {'scaler': [StandardScaler()],\n",
    "                'cl': [classifier_function],\n",
    "                cl_attr1: cl_attr1_par,\n",
    "                cl_attr2: cl_attr2_par}]\n",
    "\n",
    "# display chosen attributes\n",
    "show_attributes = 'yes' # if not 'yes', assumed 'no'\n",
    "if show_attributes == 'yes':\n",
    "    print(str('Chosen Feature Selection Method: '+str(set_feature_selecter)+'\\n'+fs_attr1+': '+str(fs_attr1_par)+'\\n'+fs_attr2+': '+str(fs_attr2_par))+'\\n')\n",
    "    print(str('Chosen additional Classification Method (beside SVM): '+str(set_classifier)+'\\n'+cl_attr1+': '+str(cl_attr1_par)+'\\n'+cl_attr2+': '+str(cl_attr2_par)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('cl', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True)], 'cl': [SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, v...1,\n",
       "          verbose=0, warm_start=False)], 'cl__C': [1, 50, 100], 'cl__random_state': [0, 10, 20]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search for pipe_2a\n",
    "### Paatieeence (this can take some minutes)\n",
    "grid2_a = GridSearchCV(pipe2_a, param_grid2, cv=5, n_jobs=-1)\n",
    "grid2_a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.64\n",
      "Test score:       0.67\n",
      "Best parameters: {'cl': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'cl__C': 10, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(grid2_a.best_score_))\n",
    "print('Test score:       {:.2f}'.format(grid2_a.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(grid2_a.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('cl', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'scaler': [StandardScaler(copy=True, with_mean=True, with_std=True)], 'cl': [SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, v...1,\n",
       "          verbose=0, warm_start=False)], 'cl__C': [1, 50, 100], 'cl__random_state': [0, 10, 20]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search for pipe2_b\n",
    "### Paatieeence (this can take some minutes)\n",
    "grid2_b = GridSearchCV(pipe2_b, param_grid2, cv=5, n_jobs=-1)\n",
    "grid2_b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.64\n",
      "\n",
      "Test score:       0.67\n",
      "\n",
      "Best parameters: {'cl': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'cl__C': 10, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(grid2_b.best_score_)+'\\n')\n",
    "print('Test score:       {:.2f}'.format(grid2_b.score(X_test, y_test))+'\\n')\n",
    "print('Best parameters: {}'.format(grid2_b.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###     \n",
    "###     \n",
    "# 4.3. PIPE 3\n",
    "#### Feature Selection:  NONE\n",
    "#### Scaling : In-Pipe with StandardScaler\n",
    "#### Classification: SVM\n",
    "#### additional Classification: RandomForestClassifier, LogisticRegression\n",
    "###      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1. DATA SETTINGS (P3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Dataset Version you want\n",
    "##### Whole Feature Matrices (Features not pre-selected)\n",
    "VERSION = 1; Feature Matrix with only ratios                                  \n",
    "VERSION = 2;  Feature Matrix with ratios + saisonality + other market data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chose which dataset version you want the selection of features and the prediction to be based on \n",
    "VERSION = 2\n",
    "\"\"\"\n",
    "INSERT NUMBER 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "# Defining sel_state variable for easier printing out    \n",
    "if VERSION == 1: sel_version = 'Whole original Dataset with only the Ratios as predicive Features.'\n",
    "elif VERSION == 2: sel_version = 'Whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features.'\n",
    "else: raise ValueError('VERSION must be either 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 2: Whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print status\n",
    "briefing_data='SUMMARY DATA SETTINGS:'+'\\n'+'Selected Version ' + str(VERSION) + ': ' + str(sel_version)+'\\n'\n",
    "print(briefing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary Data and impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "if VERSION == 1: \n",
    "# features not pre-selected, only ratios\n",
    "    X = pd.read_csv('Data/generated_datasets/features_ratios_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "elif VERSION == 2: \n",
    "# features not pre-selected, ratios + seasonality + market data\n",
    "    X = pd.read_csv('Data/generated_datasets/features_additional_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "else: raise ValueError('VERSION value must be either 1 or 2')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHRFLG</th>\n",
       "      <th>SHRENDDT</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>BID</th>\n",
       "      <th>ASK</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>...</th>\n",
       "      <th>CUSIP_65410610</th>\n",
       "      <th>CUSIP_71708110</th>\n",
       "      <th>CUSIP_74271810</th>\n",
       "      <th>CUSIP_88579Y10</th>\n",
       "      <th>CUSIP_89417E10</th>\n",
       "      <th>CUSIP_91301710</th>\n",
       "      <th>CUSIP_91324P10</th>\n",
       "      <th>CUSIP_92343V10</th>\n",
       "      <th>CUSIP_92826C83</th>\n",
       "      <th>CUSIP_93114210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20140929.0</td>\n",
       "      <td>28.04</td>\n",
       "      <td>29.49</td>\n",
       "      <td>29.39</td>\n",
       "      <td>4611190.0</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>29.40</td>\n",
       "      <td>29.41</td>\n",
       "      <td>6340863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20130730.0</td>\n",
       "      <td>32.17</td>\n",
       "      <td>34.65</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1296447.0</td>\n",
       "      <td>-0.057168</td>\n",
       "      <td>32.16</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1209589.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20140330.0</td>\n",
       "      <td>54.31</td>\n",
       "      <td>58.49</td>\n",
       "      <td>56.82</td>\n",
       "      <td>3473222.0</td>\n",
       "      <td>0.026373</td>\n",
       "      <td>56.83</td>\n",
       "      <td>56.84</td>\n",
       "      <td>3786825.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SHRFLG    SHRENDDT  BIDLO  ASKHI    PRC        VOL       RET    BID  \\\n",
       "1530     0.0  20140929.0  28.04  29.49  29.39  4611190.0  0.024042  29.40   \n",
       "1397     0.0  20130730.0  32.17  34.65  32.17  1296447.0 -0.057168  32.16   \n",
       "2238     0.0  20140330.0  54.31  58.49  56.82  3473222.0  0.026373  56.83   \n",
       "\n",
       "        ASK     SHROUT       ...        CUSIP_65410610  CUSIP_71708110  \\\n",
       "1530  29.41  6340863.0       ...                   0.0             1.0   \n",
       "1397  32.17  1209589.0       ...                   0.0             0.0   \n",
       "2238  56.84  3786825.0       ...                   0.0             0.0   \n",
       "\n",
       "      CUSIP_74271810  CUSIP_88579Y10  CUSIP_89417E10  CUSIP_91301710  \\\n",
       "1530             0.0             0.0             0.0             0.0   \n",
       "1397             0.0             0.0             0.0             0.0   \n",
       "2238             0.0             0.0             0.0             0.0   \n",
       "\n",
       "      CUSIP_91324P10  CUSIP_92343V10  CUSIP_92826C83  CUSIP_93114210  \n",
       "1530             0.0             0.0             0.0             0.0  \n",
       "1397             0.0             0.0             0.0             0.0  \n",
       "2238             0.0             0.0             0.0             0.0  \n",
       "\n",
       "[3 rows x 181 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2836, 181)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHRFLG</th>\n",
       "      <th>SHRENDDT</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>BID</th>\n",
       "      <th>ASK</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>...</th>\n",
       "      <th>CUSIP_65410610</th>\n",
       "      <th>CUSIP_71708110</th>\n",
       "      <th>CUSIP_74271810</th>\n",
       "      <th>CUSIP_88579Y10</th>\n",
       "      <th>CUSIP_89417E10</th>\n",
       "      <th>CUSIP_91301710</th>\n",
       "      <th>CUSIP_91324P10</th>\n",
       "      <th>CUSIP_92343V10</th>\n",
       "      <th>CUSIP_92826C83</th>\n",
       "      <th>CUSIP_93114210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20141009.0</td>\n",
       "      <td>97.87</td>\n",
       "      <td>103.30</td>\n",
       "      <td>100.75</td>\n",
       "      <td>15283673.0</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>100.75</td>\n",
       "      <td>100.76</td>\n",
       "      <td>5866161.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20131030.0</td>\n",
       "      <td>72.43</td>\n",
       "      <td>77.64</td>\n",
       "      <td>75.52</td>\n",
       "      <td>746229.0</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>75.53</td>\n",
       "      <td>75.54</td>\n",
       "      <td>1078864.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20100225.0</td>\n",
       "      <td>18.53</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.66</td>\n",
       "      <td>10148052.0</td>\n",
       "      <td>0.025838</td>\n",
       "      <td>18.66</td>\n",
       "      <td>18.67</td>\n",
       "      <td>8069536.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SHRFLG    SHRENDDT  BIDLO   ASKHI     PRC         VOL       RET     BID  \\\n",
       "817      0.0  20141009.0  97.87  103.30  100.75  15283673.0 -0.017073  100.75   \n",
       "2592     0.0  20131030.0  72.43   77.64   75.52    746229.0  0.050202   75.53   \n",
       "1475     0.0  20100225.0  18.53   20.00   18.66  10148052.0  0.025838   18.66   \n",
       "\n",
       "         ASK     SHROUT       ...        CUSIP_65410610  CUSIP_71708110  \\\n",
       "817   100.76  5866161.0       ...                   0.0             0.0   \n",
       "2592   75.54  1078864.0       ...                   0.0             0.0   \n",
       "1475   18.67  8069536.0       ...                   0.0             1.0   \n",
       "\n",
       "      CUSIP_74271810  CUSIP_88579Y10  CUSIP_89417E10  CUSIP_91301710  \\\n",
       "817              0.0             0.0             0.0             0.0   \n",
       "2592             0.0             0.0             0.0             0.0   \n",
       "1475             0.0             0.0             0.0             0.0   \n",
       "\n",
       "      CUSIP_91324P10  CUSIP_92343V10  CUSIP_92826C83  CUSIP_93114210  \n",
       "817              0.0             0.0             0.0             0.0  \n",
       "2592             0.0             0.0             0.0             0.0  \n",
       "1475             0.0             0.0             0.0             0.0  \n",
       "\n",
       "[3 rows x 181 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(710, 181)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "1530  0\n",
       "1397  1\n",
       "2238  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2836, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "817   1\n",
       "2592  0\n",
       "1475  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(710, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train/test split, into 20% test size and 80% train size because it is a relatively small dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Use a median fill for train\n",
    "imp = Imputer(missing_values=np.nan, strategy = 'median' , axis=0)\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_train))\n",
    "imputed_dataset.columns = X_train.columns\n",
    "imputed_dataset.index = X_train.index\n",
    "X_train = imputed_dataset\n",
    "\n",
    "# Use a median fill for the test set\n",
    "imputed_dataset = pd.DataFrame(imp.fit_transform(X_test))\n",
    "imputed_dataset.columns = X_test.columns\n",
    "imputed_dataset.index = X_test.index\n",
    "X_test = imputed_dataset\n",
    "\n",
    "display(X_train.head(3),X_train.shape)\n",
    "display(X_test.head(3), X_test.shape)\n",
    "display(y_train.head(3), y_train.shape)\n",
    "display(y_test.head(3), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.2. PIPING SETTINGS (P3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: linear.\n",
      "Additional Classifier: LR.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Kernel\n",
    "set_kernel = 'linear'\n",
    "\"\"\"\n",
    "Select 'poly', 'linear' or 'rbf'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Choose Classifier\n",
    "set_classifier = 'LR'\n",
    "\"\"\"\n",
    "Select 'LR' (for LogisticRegression) or 'RF' (for RandomForestClassifier)\n",
    "\"\"\"\n",
    "\n",
    "# Print result of settings\n",
    "briefing_pipe='SUMMARY PIPE SETTINGS:'+'\\n'+'Selected kernel: '+str(set_kernel)+'.'+'\\n'+'Additional Classifier: '+str(set_classifier)+'.'+'\\n'\n",
    "print(briefing_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.3. Piping (P3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY DATA SETTINGS:\n",
      "Selected Version 2: Whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features.\n",
      "\n",
      "SUMMARY PIPE SETTINGS:\n",
      "Selected kernel: linear.\n",
      "Additional Classifier: LR.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set conditions so according to choices under \"settings\", the methods are going to be used automatically\n",
    "\n",
    "# For Loop defining paremeters for additional Classifier\n",
    "if set_classifier == 'RF': \n",
    "    classifier_function = RandomForestClassifier()\n",
    "    cl_attr1 = 'cl__n_estimators'\n",
    "    cl_attr1_par = [10, 20, 30]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par =  [0, 10, 20]\n",
    "elif set_classifier == 'LR': \n",
    "    classifier_function = LogisticRegression()\n",
    "    cl_attr1 = 'cl__C'\n",
    "    cl_attr1_par = [1, 50, 100]\n",
    "    cl_attr2 = 'cl__random_state'\n",
    "    cl_attr2_par =  [0, 10, 20]\n",
    "else: raise ValueError('feature_selecter must be either PCA or RandomForestClassifier')\n",
    "\n",
    "#display(fs_attr1, fs_attr1_par)\n",
    "#display(fs_attr2, fs_attr2_par)\n",
    "#display(cl_attr1, cl_attr1_par)\n",
    "#display(cl_attr2, cl_attr2_par)\n",
    "\n",
    "# print settings\n",
    "print(briefing_data+'\\n'+briefing_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=20, verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold='median')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create pipeline object with standard scaler, chosen Feature Selecter and SVC estimator\n",
    "# Standardscaler standardizes the input variables\n",
    "pipe3_a = Pipeline([('scaler', StandardScaler()), ('cl', SVC(kernel=set_kernel, random_state=0))])\n",
    "pipe3_b = Pipeline([('scaler', StandardScaler()), ('cl', classifier_function)])\n",
    "\n",
    "\n",
    "# print used parameters\n",
    "display(feat_sel_function, classifier_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Pipe 3a = 0.6676056338028169   vs.   Ratio of \"UP\" (Test) = 0.5704225352112676\n",
      "Score Pipe 3b = 0.6197183098591549   vs.   Ratio of \"UP\" (Test) = 0.5704225352112676\n"
     ]
    }
   ],
   "source": [
    "# Display scores from resulting pipes\n",
    "score3_a = pipe3_a.fit(X_train, y_train).score(X_test, y_test)\n",
    "score3_b = pipe3_b.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "print('Score Pipe 3a = '+str(score2_a)+'   vs.   Ratio of \"UP\" (Test) = '+str(y_test['0'].sum()/len(y_test['0'])))\n",
    "print('Score Pipe 3b = '+str(score2_b)+'   vs.   Ratio of \"UP\" (Test) = '+str(y_test['0'].sum()/len(y_test['0'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.4. Grid Search (P3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "\n",
    "# First part: scaling with StandardScaler, \n",
    "# Feature Selection with selected method, \n",
    "# Classification with SVC with selected kernel\n",
    "\n",
    "# Second part:  scaling with StandardScaler,\n",
    "# Feature Selection with selected method, \n",
    "# Classification with selected 'additional classifier' method\n",
    "\n",
    "param_grid3 = [{'scaler': [StandardScaler()],                \n",
    "               'cl': [SVC(kernel=set_kernel)],\n",
    "               'cl__C': [10, 100]},\n",
    "               {'scaler': [StandardScaler()], \n",
    "                'cl': [classifier_function],\n",
    "                cl_attr1: cl_attr1_par,\n",
    "                cl_attr2: cl_attr2_par}]\n",
    "\n",
    "# display chosen attributes\n",
    "show_attributes = 'yes' # if not 'yes', assumed 'no'\n",
    "if show_attributes == 'yes':\n",
    "    print(str('Chosen additional Classification Method (beside SVM): '+str(set_classifier)+'\\n'+cl_attr1+': '+str(cl_attr1_par)+'\\n'+cl_attr2+': '+str(cl_attr2_par)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-fac976615478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m### Paatieeence (this can take some minutes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid3_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe3_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid3_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 **self.best_params_)\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid Search for pipe3_a\n",
    "### Paatieeence (this can take some minutes)\n",
    "grid3_a = GridSearchCV(pipe3_a, param_grid3, cv=5, n_jobs=-1)\n",
    "grid3_a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(grid3_a.best_score_)+'\\n')\n",
    "print('Test score:       {:.2f}'.format(grid3_a.score(X_test, y_test))+'\\n')\n",
    "print('Best parameters: {}'.format(grid3_a.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid Search for pipe3_b\n",
    "### Paatieeence (this can take some minutes)\n",
    "grid3_b = GridSearchCV(pipe3_b, param_grid3, cv=5, n_jobs=-1)\n",
    "grid3_b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(grid3_b.best_score_)+'\\n')\n",
    "print('Test score:       {:.2f}'.format(grid3_b.score(X_test, y_test))+'\\n')\n",
    "print('Best parameters: {}'.format(grid3_b.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
