{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, UZH 2018, Group Project\n",
    "### Group 2: Barbara Capl, Mathias Lüthi, Pamela Matias, Stefanie Rentsch\n",
    "##       \n",
    "# 3. Support Vector Machines (SVM)\n",
    "\n",
    "###   \n",
    "In this section we use the feature matrices and response vectors with features selected in chapter 2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide unnecessary warnings (\"depreciation\" of packages etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Choose the Dataset Version you want\n",
    "\n",
    "##### Whole Feature Matrix (Features not pre-selected)\n",
    "VERSION = 1; Feature Matrix with only ratios                                  \n",
    "VERSION = 2;  Feature Matrix with ratios + saisonality + other market data\n",
    "\n",
    "##### Reduced Feature Matrix (Features pre-selected)\n",
    "VERSION = 1.1; Reduced Feature Matrix with only ratios                                  \n",
    "VERSION = 2.1;  Reduced Feature Matrix with ratios + saisonality + other market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chose which dataset version you want the selection of features and the prediction to be based on \n",
    "VERSION = 2\n",
    "\"\"\"\n",
    "INSERT NUMBER 1, 2, 1.1 or 2.1\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Defining sel_state variable for easier printing out    \n",
    "if VERSION == 1:\n",
    "    sel_version = 'Based on whole original Dataset with only the Ratios Dataset as predicive Features.'\n",
    "elif VERSION == 2:\n",
    "    sel_version = 'Based on whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features.'\n",
    "elif VERSION == 1.1:\n",
    "    sel_version = 'Based on reduced Dataset with only the Ratios Dataset as predicive Features.'\n",
    "elif VERSION == 2.1:\n",
    "    sel_version = 'Based on reduced Dataset with Ratios + Seasonality + other Market Data as predictive Features.'\n",
    "else: raise ValueError('VERSION must be either 1, 2, 1.1 or 2.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) If you chose VERSION 1.1. or VERSION 2.1:  (Reduced Feature Matrix)                                                                  \n",
    "### => Choose with which method you want to have the features been pre-selected /reduced\n",
    "\n",
    "##### You have the choice between:\n",
    "mySELECTION  = RF ; Features pre-selected with Random Forest Classifier                                                           \n",
    "mySELECTION = PCA; Features pre-selected with Principal Component Analysis (PCA)                                         \n",
    "\n",
    "##### By Default;\n",
    "If VERSION 1 or VERSION 2 was chosen above: SELECTION = none by Default; no features pre-selected. You don't need to define variable mySELECTION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You chose SELECTION method No Feature Selection Method available..\n"
     ]
    }
   ],
   "source": [
    "### Choose whether you want the datasets with features selected with RF or PCA or the original file\n",
    "mySELECTION = 'PCA'\n",
    "\"\"\"\n",
    "INSERT WISHED METHOD 'RF', 'PCA'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# This is the control loop. If something has been chosen wrong, it returns an error with explanation.\n",
    "if VERSION == 1 or VERSION == 2:\n",
    "    SELECTION = 'none'\n",
    "elif VERSION == 1.1 or VERSION == 2.1:\n",
    "    SELECTION = mySELECTION\n",
    "    if mySELECTION is not 'RF' and mySELECTION is not 'PCA':\n",
    "        raise ValueError('Because VERSION '+str(VERSION)+' is chosen, mySELECTION must be set as either RF or PCA.')\n",
    "else: raise ValueError('VERSION must be either 1, 2, 1.1 or 2.1. mySELECTION must be chosen as either RF or PCA.')\n",
    "\n",
    "# Defining of sel_feat (Selected Feature Selection Method) variable and briefing for later.   \n",
    "if SELECTION == 'RF':\n",
    "    sel_feat = 'Random Forest (RF)'\n",
    "    briefing = ('You chose dataset VERSION '+str(VERSION)+' and SELECTION method '+str(SELECTION)+'.'+'\\n'+'Features therefore pre-selected with '+str(sel_feat)+'.')\n",
    "elif SELECTION == 'PCA':\n",
    "    sel_feat = 'Principal Component Analysis (PCA)'\n",
    "    briefing = ('You chose dataset VERSION '+str(VERSION)+' and SELECTION method '+str(SELECTION)+'.'+'\\n'+'Features therefore pre-selected with '+str(sel_feat)+'.')\n",
    "elif SELECTION == 'none':\n",
    "    sel_feat = 'No Feature Selection Method available.'\n",
    "    briefing = ('You chose VERSION '+str(VERSION)+'. This Version has no Feature Selection Method because Feature Matrix is whole, not reduced.'+'\\n'+'SELECTION is therefore \"none\" by Default.')\n",
    "else: raise ValueError('mySELECTION must be chosen as either RF or PCA')\n",
    "print('You chose SELECTION method '+str(sel_feat)+'.')\n",
    "#print(sel_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) SUMMARY OF SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You chose VERSION 2. This Version has no Feature Selection Method because Feature Matrix is whole, not reduced.\n",
      "SELECTION is therefore \"none\" by Default. \n",
      "\n",
      "VERSION 2 is Based on whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features. \n",
      "\n",
      "You are now done with the Settings. You can run the whole Code now by Default.\n"
     ]
    }
   ],
   "source": [
    "print(briefing, '\\n')\n",
    "print('VERSION '+str(VERSION)+' is '+str(sel_version),'\\n')\n",
    "print('You are now done with the Settings. You can run the whole Code now by Default.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Import the Response Vector and the Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### NEW COMMENT\n",
    "# In version 1 und 2; ganze Feature matrix und ganzen Response vector rein? ODER gesplittet?\n",
    "# dann müsste in DataPrep split gemacht werden für datenset ohne feature pre-selection\n",
    "# abgespeichert in generated_splits ohne Unterordner\n",
    "# hier eingelesen als X_train und y_train und X_test und y_test\n",
    "#######################\n",
    "\n",
    "\n",
    "### import Data (already splitted to train/test-data and selected features-> bc_randomforest_feature_selection)\n",
    "if VERSION == 1: \n",
    "# features not pre-selected, only ratios\n",
    "    X = pd.read_csv('Data/generated_datasets/features_ratios_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "elif VERSION == 2: \n",
    "# features not pre-selected, ratios + seasonality + market data\n",
    "    X = pd.read_csv('Data/generated_datasets/features_additional_1.csv', sep=',', header=0)\n",
    "    y = pd.read_csv('Data/generated_datasets/response_1.csv', sep=',', header=0)\n",
    "elif VERSION == 1.1: \n",
    "# features pre-selected, only ratios\n",
    "    if SELECTION == 'RF':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X1_train_f.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X1_test_f.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y1_train_f.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y1_test_f.csv', sep=',', header=0)\n",
    "    elif SELECTION == 'PCA':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/X1_train_p.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/X1_test_p.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/y1_train_p.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/y1_test_p.csv', sep=',', header=0)\n",
    "elif VERSION == 2.1: \n",
    "# features pre-selected, ratios + seasonality + market data\n",
    "    if SELECTION == 'RF':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X2_train_f.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X2_test_f.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y2_train_f.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y2_test_f.csv', sep=',', header=0)\n",
    "    elif SELECTION == 'PCA':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/X2_train_p.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/X2_test_p.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/y2_train_p.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/y2_test_p.csv', sep=',', header=0)\n",
    "else: raise ValueError('VERSION value must be either 1, 2, 1.1 or 2.1, mySELECTION must be chosen as either RF or PCA.')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test-split for whole original files. Automatically executed only if VERSION = 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of feature_labels = <class 'list'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################### NEW COMMENT\n",
    "# Split could also be already done in Datapreparation file because there we have more space etc.^ maybe\n",
    "# but it can also be made here doesnt matterrr\n",
    "#######################\n",
    "\n",
    "# For VERSION == 1 or 2 -> train-test-split for the importet sets must be done\n",
    "if VERSION == 1 or VERSION == 2:\n",
    "    # import package imputer\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    # # Train/test split, into 20% test size and 80% train size because it is a relatively small dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Use a median fill for train\n",
    "    imp = Imputer(missing_values=np.nan, strategy = 'median' , axis=0)\n",
    "    imputed_dataset = pd.DataFrame(imp.fit_transform(X_train))\n",
    "    imputed_dataset.columns = X_train.columns\n",
    "    imputed_dataset.index = X_train.index\n",
    "    X_train = imputed_dataset\n",
    "\n",
    "    # Use a median fill for the test set\n",
    "    imputed_dataset = pd.DataFrame(imp.fit_transform(X_test))\n",
    "    imputed_dataset.columns = X_test.columns\n",
    "    imputed_dataset.index = X_test.index\n",
    "    X_test = imputed_dataset\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Create StandardScaler object\n",
    "    sc = StandardScaler()\n",
    "    # Standardize features; equal results as if done in two\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    # Transform test set\n",
    "    X_test = sc.transform(X_test)\n",
    "    # Extract the feature labels\n",
    "    feature_labels = list(X)\n",
    "    print('Type of feature_labels = ' + str(type(feature_labels)), '\\n')\n",
    "\n",
    "else: print('No Train/Test split, no Imputing, no Standardization needed for chosen VERSION '+str(VERSION)+\n",
    "            '. '+'\\n'+'Loaded Datasets were already pre-splitted and imputed in Feature Selection (Chapter 2).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Print out Shape and Form of Feature Matrix and Response Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected with No Feature Selection Method available..\n",
      "Version 2; Based on whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features. \n",
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Train) = (2836, 181)\n",
      "\n",
      "Feature Matrix X (Train) with no Feature pre-Selection:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.88e-02,  1.22e+00, -6.71e-01, -6.76e-01, -6.64e-01,  2.05e-01,\n",
       "         2.08e-01, -6.63e-01, -6.64e-01,  1.41e+00, -2.98e-01, -2.97e-01,\n",
       "        -6.64e-01,  2.81e-01,  1.22e+00,  2.38e-01,  7.54e-01,  7.50e-01,\n",
       "         5.43e-01,  5.49e-01,  7.56e-01,  2.77e-02,  5.67e-01, -8.05e-02,\n",
       "         1.24e-02, -4.05e-03,  1.18e-01,  1.56e-01,  1.08e+00, -8.67e-02,\n",
       "         3.55e-01,  9.59e-01,  1.28e+00,  8.44e-01,  1.72e+00,  7.88e-01,\n",
       "         1.26e+00, -5.32e-01, -8.40e-01, -7.02e-01,  4.68e-02, -4.13e-01,\n",
       "        -7.65e-01, -4.13e-01,  1.72e-02, -2.75e-01, -4.31e-01,  2.11e-01,\n",
       "        -1.36e-01, -2.66e-01, -1.63e-01, -6.02e-02, -5.85e-02,  6.96e-02,\n",
       "        -5.02e-01, -7.97e-01, -4.69e-02, -2.27e-01, -3.65e-01, -1.73e+00,\n",
       "         3.85e-01,  1.56e-01,  3.51e-01, -3.84e-01,  1.04e+00, -1.72e-01,\n",
       "        -2.73e-01, -1.96e-01, -4.45e-01, -3.06e-01, -1.34e-01, -1.09e-01,\n",
       "         1.43e+00,  1.54e+00,  1.55e+00,  4.13e-02, -5.20e-01, -9.66e-01,\n",
       "        -3.69e-01, -7.55e-01, -8.83e-01, -5.59e-01, -6.26e-02,  1.53e+00,\n",
       "         9.05e-01, -5.77e-01,  2.12e-01, -6.57e-01, -1.59e-01,  7.50e-01,\n",
       "         2.14e+00,  1.11e+00, -2.87e-01, -3.04e-01, -2.98e-01, -3.05e-01,\n",
       "        -3.01e-01, -3.02e-01, -3.03e-01,  3.26e+00, -3.03e-01, -3.04e-01,\n",
       "        -3.02e-01, -3.03e-01, -1.83e-01, -1.13e-01, -1.54e-01, -2.63e-01,\n",
       "        -1.86e-01,  2.99e+00, -6.52e-02, -1.34e-01, -8.64e-02, -1.68e-01,\n",
       "        -8.43e-02, -1.68e-01, -2.52e-01, -8.21e-02, -2.66e-02, -1.69e-01,\n",
       "        -1.92e-01, -7.53e-02, -1.90e-01, -1.63e-01, -1.80e-01, -1.23e-01,\n",
       "        -7.77e-02, -1.61e-01, -1.88e-01, -1.88e-01, -8.21e-02, -1.68e-01,\n",
       "        -7.77e-02, -1.88e-01, -1.27e-01, -1.17e-01, -1.56e-01, -8.43e-02,\n",
       "        -8.21e-02, -1.87e-01, -1.85e-01, -3.25e-02, -7.99e-02, -1.42e-01,\n",
       "        -1.68e-01, -1.51e-01, -1.18e-01,  4.08e-01, -4.08e-01,  0.00e+00,\n",
       "         0.00e+00, -1.86e-01, -1.97e-01, -1.90e-01, -1.89e-01, -1.82e-01,\n",
       "        -1.91e-01, -1.83e-01, -1.88e-01, -1.86e-01, -1.84e-01, -1.85e-01,\n",
       "        -1.77e-01, -1.80e-01, -1.92e-01, -1.71e-01, -1.88e-01, -1.92e-01,\n",
       "        -1.93e-01, -1.89e-01, -1.88e-01, -1.93e-01,  5.34e+00, -1.83e-01,\n",
       "        -1.82e-01, -1.85e-01, -1.85e-01, -1.87e-01, -1.86e-01, -1.56e-01,\n",
       "        -1.88e-01],\n",
       "       [-1.88e-02,  8.51e-01, -6.03e-01, -5.99e-01, -6.20e-01, -5.77e-01,\n",
       "        -9.51e-01, -6.20e-01, -6.20e-01, -6.10e-01, -2.98e-01, -2.97e-01,\n",
       "        -6.20e-01,  2.81e-01,  8.65e-01, -1.05e+00, -4.68e-01, -4.73e-01,\n",
       "        -3.56e-01, -3.72e-01, -4.54e-01,  2.31e-01,  2.16e-01, -3.45e-01,\n",
       "         1.53e-01,  1.00e-01,  9.72e-01,  1.01e+00, -1.02e+00, -2.20e-01,\n",
       "         3.36e+00, -1.45e+00, -1.10e+00, -1.16e+00, -1.28e+00, -1.46e+00,\n",
       "        -1.20e+00, -8.58e-01, -1.08e+00, -1.01e+00,  6.58e-01, -7.06e-01,\n",
       "        -1.07e+00, -6.85e-01, -1.64e-01, -1.36e+00, -8.72e-01, -9.64e-01,\n",
       "         5.69e-01,  3.83e-02,  5.81e-01, -5.81e-02, -5.62e-02, -6.91e-01,\n",
       "         8.99e-01,  1.02e+00,  4.71e-01,  4.50e-02, -8.53e-01, -1.50e+00,\n",
       "         9.71e-01, -6.96e-01, -8.08e-01, -8.58e-01, -1.19e+00, -3.33e-01,\n",
       "         1.03e-01,  3.84e-01,  3.41e-01, -1.53e-01, -1.61e-01, -1.26e-01,\n",
       "        -6.15e-01, -1.02e-01,  5.39e-01, -1.98e-01, -3.67e-01,  3.27e-02,\n",
       "        -3.35e-01,  7.68e-01, -9.12e-02,  1.29e-02, -5.48e-02, -2.10e-01,\n",
       "        -7.53e-01, -5.77e-01,  1.86e-01, -5.12e-01, -2.49e-01,  1.09e+00,\n",
       "         1.59e-01,  1.04e+00, -2.87e-01, -3.04e-01, -2.98e-01, -3.05e-01,\n",
       "        -3.01e-01,  3.31e+00, -3.03e-01, -3.07e-01, -3.03e-01, -3.04e-01,\n",
       "        -3.02e-01, -3.03e-01, -1.83e-01, -1.13e-01, -1.54e-01, -2.63e-01,\n",
       "         5.37e+00, -3.34e-01, -6.52e-02, -1.34e-01, -8.64e-02, -1.68e-01,\n",
       "        -8.43e-02, -1.68e-01, -2.52e-01, -8.21e-02, -2.66e-02, -1.69e-01,\n",
       "        -1.92e-01, -7.53e-02, -1.90e-01, -1.63e-01, -1.80e-01, -1.23e-01,\n",
       "        -7.77e-02, -1.61e-01, -1.88e-01, -1.88e-01, -8.21e-02, -1.68e-01,\n",
       "        -7.77e-02, -1.88e-01, -1.27e-01, -1.17e-01, -1.56e-01, -8.43e-02,\n",
       "        -8.21e-02, -1.87e-01, -1.85e-01, -3.25e-02, -7.99e-02, -1.42e-01,\n",
       "        -1.68e-01, -1.51e-01, -1.18e-01,  4.08e-01, -4.08e-01,  0.00e+00,\n",
       "         0.00e+00, -1.86e-01, -1.97e-01, -1.90e-01, -1.89e-01, -1.82e-01,\n",
       "        -1.91e-01, -1.83e-01, -1.88e-01,  5.37e+00, -1.84e-01, -1.85e-01,\n",
       "        -1.77e-01, -1.80e-01, -1.92e-01, -1.71e-01, -1.88e-01, -1.92e-01,\n",
       "        -1.93e-01, -1.89e-01, -1.88e-01, -1.93e-01, -1.87e-01, -1.83e-01,\n",
       "        -1.82e-01, -1.85e-01, -1.85e-01, -1.87e-01, -1.86e-01, -1.56e-01,\n",
       "        -1.88e-01],\n",
       "       [-1.88e-02,  1.19e+00, -2.35e-01, -2.45e-01, -2.35e-01, -6.36e-02,\n",
       "         2.41e-01, -2.34e-01, -2.35e-01,  4.06e-01, -2.98e-01, -2.97e-01,\n",
       "        -2.35e-01,  2.81e-01,  1.20e+00,  2.71e-01,  8.86e-01,  8.77e-01,\n",
       "         7.47e-01,  7.52e-01,  8.81e-01, -3.69e-01,  2.05e+00,  2.66e-01,\n",
       "        -5.00e-01, -4.07e-01, -1.05e-01, -6.78e-02, -8.65e-02, -8.21e-01,\n",
       "        -1.98e-01,  4.73e-01,  2.42e+00,  2.60e+00,  2.01e+00,  5.62e-01,\n",
       "         2.42e-01, -1.71e+00, -9.14e-01, -1.28e+00,  3.66e-01, -5.81e-01,\n",
       "        -1.66e+00, -5.85e-01,  4.16e-02, -1.26e-01, -1.55e+00, -9.56e-01,\n",
       "         9.96e-01,  1.46e+00,  9.44e-01, -5.96e-02, -5.81e-02, -1.51e-01,\n",
       "        -2.65e-01, -1.94e-01, -2.71e-03,  1.18e+00,  1.60e+00, -6.51e-02,\n",
       "        -9.56e-01, -1.44e-01, -1.64e-01, -1.03e+00,  1.35e+00,  4.23e+00,\n",
       "         2.50e-01,  1.71e+00,  1.82e+00,  1.40e+00, -1.24e-01, -1.03e-01,\n",
       "        -3.36e-01, -2.21e-01, -2.81e-01, -2.28e-01, -5.27e-01, -1.44e+00,\n",
       "        -6.05e-01, -1.40e+00, -1.10e+00, -6.05e-01, -5.31e-02, -7.23e-01,\n",
       "        -6.65e-02,  2.48e+00, -4.99e-02, -9.39e-01,  1.68e-01,  8.16e-02,\n",
       "        -2.65e-02,  1.08e-01, -2.87e-01,  3.29e+00, -2.98e-01, -3.05e-01,\n",
       "        -3.01e-01, -3.02e-01, -3.03e-01, -3.07e-01, -3.03e-01, -3.04e-01,\n",
       "        -3.02e-01, -3.03e-01, -1.83e-01, -1.13e-01, -1.54e-01, -2.63e-01,\n",
       "        -1.86e-01, -3.34e-01, -6.52e-02, -1.34e-01, -8.64e-02, -1.68e-01,\n",
       "        -8.43e-02, -1.68e-01, -2.52e-01, -8.21e-02, -2.66e-02, -1.69e-01,\n",
       "        -1.92e-01, -7.53e-02, -1.90e-01, -1.63e-01, -1.80e-01, -1.23e-01,\n",
       "        -7.77e-02, -1.61e-01, -1.88e-01, -1.88e-01, -8.21e-02, -1.68e-01,\n",
       "        -7.77e-02,  5.31e+00, -1.27e-01, -1.17e-01, -1.56e-01, -8.43e-02,\n",
       "        -8.21e-02, -1.87e-01, -1.85e-01, -3.25e-02, -7.99e-02, -1.42e-01,\n",
       "        -1.68e-01, -1.51e-01, -1.18e-01,  4.08e-01, -4.08e-01,  0.00e+00,\n",
       "         0.00e+00, -1.86e-01, -1.97e-01, -1.90e-01, -1.89e-01, -1.82e-01,\n",
       "        -1.91e-01, -1.83e-01, -1.88e-01, -1.86e-01, -1.84e-01, -1.85e-01,\n",
       "        -1.77e-01, -1.80e-01, -1.92e-01, -1.71e-01,  5.31e+00, -1.92e-01,\n",
       "        -1.93e-01, -1.89e-01, -1.88e-01, -1.93e-01, -1.87e-01, -1.83e-01,\n",
       "        -1.82e-01, -1.85e-01, -1.85e-01, -1.87e-01, -1.86e-01, -1.56e-01,\n",
       "        -1.88e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Train) after no Feature pre-Selection:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "1530  0\n",
       "1397  1\n",
       "2238  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print status\n",
    "print('Features Selected with ' + str(sel_feat)+'.')\n",
    "print('Version ' + str(VERSION) + '; ' + str(sel_version), '\\n')\n",
    "\n",
    "# print properties and head\n",
    "if VERSION == 1 or VERSION == 2:\n",
    "    print('Shape (rows, columns) of Feature Matrix X (Train) ' + '= ' + str(X_train.shape)+'\\n')\n",
    "    print('Feature Matrix X (Train) with no Feature pre-Selection:')\n",
    "    display(X_train[0:3])\n",
    "    print(\"\")\n",
    "    print('Response Vector y (Train) after no Feature pre-Selection:')\n",
    "    display(y_train[0:3])\n",
    "    print(\"\")\n",
    "else:\n",
    "    print('Shape (rows, columns) of Feature Matrix X (Train) ' + '= ' + str(X_train_s.shape), '\\n')\n",
    "    print('Feature Matrix X (Train) with Selected Features:'+'\\n')\n",
    "    display(X_train_s[0:3])\n",
    "    print(\"\")\n",
    "    print('Response Vector y (Train) after Feature Selection:')\n",
    "    display(y_train_s[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected with No Feature Selection Method available.\n",
      "Version 2; Based on whole original Dataset with Ratios + Seasonality + other Market Data as predictive Features. \n",
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Test) = (710, 181)\n",
      "\n",
      "Feature Matrix X (Test) with no Feature pre-Selection:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.88e-02,  1.22e+00,  4.88e-01,  4.22e-01,  4.52e-01,  2.72e+00,\n",
       "        -3.79e-01,  4.52e-01,  4.52e-01,  1.22e+00, -2.98e-01, -2.97e-01,\n",
       "         4.52e-01,  2.81e-01,  1.23e+00, -3.49e-01, -6.92e-01, -6.89e-01,\n",
       "        -9.73e-01, -9.75e-01, -4.66e-01,  3.75e-02, -6.29e-01, -4.71e-01,\n",
       "         6.56e-02,  3.30e-02,  2.49e-02,  6.28e-02,  8.07e-01, -3.81e-02,\n",
       "        -2.94e-01,  1.09e+00,  5.23e-01,  6.06e-01, -2.18e-01,  1.03e+00,\n",
       "         6.28e-01,  1.37e+00,  3.02e-01,  1.28e+00, -6.60e-02,  2.16e-01,\n",
       "         7.97e-01,  2.17e-01,  8.14e-01,  2.81e+00,  1.61e-01,  8.21e-01,\n",
       "        -7.62e-01, -6.86e-01, -7.83e-01, -6.25e-02, -6.01e-02,  3.19e-01,\n",
       "        -9.49e-01, -1.06e-01, -7.99e-01, -5.00e-01, -1.18e+00,  2.47e-01,\n",
       "        -2.79e-01,  7.87e-01,  1.31e+00,  1.78e+00,  7.28e-01, -2.38e-01,\n",
       "        -3.61e-01, -8.61e-01, -7.71e-01, -3.99e-01,  2.97e-01,  1.63e-01,\n",
       "         3.36e-01,  3.77e-01, -1.41e-02, -2.37e-01,  1.62e+00,  5.74e-02,\n",
       "        -1.67e-01, -3.86e-01, -1.78e-01, -3.20e-01, -5.10e-02, -2.10e-01,\n",
       "        -5.81e-01, -5.77e-01,  1.15e+00,  2.56e-01, -1.87e-01, -5.48e-01,\n",
       "         1.42e-01, -1.39e-01, -2.87e-01, -3.04e-01, -2.98e-01, -3.05e-01,\n",
       "        -3.01e-01, -3.02e-01, -3.03e-01, -3.07e-01,  3.30e+00, -3.04e-01,\n",
       "        -3.02e-01, -3.03e-01, -1.83e-01, -1.13e-01, -1.54e-01, -2.63e-01,\n",
       "        -1.86e-01, -3.34e-01, -6.52e-02, -1.34e-01, -8.64e-02, -1.68e-01,\n",
       "        -8.43e-02, -1.68e-01,  3.97e+00, -8.21e-02, -2.66e-02, -1.69e-01,\n",
       "        -1.92e-01, -7.53e-02, -1.90e-01, -1.63e-01, -1.80e-01, -1.23e-01,\n",
       "        -7.77e-02, -1.61e-01, -1.88e-01, -1.88e-01, -8.21e-02, -1.68e-01,\n",
       "        -7.77e-02, -1.88e-01, -1.27e-01, -1.17e-01, -1.56e-01, -8.43e-02,\n",
       "        -8.21e-02, -1.87e-01, -1.85e-01, -3.25e-02, -7.99e-02, -1.42e-01,\n",
       "        -1.68e-01, -1.51e-01, -1.18e-01, -2.45e+00,  2.45e+00,  0.00e+00,\n",
       "         0.00e+00, -1.86e-01,  5.07e+00, -1.90e-01, -1.89e-01, -1.82e-01,\n",
       "        -1.91e-01, -1.83e-01, -1.88e-01, -1.86e-01, -1.84e-01, -1.85e-01,\n",
       "        -1.77e-01, -1.80e-01, -1.92e-01, -1.71e-01, -1.88e-01, -1.92e-01,\n",
       "        -1.93e-01, -1.89e-01, -1.88e-01, -1.93e-01, -1.87e-01, -1.83e-01,\n",
       "        -1.82e-01, -1.85e-01, -1.85e-01, -1.87e-01, -1.86e-01, -1.56e-01,\n",
       "        -1.88e-01],\n",
       "       [-1.88e-02,  8.62e-01,  6.56e-02,  4.05e-02,  5.76e-02, -7.06e-01,\n",
       "         5.81e-01,  5.80e-02,  5.78e-02, -6.61e-01, -2.98e-01, -2.97e-01,\n",
       "         5.76e-02,  2.81e-01,  8.76e-01,  6.11e-01,  6.94e-01,  6.94e-01,\n",
       "         8.93e-01,  8.88e-01,  5.74e-01,  6.95e-02, -7.07e-01,  4.83e-01,\n",
       "         8.05e-02,  4.96e-02,  1.21e-01,  1.59e-01,  1.54e-01, -2.94e-01,\n",
       "        -4.64e-01,  1.32e-02,  1.19e-01,  2.93e-01, -9.12e-01,  8.19e-02,\n",
       "        -3.17e-01, -1.27e+00,  7.39e-02, -9.85e-01,  3.38e-01, -4.11e-02,\n",
       "        -8.95e-01, -4.08e-02,  4.26e-02, -1.44e-01, -1.43e+00, -1.65e+00,\n",
       "         1.83e+00,  7.48e-01,  1.77e+00, -6.25e-02, -6.02e-02, -4.09e-01,\n",
       "        -2.38e-01, -9.10e-02,  1.05e+00,  6.83e-01, -7.32e-01, -1.67e-01,\n",
       "         8.73e-01, -1.88e-01, -2.32e-01, -1.01e+00,  9.05e-01,  7.40e-01,\n",
       "         1.09e+00,  1.51e+00,  1.67e+00,  7.67e-01, -1.46e-01, -1.15e-01,\n",
       "        -4.77e-01, -2.60e-01, -4.18e-01,  1.78e-01, -3.77e-01, -1.10e+00,\n",
       "        -5.97e-01, -1.31e+00, -8.76e-01, -2.16e-01, -5.01e-02, -7.23e-01,\n",
       "        -7.53e-01,  1.47e+00, -2.38e-02,  2.92e-01, -1.65e-01, -1.05e+00,\n",
       "         1.95e-01, -7.37e-02, -2.87e-01, -3.04e-01, -2.98e-01, -3.05e-01,\n",
       "        -3.01e-01, -3.02e-01, -3.03e-01, -3.07e-01,  3.30e+00, -3.04e-01,\n",
       "        -3.02e-01, -3.03e-01, -1.83e-01, -1.13e-01, -1.54e-01, -2.63e-01,\n",
       "        -1.86e-01, -3.34e-01, -6.52e-02, -1.34e-01, -8.64e-02, -1.68e-01,\n",
       "        -8.43e-02, -1.68e-01, -2.52e-01, -8.21e-02, -2.66e-02, -1.69e-01,\n",
       "        -1.92e-01, -7.53e-02, -1.90e-01, -1.63e-01, -1.80e-01, -1.23e-01,\n",
       "        -7.77e-02, -1.61e-01, -1.88e-01, -1.88e-01, -8.21e-02, -1.68e-01,\n",
       "        -7.77e-02, -1.88e-01,  7.88e+00, -1.17e-01, -1.56e-01, -8.43e-02,\n",
       "        -8.21e-02, -1.87e-01, -1.85e-01, -3.25e-02, -7.99e-02, -1.42e-01,\n",
       "        -1.68e-01, -1.51e-01, -1.18e-01,  4.08e-01, -4.08e-01,  0.00e+00,\n",
       "         0.00e+00,  5.37e+00, -1.97e-01, -1.90e-01, -1.89e-01, -1.82e-01,\n",
       "        -1.91e-01, -1.83e-01, -1.88e-01, -1.86e-01, -1.84e-01, -1.85e-01,\n",
       "        -1.77e-01, -1.80e-01, -1.92e-01, -1.71e-01, -1.88e-01, -1.92e-01,\n",
       "        -1.93e-01, -1.89e-01, -1.88e-01, -1.93e-01, -1.87e-01, -1.83e-01,\n",
       "        -1.82e-01, -1.85e-01, -1.85e-01, -1.87e-01, -1.86e-01, -1.56e-01,\n",
       "        -1.88e-01],\n",
       "       [-1.88e-02, -2.39e-01, -8.29e-01, -8.17e-01, -8.32e-01,  1.51e+00,\n",
       "         2.34e-01, -8.31e-01, -8.31e-01,  2.09e+00, -2.98e-01, -2.97e-01,\n",
       "        -8.32e-01,  2.81e-01, -2.03e-01,  2.64e-01, -9.56e-01, -9.39e-01,\n",
       "        -3.25e-01, -3.08e-01, -9.59e-01, -1.81e-01,  4.29e-01, -8.25e-01,\n",
       "        -4.69e-01, -3.87e-01,  2.54e-03,  3.49e-02,  7.90e-01, -2.22e-01,\n",
       "         6.82e-01,  5.78e-01,  1.54e+00,  1.31e+00,  1.99e+00,  6.11e-01,\n",
       "         7.05e-01,  7.03e-02, -6.92e-01, -2.07e-01, -9.31e-01, -4.27e-01,\n",
       "        -5.65e-01, -4.27e-01,  7.97e-02, -3.00e-02, -1.85e-02,  2.52e-01,\n",
       "        -1.75e-01, -2.15e-01, -2.06e-01, -6.08e-02, -5.91e-02,  7.81e-01,\n",
       "        -6.64e-01, -7.82e-01,  1.36e-01, -2.74e-01,  7.26e-02, -7.25e-01,\n",
       "         5.74e-01, -7.50e-02,  4.16e-02,  3.52e-01,  1.05e+00, -2.56e-01,\n",
       "        -2.38e-01, -3.70e-01, -4.04e-01, -3.36e-01, -1.27e-01, -9.38e-02,\n",
       "         1.63e+00,  1.45e+00,  1.32e+00,  1.57e-01, -5.33e-01, -8.44e-01,\n",
       "        -4.03e-01, -8.92e-01, -8.19e-01, -5.32e-01, -6.29e-02,  1.96e+00,\n",
       "         7.91e-01, -5.77e-01,  9.71e-01, -5.08e-01, -1.87e-01,  6.64e-01,\n",
       "        -2.47e-01,  1.16e+00,  3.48e+00, -3.04e-01, -2.98e-01, -3.05e-01,\n",
       "        -3.01e-01, -3.02e-01, -3.03e-01, -3.07e-01, -3.03e-01, -3.04e-01,\n",
       "        -3.02e-01, -3.03e-01, -1.83e-01, -1.13e-01, -1.54e-01, -2.63e-01,\n",
       "        -1.86e-01,  2.99e+00, -6.52e-02, -1.34e-01, -8.64e-02, -1.68e-01,\n",
       "        -8.43e-02, -1.68e-01, -2.52e-01, -8.21e-02, -2.66e-02, -1.69e-01,\n",
       "        -1.92e-01, -7.53e-02, -1.90e-01, -1.63e-01, -1.80e-01, -1.23e-01,\n",
       "        -7.77e-02, -1.61e-01, -1.88e-01, -1.88e-01, -8.21e-02, -1.68e-01,\n",
       "        -7.77e-02, -1.88e-01, -1.27e-01, -1.17e-01, -1.56e-01, -8.43e-02,\n",
       "        -8.21e-02, -1.87e-01, -1.85e-01, -3.25e-02, -7.99e-02, -1.42e-01,\n",
       "        -1.68e-01, -1.51e-01, -1.18e-01,  4.08e-01, -4.08e-01,  0.00e+00,\n",
       "         0.00e+00, -1.86e-01, -1.97e-01, -1.90e-01, -1.89e-01, -1.82e-01,\n",
       "        -1.91e-01, -1.83e-01, -1.88e-01, -1.86e-01, -1.84e-01, -1.85e-01,\n",
       "        -1.77e-01, -1.80e-01, -1.92e-01, -1.71e-01, -1.88e-01, -1.92e-01,\n",
       "        -1.93e-01, -1.89e-01, -1.88e-01, -1.93e-01,  5.34e+00, -1.83e-01,\n",
       "        -1.82e-01, -1.85e-01, -1.85e-01, -1.87e-01, -1.86e-01, -1.56e-01,\n",
       "        -1.88e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Test) after no Feature pre-Selection:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "817   1\n",
       "2592  0\n",
       "1475  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print status\n",
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(VERSION) + '; ' + str(sel_version),'\\n')\n",
    "\n",
    "# print properties and head\n",
    "if VERSION == 1 or VERSION == 2:\n",
    "    print('Shape (rows, columns) of Feature Matrix X (Test) ' + '= ' + str(X_test.shape)+'\\n')\n",
    "    print('Feature Matrix X (Test) with no Feature pre-Selection:')\n",
    "    display(X_test[0:3])\n",
    "    print(\"\")\n",
    "    print('Response Vector y (Test) after no Feature pre-Selection:')\n",
    "    display(y_test[0:3])\n",
    "    print(\"\")\n",
    "else:\n",
    "    print('Shape (rows, columns) of Feature Matrix X (Test) ' + '= ' + str(X_test_s.shape)+'\\n')\n",
    "    print('Feature Matrix X (Test) with Selected Features:')\n",
    "    display(X_test_s[0:3])\n",
    "    print(\"\")\n",
    "    print('Response Vector y (Test) after Feature Selection:')\n",
    "    display(y_test_s[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERSION == 1 or VERSION == 2:\n",
    "    feature_train = X_train\n",
    "    feature_test = X_test\n",
    "    response_train = y_train\n",
    "    response_test = y_test\n",
    "if VERSION == 1.1 or VERSION == 2.1:\n",
    "    feature_train = X_train_s\n",
    "    feature_test = X_test_s\n",
    "    response_train = y_train_s\n",
    "    response_test = y_test_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. SVC\n",
    "\n",
    "### Two different SVC tests are applied:\n",
    "#### => SVC1 = rbf\n",
    "#### => SVC2 = linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Kernel: rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58 0.58 0.58 0.58 0.58]\n",
      "CV accuracy on train set:  0.583 +/-  0.001\n"
     ]
    }
   ],
   "source": [
    "# Import necessary functions\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create k-Fold CV and rbf object\n",
    "kFold = StratifiedKFold(n_splits =5, random_state =0)\n",
    "rbf = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, \n",
    "          decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
    "          max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "          tol=0.001, verbose=False)\n",
    "# Run CV and print results\n",
    "scores = cross_val_score(rbf, feature_train, response_train, cv= kFold)\n",
    "print(scores)\n",
    "print('CV accuracy on train set: {0: .3f} +/- {1: .3f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV  AUC on train set:  0.529 +/-  0.027\n"
     ]
    }
   ],
   "source": [
    "# ROC score\n",
    "scores = cross_val_score(rbf, feature_train, response_train, cv=kFold , scoring = 'roc_auc')\n",
    "print ('CV  AUC on train set: {0: .3f} +/- {1: .3f}'.format(np.mean(scores),   np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.22, 3.18, 3.2 , 3.21, 3.14]),\n",
       " 'score_time': array([2.1 , 2.11, 2.21, 2.2 , 2.08]),\n",
       " 'test_accuracy': array([0.58, 0.58, 0.58, 0.58, 0.58]),\n",
       " 'test_recall': array([1.  , 1.  , 0.99, 1.  , 1.  ]),\n",
       " 'test_roc_auc': array([0.54, 0.55, 0.48, 0.54, 0.53]),\n",
       " 'train_accuracy': array([1., 1., 1., 1., 1.]),\n",
       " 'train_recall': array([1., 1., 1., 1., 1.]),\n",
       " 'train_roc_auc': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# Calculate return\n",
    "measures = ['accuracy', 'recall', 'roc_auc']\n",
    "scores = cross_validate(rbf, feature_train, response_train, cv=kFold, scoring = measures, n_jobs =2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy (CV=5):  1.0\n",
      "Validation set scores (CV=5):  0.582862710881175\n",
      "Test set accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Train set accuracy (CV=5): ' ,scores ['train_accuracy'].mean())\n",
    "print('Validation set scores (CV=5): ',scores ['test_accuracy'].mean())\n",
    "print('Test set accuracy : ',rbf.fit(feature_test , response_test).score(feature_test, response_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred1 = rbf.fit(feature_train, response_train).predict(feature_test)\n",
    "display(y_pred1[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics of Classification with SVM1 (random parameters), kernel rbf:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       305\n",
      "          1       0.57      1.00      0.72       405\n",
      "\n",
      "avg / total       0.32      0.57      0.41       710\n",
      "\n",
      "\n",
      "Confusion Matrix with SVM1 (random parameters), kernel rbf:\n",
      "\n",
      "[[  0 305]\n",
      " [  2 403]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Metrics of Classification with SVM1 (random parameters), kernel rbf:')\n",
    "print(\"\")\n",
    "print(metrics.classification_report(response_test, y_pred1))\n",
    "print(\"\")\n",
    "print('Confusion Matrix with SVM1 (random parameters), kernel rbf:')\n",
    "print(\"\")\n",
    "print(metrics.confusion_matrix(response_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5692090395480226"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(response_test, y_pred1, labels=None, pos_label=1, average= 'binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950617283950617"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(response_test, y_pred1, labels=None, pos_label=1, average= 'binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Kernel: linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58 0.58 0.58 0.58 0.58]\n",
      "CV accuracy on train set:  0.583 +/-  0.001\n"
     ]
    }
   ],
   "source": [
    "# Import necessary functions\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create k-Fold CV and SVM (linear) object\n",
    "kFold = StratifiedKFold(n_splits =5, random_state =0)\n",
    "linear = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, \n",
    "          decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
    "          max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "          tol=0.001, verbose=False)\n",
    "# Run CV and print results\n",
    "scores = cross_val_score(linear, feature_train ,  response_train , cv= kFold )\n",
    "print(scores)\n",
    "print('CV accuracy on train set: {0: .3f} +/- {1: .3f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV  AUC on train set:  0.529 +/-  0.027\n"
     ]
    }
   ],
   "source": [
    "# ROC score\n",
    "scores = cross_val_score(linear, feature_train, response_train, cv=kFold , scoring = 'roc_auc')\n",
    "print ('CV  AUC on train set: {0: .3f} +/- {1: .3f}'.format(np.mean(scores),   np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.24, 3.22, 3.2 , 3.21, 3.2 ]),\n",
       " 'score_time': array([2.09, 2.09, 2.21, 2.23, 2.07]),\n",
       " 'test_accuracy': array([0.58, 0.58, 0.58, 0.58, 0.58]),\n",
       " 'test_recall': array([1.  , 1.  , 0.99, 1.  , 1.  ]),\n",
       " 'test_roc_auc': array([0.54, 0.55, 0.48, 0.54, 0.53]),\n",
       " 'train_accuracy': array([1., 1., 1., 1., 1.]),\n",
       " 'train_recall': array([1., 1., 1., 1., 1.]),\n",
       " 'train_roc_auc': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# Calculate return\n",
    "measures = ['accuracy', 'recall', 'roc_auc']\n",
    "scores = cross_validate(linear, feature_train, response_train, cv=kFold, scoring = measures, n_jobs =2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy (CV=5):  1.0\n",
      "Validation set scores (CV=5):  0.582862710881175\n",
      "Test set accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Train set accuracy (CV=5): ' ,scores ['train_accuracy'].mean())\n",
    "print('Validation set scores (CV=5): ',scores ['test_accuracy'].mean())\n",
    "print('Test set accuracy : ',linear.fit(feature_test , response_test).score(feature_test, response_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred2 = linear.fit(feature_train, response_train).predict(feature_test)\n",
    "display(y_pred1[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics of Classification with SVM1 (random parameters), kernel rbf:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       305\n",
      "          1       0.57      1.00      0.72       405\n",
      "\n",
      "avg / total       0.32      0.57      0.41       710\n",
      "\n",
      "\n",
      "Confusion Matrix with SVM1 (random parameters), kernel rbf:\n",
      "\n",
      "[[  0 305]\n",
      " [  2 403]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Metrics of Classification with SVM1 (random parameters), kernel rbf:')\n",
    "print(\"\")\n",
    "print(metrics.classification_report(response_test, y_pred2))\n",
    "print(\"\")\n",
    "print('Confusion Matrix with SVM1 (random parameters), kernel rbf:')\n",
    "print(\"\")\n",
    "print(metrics.confusion_matrix(response_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5692090395480226"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(response_test, y_pred2, labels=None, pos_label=1, average= 'binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950617283950617"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(response_test, y_pred2, labels=None, pos_label=1, average= 'binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
