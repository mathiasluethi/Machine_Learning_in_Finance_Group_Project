{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, UZH 2018, Group Project\n",
    "### Group 2: Barbara Capl, Mathias LÃ¼thi, Pamela Matias, Stefanie Rentsch\n",
    "##       \n",
    "# 3. Support Vector Machines (SVM)\n",
    "\n",
    "In this section we use the feature matrices and response vectors with features selected in chapter 2.  \n",
    "\n",
    "#### We use two different versions (created in chapter 1):\n",
    "Version 1: Feature Matrix consists only of the Ratios                                                                        \n",
    "Version 2: Feature Matrix consists of Ratios + dummy variables for seasonality + other market data\n",
    "####   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide unnecessary warnings (\"depreciation\" of packages etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Choose which Feature Matrix (Version 1 or 2) you want to load in by choosing the Case\n",
    "### Available are: Case 1 and Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If case = 1, Feature Matrix Version 1 is used (see description above below title)\n",
    "# If case = 2, feature matrix Version 2 is used (see description above below title)\n",
    "\n",
    "_CASE_ = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Import the Response Vector and the Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>pcf</th>\n",
       "      <th>divyield</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>evm</th>\n",
       "      <th>bm</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>ptb</th>\n",
       "      <th>aftret_equity</th>\n",
       "      <th>accrual</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>fcf_ocf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.773</td>\n",
       "      <td>9.957</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>18.484</td>\n",
       "      <td>10.644</td>\n",
       "      <td>0.547</td>\n",
       "      <td>15.633</td>\n",
       "      <td>5.963</td>\n",
       "      <td>15.468</td>\n",
       "      <td>1.811</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.048</td>\n",
       "      <td>18.484</td>\n",
       "      <td>13.678</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.089</td>\n",
       "      <td>8.509</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>39.232</td>\n",
       "      <td>9.246</td>\n",
       "      <td>0.461</td>\n",
       "      <td>17.296</td>\n",
       "      <td>5.702</td>\n",
       "      <td>17.203</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.047</td>\n",
       "      <td>39.232</td>\n",
       "      <td>1.521</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.337</td>\n",
       "      <td>1.993</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>13.062</td>\n",
       "      <td>12.474</td>\n",
       "      <td>0.911</td>\n",
       "      <td>9.209</td>\n",
       "      <td>2.248</td>\n",
       "      <td>9.135</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.038</td>\n",
       "      <td>13.062</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CAPEI    pcf  divyield  pe_inc     evm     bm  pe_op_dil  PEG_ltgforward  \\\n",
       "0  20.773  9.957    0.0354  18.484  10.644  0.547     15.633           5.963   \n",
       "1  25.089  8.509    0.0398  39.232   9.246  0.461     17.296           5.702   \n",
       "2  12.337  1.993    0.0268  13.062  12.474  0.911      9.209           2.248   \n",
       "\n",
       "   pe_op_basic    ptb  aftret_equity  accrual  pe_exi  PEG_1yrforward  fcf_ocf  \n",
       "0       15.468  1.811          0.134    0.048  18.484          13.678    0.932  \n",
       "1       17.203  2.189          0.058    0.047  39.232           1.521    0.441  \n",
       "2        9.135  1.076          0.086    0.038  13.062           0.380    1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Data (already splitted to train/test-data and selected features-> bc_randomforest_feature_selection)\n",
    "if _CASE_ == 1:\n",
    "    X_train_s = pd.read_csv('Data/generated_splits/X1_train_s.csv', sep=',', header=0)\n",
    "    X_test_s = pd.read_csv('Data/generated_splits/X1_test_s.csv', sep=',', header=0)\n",
    "    y_train_s = pd.read_csv('Data/generated_splits/y1_train_s.csv', sep=',', header=0)\n",
    "    y_test_s = pd.read_csv('Data/generated_splits/y1_test_s.csv', sep=',', header=0)\n",
    "elif _CASE_ == 2:\n",
    "    X_train_s = pd.read_csv('Data/generated_splits/X2_train_s.csv', sep=',', header=0)\n",
    "    X_test_s = pd.read_csv('Data/generated_splits/X2_test_s.csv', sep=',', header=0)\n",
    "    y_train_s = pd.read_csv('Data/generated_splits/y2_train_s.csv', sep=',', header=0)\n",
    "    y_test_s = pd.read_csv('Data/generated_splits/y2_test_s.csv', sep=',', header=0)\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n",
    "\n",
    "##### <==== WARUM?\n",
    "#X1_train_s = X1_train.set_index([\"PERMNO\", \"DATE\"])\n",
    "#y1_train_s = y1_train.set_index([\"PERMNO\", \"DATE\"])\n",
    "#X1_test_s = X1_train.set_index([\"PERMNO\", \"DATE\"])\n",
    "#y1_test_s = y1_train.set_index([\"PERMNO\", \"DATE\"])\n",
    "\n",
    "\n",
    "display(X_train_s.head(3))\n",
    "display(y_train_s.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column 1 from unnamed to index_number\n",
    "colNms_X_train = X_train_s.columns.values\n",
    "colNms_X_train[0] = \"index_number\"\n",
    "\n",
    "colNms_y_train = y_train_s.columns.values\n",
    "colNms_y_train[0] = \"index_number\"\n",
    "\n",
    "colNms_X_test = X_test_s.columns.values\n",
    "colNms_X_test[0] = \"index_number\"\n",
    "\n",
    "colNms_y_test = y_test_s.columns.values\n",
    "colNms_y_test[0] = \"index_number\"\n",
    "\n",
    "\n",
    "# set index\n",
    "X_train_s = X_train_s.set_index([\"index_number\"])\n",
    "y_train_s = y_train_s.set_index([\"index_number\"])\n",
    "X_test_s = X_test_s.set_index([\"index_number\"])\n",
    "y_test_s = y_test_s.set_index([\"index_number\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Print out Shape and Form of Feature Matrix and Response Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Train), Case 1  = (2836, 14)\n",
      "\n",
      "\n",
      "Feature Matrix X (Train) with selected Features, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcf</th>\n",
       "      <th>divyield</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>evm</th>\n",
       "      <th>bm</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>ptb</th>\n",
       "      <th>aftret_equity</th>\n",
       "      <th>accrual</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>fcf_ocf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20.773</th>\n",
       "      <td>9.957</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>18.484</td>\n",
       "      <td>10.644</td>\n",
       "      <td>0.547</td>\n",
       "      <td>15.633</td>\n",
       "      <td>5.963</td>\n",
       "      <td>15.468</td>\n",
       "      <td>1.811</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.048</td>\n",
       "      <td>18.484</td>\n",
       "      <td>13.678</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.089</th>\n",
       "      <td>8.509</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>39.232</td>\n",
       "      <td>9.246</td>\n",
       "      <td>0.461</td>\n",
       "      <td>17.296</td>\n",
       "      <td>5.702</td>\n",
       "      <td>17.203</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.047</td>\n",
       "      <td>39.232</td>\n",
       "      <td>1.521</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.337</th>\n",
       "      <td>1.993</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>13.062</td>\n",
       "      <td>12.474</td>\n",
       "      <td>0.911</td>\n",
       "      <td>9.209</td>\n",
       "      <td>2.248</td>\n",
       "      <td>9.135</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.038</td>\n",
       "      <td>13.062</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pcf  divyield  pe_inc     evm     bm  pe_op_dil  \\\n",
       "index_number                                                      \n",
       "20.773        9.957    0.0354  18.484  10.644  0.547     15.633   \n",
       "25.089        8.509    0.0398  39.232   9.246  0.461     17.296   \n",
       "12.337        1.993    0.0268  13.062  12.474  0.911      9.209   \n",
       "\n",
       "              PEG_ltgforward  pe_op_basic    ptb  aftret_equity  accrual  \\\n",
       "index_number                                                               \n",
       "20.773                 5.963       15.468  1.811          0.134    0.048   \n",
       "25.089                 5.702       17.203  2.189          0.058    0.047   \n",
       "12.337                 2.248        9.135  1.076          0.086    0.038   \n",
       "\n",
       "              pe_exi  PEG_1yrforward  fcf_ocf  \n",
       "index_number                                   \n",
       "20.773        18.484          13.678    0.932  \n",
       "25.089        39.232           1.521    0.441  \n",
       "12.337        13.062           0.380    1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Train) after Feature Selection, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [1, 0, 1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Shape (rows, columns) of Feature Matrix X (Train), Case ' + str(_CASE_), ' = ' + str(X_train_s.shape))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print('Feature Matrix X (Train) with selected Features, Case ' + str(_CASE_))\n",
    "display(X_train_s.head(3))\n",
    "print(\"\")\n",
    "print('Response Vector y (Train) after Feature Selection, Case ' + str(_CASE_))\n",
    "display(y_train_s.head(3))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Test), Case 1  = (710, 14)\n",
      "\n",
      "Feature Matrix X (Test) with selected Features, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcf</th>\n",
       "      <th>divyield</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>evm</th>\n",
       "      <th>bm</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>ptb</th>\n",
       "      <th>aftret_equity</th>\n",
       "      <th>accrual</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>fcf_ocf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20.983</th>\n",
       "      <td>10.484</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>16.224</td>\n",
       "      <td>8.585</td>\n",
       "      <td>0.254</td>\n",
       "      <td>16.224</td>\n",
       "      <td>1.330</td>\n",
       "      <td>16.127</td>\n",
       "      <td>4.189</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.084</td>\n",
       "      <td>16.224</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.663</th>\n",
       "      <td>7.709</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>18.555</td>\n",
       "      <td>13.619</td>\n",
       "      <td>0.235</td>\n",
       "      <td>16.489</td>\n",
       "      <td>1.572</td>\n",
       "      <td>16.311</td>\n",
       "      <td>4.281</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.039</td>\n",
       "      <td>18.555</td>\n",
       "      <td>1.737</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.327</th>\n",
       "      <td>8.490</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>15.550</td>\n",
       "      <td>6.716</td>\n",
       "      <td>0.513</td>\n",
       "      <td>9.520</td>\n",
       "      <td>6.149</td>\n",
       "      <td>9.520</td>\n",
       "      <td>2.198</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.077</td>\n",
       "      <td>15.681</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pcf  divyield  pe_inc     evm     bm  pe_op_dil  \\\n",
       "index_number                                                       \n",
       "20.983        10.484    0.0187  16.224   8.585  0.254     16.224   \n",
       "21.663         7.709    0.0122  18.555  13.619  0.235     16.489   \n",
       "16.327         8.490    0.0343  15.550   6.716  0.513      9.520   \n",
       "\n",
       "              PEG_ltgforward  pe_op_basic    ptb  aftret_equity  accrual  \\\n",
       "index_number                                                               \n",
       "20.983                 1.330       16.127  4.189          0.310    0.084   \n",
       "21.663                 1.572       16.311  4.281          0.238    0.039   \n",
       "16.327                 6.149        9.520  2.198          0.130    0.077   \n",
       "\n",
       "              pe_exi  PEG_1yrforward  fcf_ocf  \n",
       "index_number                                   \n",
       "20.983        16.224           1.414    0.863  \n",
       "21.663        18.555           1.737    0.902  \n",
       "16.327        15.681          -0.973    0.934  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Test) after Feature Selection, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Shape (rows, columns) of Feature Matrix X (Test), Case ' + str(_CASE_), ' = ' + str(X_test_s.shape))\n",
    "print(\"\")\n",
    "print('Feature Matrix X (Test) with selected Features, Case ' + str(_CASE_))\n",
    "display(X_test_s.head(3))\n",
    "print(\"\")\n",
    "print('Response Vector y (Test) after Feature Selection, Case ' + str(_CASE_))\n",
    "display(y_test_s.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. SVM\n",
    "\n",
    "### Two different SVM tests are applied:\n",
    "#### => SVM1 = SVM with random parameters\n",
    "#### => SVM2 = SVM with other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. SVM1 : SVM with random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "# Standardscaler standardizes the input variables\n",
    "pipe1 = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('classifier', SVC(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid1 = [{'scaler': [StandardScaler()],\n",
    "               'classifier': [SVC(kernel='rbf')],\n",
    "               'classifier__gamma': [1, 10],\n",
    "               'classifier__C': [10, 100]},\n",
    "              {'scaler': [StandardScaler(), None],\n",
    "               'classifier': [LogisticRegression()],\n",
    "               'classifier__C': [10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f010f399660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f010f399660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 14, 10, 13, 696817, tzinfo=tzutc()), 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'session': '8123667debb042868e72eba50c37011a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'8123667debb042868e72eba50c37011a']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 14, 10, 13, 696817, tzinfo=tzutc()), 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'session': '8123667debb042868e72eba50c37011a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'8123667debb042868e72eba50c37011a'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 14, 10, 13, 696817, tzinfo=tzutc()), 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'session': '8123667debb042868e72eba50c37011a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-9-3f610dc7ff24>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f010f371710, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f00d25e15d0, file \"<ipython-input-9-3f610dc7ff24>\", line 3>\n        result = <ExecutionResult object at 7f010f371710, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f00d25e15d0, file \"<ipython-input-9-3f610dc7ff24>\", line 3>, result=<ExecutionResult object at 7f010f371710, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f00d25e15d0, file \"<ipython-input-9-3f610dc7ff24>\", line 3>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...m sklearn.model_selection import train_test_split', '# If case = 1, Feature Matrix Version 1 is used ...d (see description above below title)\\n\\n_CASE_ = 1', '# import Data (already splitted to train/test-da...lay(X_train_s.head(3))\\ndisplay(y_train_s.head(3))', '# rename column 1 from unnamed to index_number\\nc...)\\ny_test_s = y_test_s.set_index([\"index_number\"])', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur...str(_CASE_))\\ndisplay(y_train_s.head(3))\\nprint(\"\")', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur..., Case \\' + str(_CASE_))\\ndisplay(y_test_s.head(3))', \"# Create pipeline object with standard scaler an...            ('classifier', SVC(random_state=0))])\", \"# Define parameter grid\\nparam_grid1 = [{'scaler'...n()],\\n               'classifier__C': [10, 100]}]\", '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X_test_s':                  pcf  divyield  pe_inc     evm  ...       1.130  0.768000  \n\n[710 rows x 14 columns], 'X_train_s':                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], '_': '', ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...m sklearn.model_selection import train_test_split', '# If case = 1, Feature Matrix Version 1 is used ...d (see description above below title)\\n\\n_CASE_ = 1', '# import Data (already splitted to train/test-da...lay(X_train_s.head(3))\\ndisplay(y_train_s.head(3))', '# rename column 1 from unnamed to index_number\\nc...)\\ny_test_s = y_test_s.set_index([\"index_number\"])', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur...str(_CASE_))\\ndisplay(y_train_s.head(3))\\nprint(\"\")', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur..., Case \\' + str(_CASE_))\\ndisplay(y_test_s.head(3))', \"# Create pipeline object with standard scaler an...            ('classifier', SVC(random_state=0))])\", \"# Define parameter grid\\nparam_grid1 = [{'scaler'...n()],\\n               'classifier__C': [10, 100]}]\", '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X_test_s':                  pcf  divyield  pe_inc     evm  ...       1.130  0.768000  \n\n[710 rows x 14 columns], 'X_train_s':                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], '_': '', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/andy/barbara/github_ml_uzh/Machine_Learning_in_Finance_Group_Project/<ipython-input-9-3f610dc7ff24> in <module>()\n      1 # Run grid search\n      2 grid1 = GridSearchCV(pipe1, param_grid1, cv=5, n_jobs=-1)\n----> 3 grid1.fit(X_train_s, y_train_s)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=                    pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns]\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Apr  9 16:10:14 2018\nPID: 7047                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                    pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 568,  569,  570, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), verbose=0, parameters={'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train =                      pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns]\n        y_train = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                     pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseLibSVM.fit of SVC(C=10, cache_...one, shrinking=True,\n  tol=0.001, verbose=False)>\n        Xt = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in fit(self=SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], sample_weight=None)\n    144         sparse = sp.isspmatrix(X)\n    145         if sparse and self.kernel == \"precomputed\":\n    146             raise TypeError(\"Sparse precomputed kernels are not supported.\")\n    147         self._sparse = sparse and not callable(self.kernel)\n    148 \n--> 149         X, y = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')\n        X = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    150         y = self._validate_targets(y)\n    151 \n    152         sample_weight = np.asarray([]\n    153                                    if sample_weight is None\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    573                     ensure_min_features, warn_on_dtype, estimator)\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n--> 578         y = column_or_1d(y, warn=True)\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    579         _assert_all_finite(y)\n    580     if y_numeric and y.dtype.kind == 'O':\n    581         y = y.astype(np.float64)\n    582 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (2268, 0)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (2268, 0)\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0mTraceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 250, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\", line 149, in fit\n    X, y = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 578, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 614, in column_or_1d\n    raise ValueError(\"bad input shape {0}\".format(shape))\nValueError: bad input shape (2268, 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/andy/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Apr  9 16:10:14 2018\nPID: 7047                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                    pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 568,  569,  570, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), verbose=0, parameters={'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train =                      pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns]\n        y_train = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                     pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseLibSVM.fit of SVC(C=10, cache_...one, shrinking=True,\n  tol=0.001, verbose=False)>\n        Xt = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in fit(self=SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], sample_weight=None)\n    144         sparse = sp.isspmatrix(X)\n    145         if sparse and self.kernel == \"precomputed\":\n    146             raise TypeError(\"Sparse precomputed kernels are not supported.\")\n    147         self._sparse = sparse and not callable(self.kernel)\n    148 \n--> 149         X, y = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')\n        X = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    150         y = self._validate_targets(y)\n    151 \n    152         sample_weight = np.asarray([]\n    153                                    if sample_weight is None\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    573                     ensure_min_features, warn_on_dtype, estimator)\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n--> 578         y = column_or_1d(y, warn=True)\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    579         _assert_all_finite(y)\n    580     if y_numeric and y.dtype.kind == 'O':\n    581         y = y.astype(np.float64)\n    582 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (2268, 0)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (2268, 0)\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Apr  9 16:10:14 2018\nPID: 7047                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                    pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 568,  569,  570, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), verbose=0, parameters={'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train =                      pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns]\n        y_train = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                     pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseLibSVM.fit of SVC(C=10, cache_...one, shrinking=True,\n  tol=0.001, verbose=False)>\n        Xt = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in fit(self=SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], sample_weight=None)\n    144         sparse = sp.isspmatrix(X)\n    145         if sparse and self.kernel == \"precomputed\":\n    146             raise TypeError(\"Sparse precomputed kernels are not supported.\")\n    147         self._sparse = sparse and not callable(self.kernel)\n    148 \n--> 149         X, y = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')\n        X = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    150         y = self._validate_targets(y)\n    151 \n    152         sample_weight = np.asarray([]\n    153                                    if sample_weight is None\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    573                     ensure_min_features, warn_on_dtype, estimator)\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n--> 578         y = column_or_1d(y, warn=True)\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    579         _assert_all_finite(y)\n    580     if y_numeric and y.dtype.kind == 'O':\n    581         y = y.astype(np.float64)\n    582 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (2268, 0)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (2268, 0)\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f610dc7ff24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgrid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f010f399660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f010f399660, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andy/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andy/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 14, 10, 13, 696817, tzinfo=tzutc()), 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'session': '8123667debb042868e72eba50c37011a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'8123667debb042868e72eba50c37011a']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 14, 10, 13, 696817, tzinfo=tzutc()), 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'session': '8123667debb042868e72eba50c37011a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'8123667debb042868e72eba50c37011a'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 14, 10, 13, 696817, tzinfo=tzutc()), 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'session': '8123667debb042868e72eba50c37011a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '282215d2d3fe477bb69b344a252c87c9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-9-3f610dc7ff24>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f010f371710, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f00d25e15d0, file \"<ipython-input-9-3f610dc7ff24>\", line 3>\n        result = <ExecutionResult object at 7f010f371710, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f00d25e15d0, file \"<ipython-input-9-3f610dc7ff24>\", line 3>, result=<ExecutionResult object at 7f010f371710, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f00d25e15d0, file \"<ipython-input-9-3f610dc7ff24>\", line 3>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...m sklearn.model_selection import train_test_split', '# If case = 1, Feature Matrix Version 1 is used ...d (see description above below title)\\n\\n_CASE_ = 1', '# import Data (already splitted to train/test-da...lay(X_train_s.head(3))\\ndisplay(y_train_s.head(3))', '# rename column 1 from unnamed to index_number\\nc...)\\ny_test_s = y_test_s.set_index([\"index_number\"])', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur...str(_CASE_))\\ndisplay(y_train_s.head(3))\\nprint(\"\")', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur..., Case \\' + str(_CASE_))\\ndisplay(y_test_s.head(3))', \"# Create pipeline object with standard scaler an...            ('classifier', SVC(random_state=0))])\", \"# Define parameter grid\\nparam_grid1 = [{'scaler'...n()],\\n               'classifier__C': [10, 100]}]\", '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X_test_s':                  pcf  divyield  pe_inc     evm  ...       1.130  0.768000  \n\n[710 rows x 14 columns], 'X_train_s':                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], '_': '', ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', '# hide unnecessary warnings (\"depreciation\" of p...m sklearn.model_selection import train_test_split', '# If case = 1, Feature Matrix Version 1 is used ...d (see description above below title)\\n\\n_CASE_ = 1', '# import Data (already splitted to train/test-da...lay(X_train_s.head(3))\\ndisplay(y_train_s.head(3))', '# rename column 1 from unnamed to index_number\\nc...)\\ny_test_s = y_test_s.set_index([\"index_number\"])', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur...str(_CASE_))\\ndisplay(y_train_s.head(3))\\nprint(\"\")', 'print(\"\")\\nprint(\\'Shape (rows, columns) of Featur..., Case \\' + str(_CASE_))\\ndisplay(y_test_s.head(3))', \"# Create pipeline object with standard scaler an...            ('classifier', SVC(random_state=0))])\", \"# Define parameter grid\\nparam_grid1 = [{'scaler'...n()],\\n               'classifier__C': [10, 100]}]\", '# Run grid search\\ngrid1 = GridSearchCV(pipe1, pa... cv=5, n_jobs=-1)\\ngrid1.fit(X_train_s, y_train_s)'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X_test_s':                  pcf  divyield  pe_inc     evm  ...       1.130  0.768000  \n\n[710 rows x 14 columns], 'X_train_s':                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], '_': '', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/andy/barbara/github_ml_uzh/Machine_Learning_in_Finance_Group_Project/<ipython-input-9-3f610dc7ff24> in <module>()\n      1 # Run grid search\n      2 grid1 = GridSearchCV(pipe1, param_grid1, cv=5, n_jobs=-1)\n----> 3 grid1.fit(X_train_s, y_train_s)\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=                    pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns]\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Apr  9 16:10:14 2018\nPID: 7047                     Python 3.6.4: /home/andy/anaconda3/bin/python\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]),                     pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], {'score': <function _passthrough_scorer>}, array([ 568,  569,  570, ..., 2833, 2834, 2835]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), 0, {'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                    pcf  divyield     pe_inc    ...   -1.861000  0.55700  \n\n[2836 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 0, 1, 1, ..., 0, 0, 1, 1, 1, 1, ...]\n\n[2836 rows x 0 columns], scorer={'score': <function _passthrough_scorer>}, train=array([ 568,  569,  570, ..., 2833, 2834, 2835]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    559, 560, 561, 562, 563, 564, 565, 566, 567]), verbose=0, parameters={'classifier': SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 1, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train =                      pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns]\n        y_train = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scaler', Sta...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=                     pcf  divyield     pe_inc   ...   -1.861000  0.55700  \n\n[2268 rows x 14 columns], y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseLibSVM.fit of SVC(C=10, cache_...one, shrinking=True,\n  tol=0.001, verbose=False)>\n        Xt = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in fit(self=SVC(C=10, cache_size=200, class_weight=None, coe...None, shrinking=True,\n  tol=0.001, verbose=False), X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], sample_weight=None)\n    144         sparse = sp.isspmatrix(X)\n    145         if sparse and self.kernel == \"precomputed\":\n    146             raise TypeError(\"Sparse precomputed kernels are not supported.\")\n    147         self._sparse = sparse and not callable(self.kernel)\n    148 \n--> 149         X, y = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')\n        X = array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]])\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    150         y = self._validate_targets(y)\n    151 \n    152         sample_weight = np.asarray([]\n    153                                    if sample_weight is None\n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([[-1.13696126e+01, -1.56720660e+00, -2.497...49480175e-01, -3.98922196e-01, -6.70093907e-01]]), y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    573                     ensure_min_features, warn_on_dtype, estimator)\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n--> 578         y = column_or_1d(y, warn=True)\n        y = Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns]\n    579         _assert_all_finite(y)\n    580     if y_numeric and y.dtype.kind == 'O':\n    581         y = y.astype(np.float64)\n    582 \n\n...........................................................................\n/home/andy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=Empty DataFrame\nColumns: []\nIndex: [1, 1, 1, 1, ..., 1, 1, 0, 0, 0, 0, ...]\n\n[2268 rows x 0 columns], warn=True)\n    609                           \" expected. Please change the shape of y to \"\n    610                           \"(n_samples, ), for example using ravel().\",\n    611                           DataConversionWarning, stacklevel=2)\n    612         return np.ravel(y)\n    613 \n--> 614     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (2268, 0)\n    615 \n    616 \n    617 def check_random_state(seed):\n    618     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (2268, 0)\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# Run grid search\n",
    "grid1 = GridSearchCV(pipe1, param_grid1, cv=5, n_jobs=-1)\n",
    "grid1.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"\")\n",
    "print('Best CV accuracy: {:.2f}'.format(grid1.best_score_))\n",
    "print('Test score:       {:.2f}'.format(grid1.score(X_test_s, y_test_s)))\n",
    "print(\"\")\n",
    "print('Best parameters: {}'.format(grid1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes\n",
    "y_pred1 = grid1.predict(X_test_s)\n",
    "display(y_pred1[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print('Metrics of Classification with SVM1 (random parameters), kernel rbf:')\n",
    "print(\"\")\n",
    "print(metrics.classification_report(y_test_s, y_pred1))\n",
    "print(metrics.confusion_matrix(y_test_s, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. SVM2 : SVM with other \n",
    "\n",
    "### Kernel: linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "# Standardscaler standardizes the input variables\n",
    "pipe2 = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('classifier', SVC(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid2 = [{'scaler': [StandardScaler()],\n",
    "               'classifier': [SVC(kernel='linear')],\n",
    "               'classifier__gamma': [1, 10],\n",
    "               'classifier__C': [10, 100]},\n",
    "              {'scaler': [StandardScaler(), None],\n",
    "               'classifier': [LogisticRegression()],\n",
    "               'classifier__C': [10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search\n",
    "grid2 = GridSearchCV(pipe2, param_grid2, cv=5, n_jobs=-1)\n",
    "grid2.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"\")\n",
    "print('Best CV accuracy: {:.2f}'.format(grid2.best_score_))\n",
    "print('Test score:       {:.2f}'.format(grid2.score(X_test_s, y_test_s)))\n",
    "print(\"\")\n",
    "print('Best parameters: {}'.format(grid2.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict   classes\n",
    "y_pred2 = grid2.predict(X_test_s)\n",
    "display(y_pred2[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print('Metrics of Classification with SVM2 (random parameters), kernel linear:')\n",
    "print(\"\")\n",
    "print(metrics.classification_report(y_test_s, y_pred2))\n",
    "print(metrics.confusion_matrix(y_test_s, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline object with standard scaler and SVC estimator\n",
    "pipe3 = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('classifier', SVC(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid3 = [{'scaler': [StandardScaler()],\n",
    "               'classifier': [SVC(kernel= \"poly\")],\n",
    "               'classifier__gamma': [1, 10],\n",
    "               'classifier__C': [10, 100]},\n",
    "              {'scaler': [StandardScaler(), None],\n",
    "               'classifier': [LogisticRegression()],\n",
    "               s'classifier__C': [10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search\n",
    "grid3 = GridSearchCV(pipe3, param_grid3, cv=5, n_jobs=-1)\n",
    "grid3.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"\")\n",
    "print('Best CV accuracy: {:.2f}'.format(grid3.best_score_))\n",
    "print('Test score:       {:.2f}'.format(grid3.score(X_test_s, y_test_s)))\n",
    "print(\"\")\n",
    "print('Best parameters: {}'.format(grid3.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict   classes\n",
    "y_pred3 = grid3.predict(X_test_s)\n",
    "display(y_pred3[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print('Metrics of Classification with SVM2 (random parameters), kernel poly:')\n",
    "print(\"\")\n",
    "print(metrics.classification_report(y_test_s, y_pred3))\n",
    "print(metrics.confusion_matrix(y_test_s, y_pred3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
