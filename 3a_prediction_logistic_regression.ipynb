{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, UZH 2018, Group Project\n",
    "### Group 2: Barbara Capl, Mathias LÃ¼thi, Pamela Matias, Stefanie Rentsch\n",
    "##       \n",
    "# 3. Prediction with Multiple Logistic Regression\n",
    "\n",
    "In this section we use the feature matrices and response vectors with features selected in chapter 2.  \n",
    "\n",
    "#### We use two different versions (created in chapter 1, features-selected in chapter 2):\n",
    "Version 1: Feature Matrix consists only of the Ratios                                                                        \n",
    "Version 2: Feature Matrix consists of Ratios + dummy variables for seasonality + other market data\n",
    "####  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide unnecessary warnings (\"depreciation\" of packages etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Choose which Feature Matrix (Version 1 or 2) you want to load in by choosing the Case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Choose the Dataset Version you want\n",
    "VERSION = 1; Feature Matrix with only ratios                                  \n",
    "VERSION = 2;  Feature Matrix with ratios + saisonality + other market data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chose which dataset version you want the selection of features and the prediction to be based on \n",
    "_VERSION_ = 2\n",
    "\"\"\"\n",
    "INSERT NUMBER 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define sel_state variable for easier printing out    \n",
    "if _VERSION_ == 1:\n",
    "    sel_version = 'Based on Dataset with only the Ratios Dataset as predicive Features'\n",
    "elif _VERSION_ == 2:\n",
    "    sel_version = 'Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features'\n",
    "else: raise ValueError('_VALUE_ must be either 1 or 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Choose with which method you want to have the features been pre-selected\n",
    "SELECTON  = RF ; Features pre-selected with Random Forest Classifier                                                           \n",
    "SELECTION = PCA; Features pre-selected with Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose whether you want the datasets with features selected with RF or PCA\n",
    "_SELECTION_ = 'RF'\n",
    "\"\"\"\n",
    "INSERT 'RF' OR 'PCA'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define sel_state variable for easier printing out    \n",
    "if _SELECTION_ == 'RF':\n",
    "    sel_feat = 'Random Forest (RF)'\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    sel_feat = 'Principal Component Analysis (PCA)'\n",
    "else: raise ValueError('_SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Import the Response Vector and the Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Data (already splitted to train/test-data and selected features-> bc_randomforest_feature_selection)\n",
    "if _VERSION_ == 1:\n",
    "    if _SELECTION_ == 'RF':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X1_train_f.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X1_test_f.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y1_train_f.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y1_test_f.csv', sep=',', header=0)\n",
    "    elif _SELECTION_ == 'PCA':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/X1_train_p.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/X1_test_p.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/y1_train_p.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/y1_test_p.csv', sep=',', header=0)\n",
    "elif _VERSION_ == 2:\n",
    "    if _SELECTION_ == 'RF':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X2_train_f.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/X2_test_f.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y2_train_f.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_randomforest/y2_test_f.csv', sep=',', header=0)\n",
    "    elif _SELECTION_ == 'PCA':\n",
    "        X_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/X2_train_p.csv', sep=',', header=0)\n",
    "        X_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/X2_test_p.csv', sep=',', header=0)\n",
    "        y_train_s = pd.read_csv('Data/generated_splits/features_selected_pca/y2_train_p.csv', sep=',', header=0)\n",
    "        y_test_s = pd.read_csv('Data/generated_splits/features_selected_pca/y2_test_p.csv', sep=',', header=0)\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Print out Shape and Form of Feature Matrix and Response Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected with Random Forest (RF)\n",
      "Version 2; Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features\n",
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Train) =(2836, 15)\n",
      "\n",
      "Feature Matrix X (Train) with Selected Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RET</th>\n",
       "      <th>RETX</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>ewretd</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>ALTPRC</th>\n",
       "      <th>debt_ebitda</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>ps</th>\n",
       "      <th>SHRENDDT</th>\n",
       "      <th>VOL</th>\n",
       "      <th>int_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024042</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.038183</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>18.484</td>\n",
       "      <td>15.633</td>\n",
       "      <td>29.39</td>\n",
       "      <td>1.704</td>\n",
       "      <td>1.4810</td>\n",
       "      <td>3.703</td>\n",
       "      <td>20140929.0</td>\n",
       "      <td>4611190.0</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.057168</td>\n",
       "      <td>-0.066454</td>\n",
       "      <td>-0.014999</td>\n",
       "      <td>-0.015631</td>\n",
       "      <td>-0.017055</td>\n",
       "      <td>-0.013012</td>\n",
       "      <td>39.232</td>\n",
       "      <td>17.296</td>\n",
       "      <td>32.17</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.689</td>\n",
       "      <td>20130730.0</td>\n",
       "      <td>1296447.0</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026373</td>\n",
       "      <td>0.026373</td>\n",
       "      <td>0.043117</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>0.043937</td>\n",
       "      <td>0.044257</td>\n",
       "      <td>13.062</td>\n",
       "      <td>9.209</td>\n",
       "      <td>56.82</td>\n",
       "      <td>8.714</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>2.034</td>\n",
       "      <td>20140330.0</td>\n",
       "      <td>3473222.0</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RET      RETX    sprtrn    ewretx    vwretx    ewretd  pe_inc  \\\n",
       "0  0.024042  0.024042  0.037655  0.032156  0.038183  0.033697  18.484   \n",
       "1 -0.057168 -0.066454 -0.014999 -0.015631 -0.017055 -0.013012  39.232   \n",
       "2  0.026373  0.026373  0.043117  0.042687  0.043937  0.044257  13.062   \n",
       "\n",
       "   pe_op_dil  ALTPRC  debt_ebitda  cash_ratio     ps    SHRENDDT        VOL  \\\n",
       "0     15.633   29.39        1.704      1.4810  3.703  20140929.0  4611190.0   \n",
       "1     17.296   32.17        3.055      0.3210  0.689  20130730.0  1296447.0   \n",
       "2      9.209   56.82        8.714      0.4785  2.034  20140330.0  3473222.0   \n",
       "\n",
       "   int_debt  \n",
       "0     0.045  \n",
       "1     0.070  \n",
       "2     0.052  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Train) after Feature Selection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "\n",
    "print(\"\")\n",
    "print('Shape (rows, columns) of Feature Matrix X (Train) ' + '=' + str(X_train_s.shape))\n",
    "print(\"\")\n",
    "\n",
    "print('Feature Matrix X (Train) with Selected Features')\n",
    "display(X_train_s[0:3])\n",
    "print(\"\")\n",
    "\n",
    "print('Response Vector y (Train) after Feature Selection')\n",
    "display(y_train_s[0:3])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected with Random Forest (RF)\n",
      "Version 2; Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features\n",
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Test) =(710, 15)\n",
      "\n",
      "Feature Matrix X (Train) with Selected Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RET</th>\n",
       "      <th>RETX</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>ewretd</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>ALTPRC</th>\n",
       "      <th>debt_ebitda</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>ps</th>\n",
       "      <th>SHRENDDT</th>\n",
       "      <th>VOL</th>\n",
       "      <th>int_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.015514</td>\n",
       "      <td>-0.046891</td>\n",
       "      <td>-0.026823</td>\n",
       "      <td>-0.044988</td>\n",
       "      <td>16.224</td>\n",
       "      <td>16.224</td>\n",
       "      <td>100.75</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.859</td>\n",
       "      <td>3.318</td>\n",
       "      <td>20141009.0</td>\n",
       "      <td>15283673.0</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.029749</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>0.035682</td>\n",
       "      <td>0.051828</td>\n",
       "      <td>18.555</td>\n",
       "      <td>16.489</td>\n",
       "      <td>75.52</td>\n",
       "      <td>6.228</td>\n",
       "      <td>0.399</td>\n",
       "      <td>2.379</td>\n",
       "      <td>20131030.0</td>\n",
       "      <td>746229.0</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025838</td>\n",
       "      <td>0.025838</td>\n",
       "      <td>-0.036974</td>\n",
       "      <td>-0.012292</td>\n",
       "      <td>-0.038109</td>\n",
       "      <td>-0.011388</td>\n",
       "      <td>15.550</td>\n",
       "      <td>9.520</td>\n",
       "      <td>18.66</td>\n",
       "      <td>1.467</td>\n",
       "      <td>1.592</td>\n",
       "      <td>3.293</td>\n",
       "      <td>20100225.0</td>\n",
       "      <td>10148052.0</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RET      RETX    sprtrn    ewretx    vwretx    ewretd  pe_inc  \\\n",
       "0 -0.017073 -0.017073 -0.015514 -0.046891 -0.026823 -0.044988  16.224   \n",
       "1  0.050202  0.050202  0.029749  0.049754  0.035682  0.051828  18.555   \n",
       "2  0.025838  0.025838 -0.036974 -0.012292 -0.038109 -0.011388  15.550   \n",
       "\n",
       "   pe_op_dil  ALTPRC  debt_ebitda  cash_ratio     ps    SHRENDDT         VOL  \\\n",
       "0     16.224  100.75        0.346       0.859  3.318  20141009.0  15283673.0   \n",
       "1     16.489   75.52        6.228       0.399  2.379  20131030.0    746229.0   \n",
       "2      9.520   18.66        1.467       1.592  3.293  20100225.0  10148052.0   \n",
       "\n",
       "   int_debt  \n",
       "0     0.018  \n",
       "1     0.018  \n",
       "2     0.038  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Test) after Feature Selection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "\n",
    "print(\"\")\n",
    "print('Shape (rows, columns) of Feature Matrix X (Test) ' + '=' + str(X_test_s.shape))\n",
    "print(\"\")\n",
    "\n",
    "print('Feature Matrix X (Train) with Selected Features')\n",
    "display(X_test_s[0:3])\n",
    "print(\"\")\n",
    "\n",
    "print('Response Vector y (Test) after Feature Selection')\n",
    "display(y_test_s[0:3])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Simple Logistic Regression (statsmodels) (SLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Preparation and fitting (on Training Set) , define BEST FEATURE (SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected with Random Forest (RF)\n",
      "Version 2; Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.057065\n",
      "         Iterations 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "\n",
    "# Run Simple Logistic Regression\n",
    "# Logistic Regression (with the most important feature from feature selection)\n",
    "# Assign \"best_feature\" to matrix X and response to y, acording to chosen Version of datasets and feature Selection method\n",
    "if _VERSION_ == 1:\n",
    "    if _SELECTION_ == 'RF':\n",
    "        best_feature = 'CAPEI'\n",
    "        logReg = sm.Logit(endog = y_train_s, exog= sm.add_constant(X_train_s[[best_feature]])).fit()\n",
    "    elif _SELECTION_ == 'PCA':\n",
    "        best_feature = None\n",
    "        print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "elif _VERSION_ == 2:\n",
    "    if _SELECTION_ == 'RF':\n",
    "        best_feature = 'RET'\n",
    "        logReg = sm.Logit(endog = y_train_s, exog= sm.add_constant(X_train_s[[best_feature]])).fit()\n",
    "    elif _SELECTION_ == 'PCA':\n",
    "        best_feature = None\n",
    "        print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround solution for error (\"AttributeError: module 'scipy.stats' has no attribute 'chisqprob'\")\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Summary (SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      0   No. Observations:                 2836\n",
      "Model:                          Logit   Df Residuals:                     2834\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 09 Apr 2018   Pseudo R-squ.:                  0.9168\n",
      "Time:                        21:29:31   Log-Likelihood:                -161.84\n",
      "converged:                       True   LL-Null:                       -1945.8\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.9371      0.163     -5.738      0.000      -1.257      -0.617\n",
      "RET          392.1753     29.763     13.177      0.000     333.842     450.509\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.68 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "logReg pvalues: \n",
      "\n",
      "const    9.554484e-09\n",
      "RET      1.193306e-39\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# LogReg with only one feature as exogen variable\n",
    "if _SELECTION_ == 'RF':\n",
    "    print(logReg.summary())\n",
    "    print(\"\")\n",
    "    print('logReg pvalues: ')\n",
    "    print(\"\")\n",
    "    print(logReg.pvalues)\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Assessing Output (SLM)\n",
    "\n",
    "### Hypothesis testing / Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "99% Confidence Interval (Significance Level 1%)\n"
     ]
    }
   ],
   "source": [
    "significance_level = 0.01\n",
    "\n",
    "if _SELECTION_ == 'RF':\n",
    "    print(\"\")\n",
    "    print(str(int(100 - significance_level*100)) + '% Confidence Interval (Significance Level ' \n",
    "          + str(int(significance_level*100)) + '%)')\n",
    "    logReg.conf_int(alpha=significance_level)\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _SELECTION_ == 'RF':\n",
    "    logReg.pred_table(threshold=0.5)\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Prediction (SML)\n",
    "\n",
    "### A: In-sample Prediction of probability for returns going UP in the next period (predict y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For whole Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected with Random Forest (RF)\n",
      "Version 2; Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features\n",
      "\n",
      "Predicted probability of price going UP for whole Feature Train Set is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9.997948e-01\n",
       "1    7.180963e-11\n",
       "2    9.999178e-01\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "\n",
    "# X must include 1 in first column for intercept\n",
    "# we wish to get the probability of 'UP' (=1) for the whole test set\n",
    "if _SELECTION_ == 'RF':\n",
    "    pred_train_all = logReg.predict(sm.add_constant(X_train_s[best_feature]))\n",
    "    print('Predicted probability of price going UP for whole Feature Train Set is: ')\n",
    "    display(pred_train_all.head(3))\n",
    "    display(y_train_s.head(3))\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: New-sample Prediction of probability for returns going UP in the next period (predict y_test)\n",
    "\n",
    "#### For chosen value of predictive variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Selected with Random Forest (RF)\n",
      "Version 2; Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features\n",
      "\n",
      "Chosen best feature = RET\n",
      "Chosen value of best feature = 0.02\n",
      "\n",
      "Predicted probability of price going UP with chosen RET value is: 99.9000%\n",
      "Ratio of \"UP\" (Train)  =  55.9238%\n"
     ]
    }
   ],
   "source": [
    "# X must include 1 in first column for intercept\n",
    "# we wish to get the probability of 'UP' (=1) for a best_feature_value of USD 15\n",
    "\n",
    "# Print Text\n",
    "print(\"\")\n",
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "print('Chosen best feature = ' + str(best_feature))\n",
    "\n",
    "# Loop for Version differenciation\n",
    "if _VERSION_ == 1:\n",
    "    if _SELECTION_ == 'RF':\n",
    "        best_feature_value = 15\n",
    "        print('Chosen value of best feature = ' + str(best_feature_value))\n",
    "        print(\"\")\n",
    "        pred_test_one = logReg.predict([1, best_feature_value])\n",
    "        ratio_response_train = y_train_s.sum() / y_train_s.size\n",
    "        print('Predicted probability of price going UP with chosen ' + str(best_feature) + ' value is: '\n",
    "              + str(\"%.4f\" % round(float(pred_test_one*100),4)) + '%')\n",
    "        print('Ratio of \"UP\" (Train)  =  ' + str(\"%.4f\" % round(float(ratio_response_train*100),4)) + '%')\n",
    "    elif _SELECTION_ == 'PCA':\n",
    "        print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')  \n",
    "elif _VERSION_ == 2:\n",
    "        if _SELECTION_ == 'RF':\n",
    "            best_feature_value = 0.02\n",
    "            print('Chosen value of best feature = ' + str(best_feature_value))\n",
    "            print(\"\")\n",
    "            pred_test_one = logReg.predict([1, best_feature_value])\n",
    "            ratio_response_train = y_train_s.sum() / y_train_s.size\n",
    "            print('Predicted probability of price going UP with chosen ' + str(best_feature) + ' value is: '\n",
    "                  + str(\"%.4f\" % round(float(pred_test_one*100),4)) + '%')\n",
    "            print('Ratio of \"UP\" (Train)  =  ' + str(\"%.4f\" % round(float(ratio_response_train*100),4)) + '%')\n",
    "        elif _SELECTION_ == 'PCA':\n",
    "            print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For whole Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Selected with Random Forest (RF)\n",
      "Version 2; Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features\n",
      "\n",
      "\n",
      "Predicted probability of price going UP for whole Feature Test Set is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.000484\n",
       "1    1.000000\n",
       "2    0.999899\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "\n",
    "# we wish to get the probability of 'UP' (=1) for the whole test set\n",
    "if _SELECTION_ == 'RF':\n",
    "    pred_test_all = logReg.predict(sm.add_constant(X_test_s[[best_feature]]))\n",
    "    print(\"\")\n",
    "    print('Predicted probability of price going UP for whole Feature Test Set is: ')\n",
    "    display(pred_test_all.head(3))\n",
    "    display(y_test_s.head(3))\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Plot Results (SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Selected with Random Forest (RF)\n",
      "Version 2; Based on Dataset with Ratios + Seasonality + other Market Data as predictive Features\n",
      "\n",
      "Chosen best feature = RET\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAFKCAYAAAAjekdZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcFPWd//FXMzMMDPcpCoqC+lGBBIMXJEETjGICRo2aRMz+cGNOs8luduMmm2w22WRzbY7fL5tr1f39TDZoPKKuR8REjRrjjWIQ4YMycg0MxwwwwMDMdE///qjqoWe6p6dnmO6eLt/Px4MHPf2t41PVVfXpz7equmLJZBIREREpvUGlDkBEREQCSsoiIiIDhJKyiIjIAKGkLCIiMkAoKYuIiAwQSsoiIiIDRGWpA5CemVkSWA/Ew7cqgceBz7r7ATNbCvwU2Nxl1DrgA8Az4d81wCSgNvz7YXf/TAFDP2Jm9hhwk7v/uhfjLAWudvfzs7T9CrgDWAW87u6VZvYZ4Ch3/2czOxs46O5/6YfYRxF8TsOAc9y9oY/TuRBY4+6bjjSmQktfl/00vSRwrLtvSXvvPIJt4sTw9e85vE1XAK8Bn3H32i7Tmgw85O4zexnDx9z9xvD1BoJt68k+LVA/68/ttZvp/wq4w93v68U4XwFOdPelhYgp6pSUy8d5qQOTmVUDvwH+Cfhy2P50tiQUOiUc7zyCg9kpBY51wHL3vwIws+PT3vtJ2iDXAE8C/XGQewswzt2PPcLp/B3wTWDAJ+Uu67JYNqVv02b2j8AtwDnpA7l7HdDbhDwJuB64sR/iLIT+3F4zpPYXKR4l5TLk7i1mthy4uD+na2bXARe6+8Xh3xXAduAdwCzgXwgqkTaCKv2xHNM6HniZIJn8L6Aa+Ad3/5+wkr0YGAWscPfrzeyzwCcJTqk4cK277wwnN8vMniOo8h8CPunuCTO7GPi3cNr7gI+6+8pwnAoz+29gHrAX+LC7e6ryJjiQpWL9GjAFeAH4K+BiMzsK+AZwgrtvD4f7ATDI3f+uy7KeB/yQoCdiL3AdsANYBhxlZmuBd7j7rrRxbgYagfPD+fwP8H1gITAYuMHdv2Vm3wAWAKea2fXARQQV/jfTpvO6u38zrOL+L7AEeA/wK+Be4DLgBOAJ4Cp3T5rZN4ErgBiwhaD625rlM7wFmAg8HK6jO9395mzL7O4vpNalu18bruvu5r8U+Gr4uf0I+H/uHqN//AT4jpmNcve9XZYn1TuyFHgf0AS8k6AX6gp3X91lWk8BU8LP8C3he2eY2feB44DfuPvnw+mntsdhwOvhsu5Kn1gYw9PAt4GPAWOBz7v7bWH7PwNXA0OAe4DPE6z354A57r7FzJYAf0Pw+aa214nu/sMu88m6/3U3n3Cfegz4M8Fn9lHgW4Q9VTk+86HAzQRfgjYAa7v5XCQPOqdchsxsDHAVwQGjP/0WeLeZ1YR/zwe2uvta4GfA+9z9VODT5PeFYASQDLsLPwXcZGapL4IXECTX683sHOALBL0BpxBUhN9Om867gPMIKv5zgUXhdH4JfMzdT+ZwUkt5B/Azd58OPAh8p6dg3f0XBAe/6939BwSJ6INpg7wfuC19HDMbRtAd/jdh7N8jSGRbCA6Ym9z9lK4H59AC4Cx3vwP4LHAawZefGcDlZrYo7AauA5akDtw9mOLultbVvZggQZ8MvBuYZ2YzgCuBmeG6u5vgy0FX3wf+5O4nEnwZOj/XMptZtuNJtvmPJdieFgOnAxfmsVy9UQkkgdYehnsvwTZyMvBH4G+zDPPXHP4MU9ObA7wdOAP4jJkda2bHEiSmD7v7tHB6v+hmvuOBdnefFc4z9QXrcoLt7SxgevjvU+6+kWD7/V647r8JfNzdf8bh7fWHmbPJvv91N5+08eYAM9y94/jSw2d+DcEX5ukEyfyCbpZb8qCkXD4eM7O1ZlYLvAE8Anw3rX1u2J7+7/O9mYG71wMvERxEAS4Fbg9f7wA+aWZT3f3JVHXQgxjwX+G0HwaqgJPCtnXu/lr4+n0EFdiO8O+b6Lxj3+nuze7eDDwAzHX3ODDR3VPny/8ETEsb5zV3fzp8fTswN494u7oV+DCAmb0ljP/ZLsOcA2xx9z+Hy/lbgoPu8XlM/xF3PxS+vhL4L3dvcfcDBFXQZX2I+f4uf9/p7gfDaa4jqO72ABOAJWY2xt3/w91/lWVa7yRYB7j73UCqku7NMmeb/9kEn/9qd28Hft6H5cwq7N25HnjQ3Q/2MPir7r4ifP1iGFs+bnX3RNizsJ2gkl0MPO/ur4TD/Jyggq3IMn4l8P+yzPdKYJm77w2375s4vA38mGDfuY2gOs+nu7q7/S/XfAB+F34u6XJ95vOBu9w97sF1E123QekFdV+Xj/PCrqvxBAe328IdKiXXOeXeuJOgCv4fgsowlaAvBr4CrDCzzcDfuvvjPUwr6e670/7eA4wJXzemvT+Bwwd8gN0EXaYpO9Ne7wWODl9/1sxSXXNDCKqj7sYZQ+/dC9xoZicAlxCs864/Fj8hjDfdni7xdyd9HYwm6HL9l/DvaoIqqLcau/y9N+11Aqhw9zoz+wDw98B/mNkTBL0WXS8UHEPnZasL/+/NMmfMP8d0s0mSWTxUhNNKOS7sXk55jqDLtifZYstHU5bxRgNnd4ljLzCO4AttukT4JaXrfEcDfxNu0xAcn3cChF3LNwA3EPSq5KO7/a/b+YS6bkOQ+zMfS+d1uZugSpc+UFIuM+6+y8x+TNB99P4CzOK3wJfM7Ayg0d3XhfNdD1wTdlf9FUEX7eQephUzs3F++KrjMWTf4bcTHLxSxoXvpYxNez0GaDSzecA/EnT/bjCz99D5YpyMcXqINYMHV7bfR3Du9XKCbrqcsZtZLJz3dmBqL2a3Ffi+u/dUZXRNHmO7GzAXd38UeDTslvw+Qffoki6DNQEj0/5OfRnKtcz56G662dQTVGPpF7md3OXvThd6lchWgrsZLj/CadzrWS6WCz+nLxBUzN8l2CZ70t3+1+18csj1me8muD4kZUIvpitdqPu6PP2A4Nzcuf09YQ+u8H6D4Kru2wHMbIKZ/cHMRobdWs/QuSrN5apwGhcABwmq/K4eAC4zs9RO/4nwvZTLzGxIeGC6iKCreiJBBbI5PAe+FBiWdl7TzGxO+PqKcJx8tBFUEim3EJxDr0nr6kz3HHC0maW6xz9EcD55Q57zS7kXuNbMKswsZmZfMbOFWWLaBrwVwMymEZzb7BUzu8DMfmpmg8KK7WWyf57PEdxSh5ktAo5Je/9IlnkFMMPMTgw/r2tzDPtz4MtmNjyMYzrwDwQXHBVDGzA87VqI7vweeGf4mWBmZ5nZ/+nlvO4FPpK6psPMPpFWzX6d4Nz/54GTzGxxWnyjM6Z0WLb9L9d8upPrM3+asKs+7Ml7b57LK1koKZchd99HUNl8P/zGCtnPKa+14N7M3rqDoLv29nB+O4HlwPNm9irB7VgfheC+VAuuEM4mAQw2s9UEB9drs5yrwt2fC5fnT2H332gO3+oFwQVXfwTWhK+Xh/+2Etyb/XuCK3j3Ehy4AB4l6N5+jaAL/ot5LvvdwHfNLHXQf4igqst6kVWY1K4AfhLG/mngQ1m6uXvyE2AjsJrg6tVTOXyF+J3AbeE1AjcCx4fL9e2wrbeeILiCdl342XyQ4Erorq4n+EK0luCitKcJukSPaJndfRvB7Xx/JDhHn+sL07fC9mfDed0OfMndH8xnXv3gLwTVZb2ZdXvOOTy//DHgbjNbQ/B55nNhXrq7gfuAF8NlvRh4yMzeStBT8w13TwCfIVj3w8ncXtN1t/9lnU+uwHr4zG8k2Pdqgbs4vA9KH8T0PGUpBEu7/aTUsRyp8KB2hbu/WupYis3MYqlka2bPA99M3VbTj9OdATzp7n057y9ZRGn/e7NRpSySg5l9CNj2Jk3I/07wS3GY2SkE1Xu2LvzeTrcSqLPg16ggqNSfzjGKyJuGvkWJdMPM/kBw28eRXLxTzn4I/LeZvU7QFXqdp/3cZV+5e9yCH6r5ZXhOeRvh6RCRNzt1X4uIiAwQ6r4WEREZIJSURUREBoiSn1NesWKF+s9FRORNZ86cORkPYSl5UgaYM2dOzwN1Y82aNZx66qn9GE350TrQOnizLz9oHYDWAZTPOlixIvuNDOq+FhERGSCUlEVERAYIJWUREZEBQklZRERkgFBSFhERGSCUlEVERAYIJWUREZEBQklZRERkgChKUjazmWa23sw+U4z5iYiIlKOC/6KXmQ0D/gN4pNDzkjen47/4QPiqtqRx9EV1RYyWxOFfmo2l/sUgmYRBg2IMroxx/LhhTB5Tw8QR1cw4ZhR3v7SFzY3NjKiuZMueg1TGkpx6zG4AGg+0UlUxiLZEO2OHDebEo0bwgbdNAeAXj69nR9Mh5k4bx76WOElg5jGjeGXrXmLAZW+bwpypY3qMe8XG3TxT28A508ZlHb6n9r4OK1JMpdg2C/7oxvCB5lXAPwK73P0n6e0rVqxIrlq1qtM4M2bM4Mwzz6StrY1ly5ZlTHP27NnMnj2b5uZmbr75Zmpqajq1n3HGGcycOZO9e/dy9913Z4w/d+5czIxdu3Zx//33Z7TPnz+fadOmUV9fz/LlyzPaFyxYwLHHHsvmzZt55JHM7xoLFy5k0qRJ1NbW8sQTT2S0L1q0iPHjx+PuPP105rPdL730UkaNGsUrr7zCCy+8kNF+5ZVXUlNTw8qVK1m5ciXNzc2d1sGSJUuoqqri+eefZ/Xq1RnjL126FICnnnqKdevWdWqrqqpiyZIlADz++OO88cYbndpramq48sorAXj44YfZsqXz43VHjhzJZZddBsDy5cupr6/v1D5u3DgWL14MwH333UdDQ0On9kmTJrFw4UIA7rrrLpqamjq1T5kyhfPPPx+A22+/nUdf2dypfVv7SF6OHwPAgtgqBrXsJ5loA5KQTFK7o4kVtTsBuOKc6RnrZt22Pby8sYHKQTEuPWtaRvvqLY28umU3Q6oqWDzn+Iz2lzc2sG7bHoYPqeKi2cdltK+o3UntjibGDKvm/FlTMtqffW07mxr2M2HkEM47bXJG+5O+jW27mzl6TA3vsKMz2h97tY6dTYc4btxwzj7pqIz2h1dtYfeBFqZNHMmcaRMy2h/6y2bOO3k8k8cOp6qqKqP90KFD1O89SG3jIU49ZgyxGIwbNpiqiqDT7eDBg2xvOsTmPa2cOGlU1nYItrPKykraEu00HGglmYREezvx1haOGjmEwYMHU1FR0WneyWSSQ4cOAWRtP3ToEKnjWXV1NYMGde4IbG9vp6WlJa/2IUOGEIt1/lniRCJBa2trXu1Dhw7NWHfxeJy2trY+t7e1tRGPx4nFYgwZMiRr+/bt2xk/fnzW9tbWVhKJRLfjp9oHDRpEdXV1RntLSwvt7e09tldUVDB48OCM9tTn01N7ZWVlt9tervbUttXa2sqoUaO6bU9te921p7at1LZJRRXJEZP41F9/hDlTx/TbcW/WrFml+e1rd48DcTPrdpjm5uZOf9fX17NmzRri8XhGG8DWrVuprq7u2Ai6DlNXV0dFRQXNzc1Zx9+yZQvt7e00NTVlbd+0aRMtLS3s3r07a/uGDRvYv38/u3btytpeW1vL7t272b59e9b29evXs3PnTrZu3Zq1/fXXX6empoa6urqs7evWraO6urpj/K7rYO3atVRWVlJfX591/DVr1gBkja+ioqKjfefOnRnt8Xi8o72hoSGjPZlMdrQ3NjbmnP6ePXsy2hsbGzva9+7d27GjpDQ0NHS0d03Y6fY+exctk1s677yxGC1169m38jkAEjOvyhjv0JY17Fv5EpWVlSROuzKzfdMq9v1lFfGhQ0nYpZntG15i35q1xEaMIHHi4oz2g2+sYN9rrzN47FgSJyzMaG9e/xz7Nmyk5qiJJI47P7N93TPsq6tj1OTJJCafm9F+wP/Mvu07aD5+Komj357ZvuYJ9jU2cvCkE0lMPCujfd+qR7ntmf3MPO0UTj/99Iz2e+65h30HDjJj5kwSI2cBsGNfUNkD3HHHHRxqjTP79Nkkhp+a0X7rrbcCcNZZZzF9+nSSSUiVBW3xNm6//U4qB8G8efOYOnVq53V38CD33HMPEHxxnjy585eWffv2dXzJXrBgARMnTuzU3tjYyEMPPQTAhRdeyNixYzu179ixo+NL9qJFixgxYkSn9rq6uo4v2ZdccklG4ty4cSNPPfUUAFdccUXGgX/9+vU891yw7X34wx+mq7Vr1/LSS8G2d8UVV2S0r1q1ildeeYWhQ4dyySWXZLS/9NJLrF27lhEjRrBo0aKM9ueee47169czduxYLrzwwoz2p556io0bNzJx4kQWLFiQ0f7EE09QV1fH5MmTmT9/fkb7I488wo4dO5g6dSrz5s3LaH/ooYdobGxk+vTpnHVW5rZ3//33s2/fPk45pftt7+DBg8ycOZNZs2ZltN9xxx3E43FOP/10TjnllIz2rtteung8zh133AEc3vZS22assgqGH8V9z66hpnlMQY576QpeKaeY2dfoplLWAymOzJt5HRzuuj6spf516n/5d9ScPJfR511D5aiJxAZVZBn7zaOyIkayPUmih919cOUgbv3YOTm76lZs3M2Sm56hLd5OVeUgll3befie2nszrd54M+8HKVoH/bcO+nPbzDr9FSsG7lOiRPpqw3fel5GY97+8nFjVYMa993MMqh5Wosjy07/nlEcDhT+nPGfqGJZde06359p6au/rsCLFVKptU0lZyt6G77yv07fjqbd+moXvX8wdP8rsfo6Kq87ufL463+rgxr86o1/mP2fqmB6Tbb4Hsd4MK1JMpdg2C35LlJnNMbPHgKXA58zsMTMbm3sskb6pr69n06ZNzJ07t9ShiIj0WjEu9FoBnFfo+YgArFy5EoAjuU5BRKRU9IteEikbNmwAyLi6UkSkHCgpS6Rs3LiRyspKjj468x5eEZGBTklZImXDhg0cd9xxGT8sISJSDpSUJVLq6uqYMiXzl7JERMqBkrJESmNjI+PGjSt1GCIifaKkLJHS2NiY8fOJIiLlQklZIiOZTCopi0hZU1KWyDh48CAtLS3qvhaRsqWkLJGRegykKmURKVdKyhIZjY2NgJKyiJQvJWWJjD179gAwevToEkciItI3SsoSGQcOHABg+PDhJY5ERKRvlJQlMlJJuaampsSRiIj0jZKyREYqKQ8bNqzEkYiI9I2SskRGc3MzoKQsIuVLSVkiQ5WyiJQ7JWWJDJ1TFpFyp6QskdHc3MyQIUMYNEibtYiUJx29JDIOHDigrmsRKWtKyhIZSsoiUu6UlCUympublZRFpKwpKUtkqFIWkXKnpCyR0dzcrCuvRaSsKSlLZLS0tFBdXV3qMERE+kxJWSJDSVlEyp2SskRGa2srgwcPLnUYIiJ9pqQskaFKWUTKnZKyRIYqZREpd0rKEhmqlEWk3CkpS2S0tLSoUhaRsqakLJHR2tqqSllEypqSskSGuq9FpNwpKUsktLe3E4/H1X0tImVNSVkioa2tDUCVsoiUNSVliYTW1lYAVcoiUtaUlCUSVCmLSBQoKUskqFIWkShQUpZISCVlVcoiUs6UlCUS1H0tIlGgpCyRoO5rEYkCJWWJBFXKIhIFSsoSCaqURSQKlJQlEnShl4hEgZKyREKq+1qVsoiUMyVliQQlZRGJAiVliYREIgFAVVVViSMREek7JWWJhFRSrqysLHEkIiJ9p6QskRCPxwGoqKgocSQiIn2npCyRoEpZRKJASVkiob29HVBSFpHypqQskZDqvlZSFpFypqQskaDuaxGJAiVliQQlZRGJAiVliQR1X4tIFCgpSySkKmXdEiUi5UxJWSJBlbKIRIGSskSCbokSkShQUpZISCQSxGIxBg3SJi0i5UtHMImEeDyuKllEyp6SskRCIpFQUhaRsqekLJGgpCwiUdDjUczMZgJXAHOBieHbO4GngTvd/S+FC08kP/F4XLdDiUjZ6zYpm9lE4BfAHOABYBmwI2yeAJwN3GtmLwMfd/ftBY5VpFuqlEUkCnIdxR4HvgNc6e7xLO2/MrPPAlcBjwIzChCfSF6UlEUkCnIdxd7t7ttyjezuCeC/zewP/RuWSO8oKYtIFHR7oVdPCTk9Ebt7fX8GJdJbSsoiEgVHcvX15H6LQuQI6T5lEYmCXBd6rcsxXgw4tv/DEekbVcoiEgW5jmIbgL8A92VpiwE3FyAekT5JJBK6JUpEyl6upHw1wRXY/+nur3VtNLODBYtKpJfUfS0iUZDrQq8dwDyCHwrJ5gsFiUikD9rb25WURaTs5bzQy913u/seM5ueei/12t3vL3RwIvnSOWURiYJ8r76+r5vXIgOCuq9FJAryTcqxbl6LDAiqlEUkCvJNysluXosMCErKIhIFenSjRIKeEiUiUaDua4kEVcoiEgX5JuUHunktMiAoKYtIFHSblM3sf6Veu/s/ZHudNuxH+j80kfwpKYtIFOSqlC8yswfNbH53A5jZO8zsfmBR/4cmkj8lZRGJgm6PYu7+ITP7IPAzM5sErAB2hM0TgDnh3//m7rcUPFKRHHSfsohEQc6jmLvfBtxmZqcCZwETCS702gF83t1fLXyIIj1TpSwiUZDXUczd1wBrChyLSJ/pKVEiEgW6T1kiQd3XIhIFSsoSCXpKlIhEgZKyRIIqZRGJgm6PYmYWAz4GXAC0AL9197uKFZhIb+hCLxGJglyV8jeAvwYeAZ4Fvmpmny5KVCK9pKQsIlGQ6yh2GXCWu+8HMLPfAL8DflaMwER6Q93XIhIFuSrlQamEDODuO4BhhQ9JpPd0S5SIREGupNye5T09S1kGnPb2dpLJpCplESl7uY5i483sn3K95+7fKkxYIvlLJBIASsoiUvZyHcV+B5zU5b0H0t5T1SwDQjweB5SURaT85XogxdIixiHSZ0rKIhIVue5T7tp1DZAANgH3uPvBgkUl0gtKyiISFbku9Dopy78ZwOeAl83shMKHJ9IzJWURiYpc3dfXdNdmZkuBfwcuL0BMIr2SSsq6JUpEyl2ffvva3W8mqJpFSk6VsohExZE8kCLbfcwiRadbokQkKvqUlM3sWmBtP8ci0ieqlEUkKnJdff0HMu9FHgRMBQ4BiwoYl0jelJRFJCpyHcV+neW9dqAeeNzdWwsTkkjvKCmLSFTkuvr6l8UMRKSvlJRFJCqO5EIvkQFBt0SJSFQoKUvZU6UsIlHRbVI2s/eE/y8sXjgivadbokQkKnIdxW4ys/OAH5vZuUCs6wDuvrVQgYnkS5WyiERFrqPYn4DXCKrpuiztSUAn8aTklJRFJCpyXX19NXC1mf3R3d9VxJhEekVJWUSiosejmLu/y8yOA94NTAS2A39Q17UMFErKIhIVPV59bWZXAy8DFwMGXAqsMrNLChybSF50S5SIREU+pcX1wFvdfVPqDTObDvwWuKdQgYnkS5WyiERFPvcpD05PyADuvh6oLkxIIr2jW6JEJCryOYptMLPrgZ+7+z4zGwV8AthQ0MhE8qRKWUSiIp9K+WPAu4DdZhYHdgLzw/dFSk5JWUSiIp+rrzcDF5lZJTAO2OXuiYJHJpInJWURiYq8j2LuHie4HUpkQFFSFpGo0AMppOzpligRiQolZSl7uvpaRKKix6OYmb0I/Aa43d03FDwikV5S97WIREU+R7GvApcAz5rZG8BtwB3uvqWgkYnkSUlZRKIin6uv7wfuN7MY8A7gcoIEXQssA5a5+77ChinSPSVlEYmK3pxTHg5MA04MX+8BZgEvm9lFBYhNJC9KyiISFfmcU74MWAIsBJ4lOL98tbvvDttPApYD0wsYp0i3Ukl50CBdtygi5S2f0uJLwC3A32R7XKO7v2Zmv+73yETyFI/HqaioIBaLlToUEZEjkk9p8Zq7/6hrQjazZ1Ov3f1f+j0ykTwlEgndoywikdBtpWxmiwmeobzQzG7o0jya4NyySMmlKmURkXKXq/v6WWAYwe1QdV3aNgDfK1BMIr0Sj8d1kZeIREK3RzJ33wH8xszWuvvKIsYk0iuqlEUkKnJ1Xz/o7hcBd5hZMtsw7n5ywSITyZOSsohERa4+v6+G/19bjEBE+krd1yISFbmOZFVmNg9oK1YwIn0Rj8d1j7KIREKupLysh3GTBL/wJVJSiURClbKIREKuC71OKGYgIn2lc8oiEhW5LvT6urv/S5Z7lDu4+8cLE5ZI/pSURSQqcvX57Qj/73qPssiAogu9RCQqcnVf/zT8/+tmVkHwwIkxQCOw3t3bixOiSG6qlEUkKnq8ZNXMLga2Ak8TPCHqeWCTmV1Y4NhE8qKkLCJRkU+f34+AJe7+cOoNM7sA+ClwUqECE8mXkrKIREU+N3e2pCdkAHf/PXCoMCGJ9I6eEiUiUZFPpXyjmX0e+JW77zKzMcAS4KbChiaSH1XKIhIVuW6JaiP4gZAYUAH8u5mlmmPAfuD/FDpAkZ7o6msRiYpcR7Kenpc8rD8DEemreDzOkCFDSh2GiMgRy3VL1MbU6/CWqKM5fA56BLAcOLag0YnkQZWyiERFj0cyM/sQ8F9AeinSAtxTqKBEekPnlEUkKvK5+vpfgYVAFbAOGAp8DbijcGGJ5E9JWUSiIp+kHHf3P4W/4BVz91Z3/x7wlQLHJpIXdV+LSFTkcyRrMLMvAD8AdoW/5PUSOp8sA4QqZRGJinwq5WuBd4aV8r8BdwLbCM4zi5RcW1ubkrKIREKPlbK7O3Bx+PrB8MdDhrn73kIHJ5IPdV+LSFTkc/X1BOCLwFwOPyXqCTP7d3dvLHB8Ij1S97WIREU+5cVtBM9U/g6wlyAxXx6+/57ChSaSHyVlEYmKfJLy8e7+7i7v3WNm6wsRkEhvqftaRKIinwu9VpvZ1PQ3zGwKsKowIYn0jpKyiERFrgdS3BC+PAC8bGZPAjuBscA7gHsLH55Iz9R9LSJRkau8qEv7f03a+xuAFwsVkEhvJJNJJWURiYxcD6T4evrfZnY8MBHYnv6wCpFSam9vB1D3tYhEQj63RL0NuBUYR3D19Vgz2wx80N3X5BxZpMDi8TiAKmURiYR8youfAl9y97tSb5jZh4FfAOcWKjCRfCi+tsbXAAAS2ElEQVQpi0iU5HP19aj0hAzg7rcCEwoTkkj+UklZ3dciEgX5JOWDZnZO+htmdjbQXJiQRPKnSllEoiSf8uLvgXvD88i7gfHAJOCKQgYmkg9VyiISJfk8kOKx8Mrrcwi6rLcDz7m7KmUpOVXKIhIl+Vx9/Ud3fxfwaBHiEekVJWURiZJ8zim/ZGZXm9nwgkcj0kvqvhaRKMnnSPZB4Drgl2aWCN+LAUl3H1ywyETyoEpZRKIkn6Q8r+BRiPSRkrKIREnOpGxm44BZQAvwZ13cJQONuq9FJEq6PadsZu8G1gH/DHwXeM3M3lKswETyoUpZRKIkV3nxbWCxuz8FYGYXAd8DFhYjMJF8KCmLSJTkuvp6dCohA7j7g8DxBY9IpBfUfS0iUZIrKSeyvNdeqEBE+kKVsohESa7yotLMjia4/Snre+6+tZDBifRESVlEoiRXUj4R2ELnpAxQF/6fBHQklJJS97WIREm3RzJ3z+fXvkRKSpWyiESJEq+UNSVlEYkSJWUpa+q+FpEoUVKWstbW1gaoUhaRaFBSlrKm7msRiRIlZSlr6r4WkShRUpayluq+rqqqKnEkIiJHTklZylprayugSllEokFJWcpaKimrUhaRKFBSlrKm7msRiRIlZSlr6r4WkShRUpaylqqUlZRFJAqUlKWstba2UlVVRSzW9bkpIiLlR0lZylprayuDBw8udRgiIv1CSVnKWltbm5KyiESGkrKUtVT3tYhIFCgpS1lTpSwiUaKkLGVNlbKIRImSspQ1VcoiEiVKylLWVCmLSJQoKUtZ0y1RIhIlSspS1tR9LSJRoqQsZU3d1yISJUrKUtZUKYtIlCgpS1lTpSwiUaKkLGVNF3qJSJQoKUtZU/e1iESJkrKUNXVfi0iUKClLWVNSFpEoUVKWsnbo0CGGDh1a6jBERPqFkrKUtUOHDjFkyJBShyEi0i+UlKWsKSmLSJQoKUvZSiQStLa2qvtaRCJDSVnKVktLC4AqZRGJDCVlKVuHDh0CUKUsIpGhpCxl6+DBg4AqZRGJDiVlKVupSllJWUSiQklZylaqUlb3tYhEhZKylC1VyiISNUrKUraUlEUkapSUpWyp+1pEokZJWcqWKmURiRolZSlbzc3NANTU1JQ4EhGR/qGkLGVr3759AIwYMaLEkYiI9A8lZSlbSsoiEjVKylK2Ukl5+PDhJY5ERKR/KClL2dq/fz9DhgyhsrKy1KGIiPQLJWUpW/v27VPXtYhEipKylC0lZRGJGiVlKVv79+/X+WQRiRQlZSlbTU1NqpRFJFKUlKVsNTQ0MH78+FKHISLSb5SUpWzt2rVLSVlEIkVJWcpSMplk165djBs3rtShiIj0GyVlKUsHDhygtbVVlbKIRIqSspSlXbt2AahSFpFIUVKWsrRlyxYAJk+eXOJIRET6j5KylKWNGzcCMHXq1BJHIiLSf5SUpSylkvJxxx1X4khERPqPkrKUpbVr13LMMcdQU1NT6lBERPqNkrKUpZdeeonZs2eXOgwRkX5VlGfemdmPgHOAJPA5d3++GPOVaNq+fTurV6/myiuvLHUoIiL9quCVspmdC5zk7nOBa4GfFHqeEm2//vWvSSaTvP/97y91KCIi/aoYlfIC4B4Ad3/VzMaY2Uh3byrUDP/4lzd49KV1zJ4ymhmTR5FMJju1J5NJVm/dy8ub9/DWY0dz2tEjM6bxSt0e/rJlL2+ZMooZx4xidd1eXt6yh7dOGQ3AH16tZ/eBVsYMG8z5px7FqUePyJgHwO9WbePPr+/i7dPHcdGso3l1axOr6vYwa/IoAFZt2cuIIZU0HWrreO+3K7ZQt7uZyWOGctnbpgDwyJrtxIBpE4ZTu3M/a7c1sXN/C1UVMcYNiTH96Bd5Y+d+Nuw6wMihVUyfMJz9h9poTSQ5/7SjuOC0o/jff3Ceqm2AJAypGkR7e5Lm1nYAYjGoiAVdGclkkkQSgr86LVTuFZ/R3nX8rn/2fvqtO95g75PLGHL86Vx8y2a4ZXPaALUAjB5axVknjOUT505nztQxAKzYuJtnahs4Z9q4jve605thRUT6U6xrwupvZnYD8IC7/0/495+Aj7r7OoAVK1YkV61a1WmcGTNmcOaZZ9LW1sayZcsypjl79mxmz55Nc3MzN998c6eLffYdinPjTTeyasVzjBw5kssuuyxj/Keeeop169Yxbtw4Fi9enNH+xBNPUFtby6RJk1i4cGFG+yOPPMLmzZs59thjWbBgQUb78uXLqa+vZ9q0acyfPz+j/b777qOhoYGTTz6ZefPmZbTfddddNDU1dayHrm6//Xaam5s71kNXy5Yto62tjTPPPJMZM2ZktN98880AzJs3j5NPPrlTW/o6nz9/PtOmTevU3tzczO233w7AggULOPbYYzu1NzU1cddddwGwcOFCJk2a1Km9oaGB++67D4DFixdn/PhHfX09y5cvB+Cyyy5j5MjOX5g2b97Mk17PhEu+yPljGqgm3ql9W/tIXo4fA8AF1a8x6+jg0Y5r6ptIJpNsS47hnz96KXOmjulYD+lGHH0CX36ymUS8jfdUv86pk0YyYsjh767p215qPaQ744wzmDlzJnv37uXuu+/OaJ87dy5mxq5du7j//vsz2lPrPH09pEut882bN/PII490vN/c3ExNTU3HOq+treWJJ57IGH/RokWMHz8ed+fpp5/OaL/00ksZNWoUr7zyCi+88EJG+5VXXklNTQ0rV65k5cqVGe1LliyhqqqK559/ntWrV2e0L126FDi8D6arqqpiyZIlADz++OO88cYbndpramo6Tlk8/PDDHfeqpySTSa655hrg8D6YLn1/T+2D6dL399Q+mG7KlCmcf/75wOF9MN0JJ5zAueeeCxzeB9Ol7+/Ztr3eHPe62/YqKio45phjirrtpQyUbS/bZwuF3fbSc02+296sWbOYM2dOrGucxaiUu840RpeaqevGXV9fz5o1a4jH4xltAFu3bqW6upqWlhba29s7DdNwIM6osz7A+GPOZcTgGOMn1zCyehCxWFoY449n97qDjKqOUTWuitFDKxhZXdHRnBw/jf2vNTN6aIyq8VUMqYxxqC3ZsSSj3vkRDjYnGV0ziKrxwXijh1Qwakjw+vrrr6eyspLlaxupqmnvmG7loBjxdhh7waeoaIFRI2JUjc88gzDuvZ+jug1GjopRNTYt7vDluMVfYFgCRoyGqk6FXDDAhEu+TDwJw8dC1ajMlT7xiq8DMHxckqouTz6MJWHild8AYNj4dqqGdf7SVp2IMfGD3wzaJySo6nLx85AxMY760BkA1EyMUzWk8/hDR0/jqA8HB6ahR7VRNbhze82o6Rw19rxgWpNaqeqyhY4YP4tJZ1j4V+aOly6ZTNKwL9g2ku1BXZ5oT3Lfs2uoaR6Tddva8EY9rW3Dg/UVjl/RfjiI9G0v2/h1dXVUVFTQ3NyctX3Lli20t7fT1NSUtX3Tpk20tLSwe/fu7PFt2MD+/fvZtWtXp/bUflBbW8vu3bvZvn171vHXr1/Pzp072bp1a9b2119/nZqaGurq6rK2r1u3jurq6m7HX7t2LZWVldTX12dtX7NmDUDW+CoqKjrad+7cmdEej8c72hsaGjLaBw8e3NHe2NiYc/p79uzJaG9sbOxo37t3LwcPHuzU3tDQ0NHe1NREa2trp/adO3d2tO/fv59EItGpffv27R3t2dZNb4573W17EydO5PXXXy/qtpcyULa9tra2om97yWTyiLa9dMWolL8GbHP3/wz/rgXe6u77IKiU58yZ0+fpr1mzhlNPPbXj7xUbd7Pkpmdoi7dTVTmIZdeek9EF2dMwXdu/umgG/3r/atri7VRUDKK9vZ344VzL4IoYt358bsZ8bnl2E/909+FegE/On8bNT2/omA7JJPFEknZgUCxI2olkkDhSKgbFiJHsNL++mD1lFCu37D2yiZSZyooYt318LkCP20RKPtvPQNR1P3gz0jrQOoDyWQcrVqwoWaX8e+DrwH+a2enA1lRCLoQ5U8ew7Npzcp4T7GmYbO02aUTH3wC/fXELu/a1MH5ENR9425Ss87nq7OCHLR58ZRsXzTyaq84+jvfMmNRpOs/UNjCmZjC7m1s73vvPx9dTu3M/0yYM5xPnTu+YXwyC89tb9/Lixt3U7TlIdeUgjqqJ8ZYTjuLVur28uq2JscMG85Ypo9nT3EpLvJ0PnnkcV519HH/7m5f43SvbIAk1gytItCfZ3xJ8m4+FXwqSQHt76pxyecp2TrmnbSIln+1HRKRQCl4pA5jZd4D5QDtwnbu/nGrr70r5zUjrQOvgzb78oHUAWgdQPuuglJUy7v7FYsxHRESknOkXvURERAYIJWUREZEBQklZRERkgFBSFhERGSCUlEVERAYIJWUREZEBQklZRERkgFBSFhERGSCK8oteuaxYsaKMf9BRRESkb7L9olfJk7KIiIgE1H0tIiIyQCgpi4iIDBBFeSBFfzKzKuBmYCqQAK5x99puhr0VaHH3pUULsMDyWX4z+yDw9wRP5XrE3b9c7DgLxcx+BJwDJIHPufvzaW3nA98iWC+/c/dvlCbKwuphHbwL+DbBOnDgWnc/wqdxDzy51kHaMN8G5rr7eUUOr+B62AaOBW4FBgMvuvsnSxNlYfWwDq4DribYD15w978tTZS9V46V8lXAHnd/B/BdggNQBjN7DzC9mIEVSc7lN7Oa8P0FwFzgfDM7rehRFoCZnQuc5O5zgWuBn3QZ5MfAB4C3AxdFZbnT5bEObgAud/e3AyOAhUUOseDyWAeEn/38YsdWDHks/w+AH7j7WUDCzI4rdoyFlmsdmNlI4AvAO8Pj5Glmdk5pIu29ckzKC4C7w9cPAe/oOoCZVQNfAb5ZxLiKJefyu3szMMvd97l7EmgAxhU3xIJZANwD4O6vAmPCHRAzmwY0uvvmsDJ8IBw+arpdB6E57r4lfL2T6Hz26XpaBxAkpsj0EHWRaz8YBLwTuDdsv87dN5Uq0ALKtQ20hv+Gm1klUAM0liTKPijHpDyJ4GCDuyeAdjMb3GWYLwE/B5qKHFsx9Lj87r4PwMxmAscDzxQ5xkLpWPbQ9vC9bG31wNFFiquYcq0D3L0JwMyOBt4D/K6o0RVHznVgZkuBx4ENRY2qeHIt/wRgL/CvZva4mX3bzDJuu4mAbteBux8Cvg7UEmwDz7j7umIH2FcD+pyymV1L0DWR7uwuf8cIzimkxjkJOMPdv2Zm5xU2wsLqy/KnjXsSwXmlq9y9rTARFl3Xg0v6sudqi5Iel9PMJgL3Ade5e0OxAiuibteBmY0FrgHOByYXOa5i6Wk/mAL8X+CrBD1G7w3/j5Jc28BI4J+AkwkKs0fN7K3u/nJxQ+ybAZ2U3f0m4Kb098zsZoJvRC+HFz3FuiSd9wHHmdkzwEhggpld7+7fK1LY/aaPy4+ZTSHo2vmIu68sUrjFUEdaRQQcQ1ARZ2ubDGwrUlzFlGsdpA5IDwJfcfffFzm2Ysm1Dt5NUC3+CagGppvZj9z974obYkHlWv5dwCZ3Xw9gZo8AM4heUs61Dk4Fat19F4CZ/QmYA5RFUi7H7uvfA1eErxcDf0xvdPf/7e5vcfdzgE8DD5RjQs4h5/KH/gv4lLu/WLSoiuP3wOUAZnY6sDXVVe/uG4CRZnZ8eB5pUTh81HS7DkI/AH7k7g+WIrgiybUd3Onup4X7/6UEVx9HKSFD7uWPA7VhTxkEychLEmVh5doPNgCnmtnQsOv+DOC1kkTZB2X3i15mVkFQPZ4EtABL3X2zmX0ReNzdn04b9rywfWkpYi2Enpaf4MKulcBzaaP90N3vLXqwBWBm3yG4qrYduA44Hdjr7neb2XyCK88Bfuvu3y9RmAXV3ToguPBvN/B02uC3uPsNRQ+ywHJtB2nDHA/cHNFbonLtBycCvwCGAKsJvqBH8ba4XOvgEwSnMeLAU+5+feki7Z2yS8oiIiJRVY7d1yIiIpGkpCwiIjJAKCmLiIgMEErKIiIiA4SSsoiIyAAxoH88RER6z8ySwHqC20Eg2M8fBz7r7gfCn6H8KbC5y6h1BA/0SP0saw3BDzSknkL2sLt/poChi7zpKSmLRNN5qQdThA9o+Q3BTw+mHtLwtLuf3824p4TjnQfc5O6nFDhWEQmp+1ok4ty9BVgOzC51LCKSm5KySMSZ2RiC53A/VepYRCQ3dV+LRNNjZhYHBgNjgR9y+CdIAeaa2dou49zg7j8sVoAikklJWSSaznP3LWY2HlgH3BY+rCAl1zllESkRdV+LRFj4+LofA1F6UppIZCkpi0TfD4B5ZnZuqQMRkdzUfS0Sce6+L3zM3ffN7Kzw7WznlAEWuHtdEcMTkTR6dKOIiMgAoe5rERGRAUJJWUREZIBQUhYRERkglJRFREQGCCVlERGRAUJJWUREZIBQUhYRERkglJRFREQGCCVlERGRAeL/A/6qa1LxrzVsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ce3c95588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "print('Chosen best feature = ' + str(best_feature))\n",
    "print(\"\")\n",
    "\n",
    "# Plot scatter and log.Reg\n",
    "if _SELECTION_ == 'RF':\n",
    "    \n",
    "    # Transfer best_feature column an prediction for response vector in a newly made dataframe \"res\"\n",
    "    res = pd.DataFrame()\n",
    "    res['best_feature'] = X_train_s[best_feature]\n",
    "    res['pred'] = logReg.predict()\n",
    "\n",
    "    # Sort results by values of the best_feature column\n",
    "    res = res.sort_values('best_feature')\n",
    "    plt.figure(figsize =(8,5))\n",
    "    plt.scatter(X_train_s[best_feature], y_train_s, marker ='.')\n",
    "    plt.plot(res.best_feature, res.pred, c = 'k')\n",
    "    plt.axhline(y=0, color = \"gray\", linestyle = \"dashed\")\n",
    "    plt.axhline(y=1, color = \"gray\", linestyle = \"dashed\")\n",
    "    plt.ylabel(\"Probability of UP (=1)\", fontsize =12)\n",
    "    plt.xlabel(str(best_feature), fontsize =12)\n",
    "    plt.title(str(best_feature) + ' vs. probability of returns going UP in the next period');\n",
    "    \n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('ERROR: PCA best feature not defined! Thus no Simple Regression possible.')\n",
    "    \n",
    "else: raise ValueError('_VERSION_ value must be either 1 or 2, _SELECTION_ must be either RF or PCA')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Multiple Logistic Regression with n pre-selected features (MLR1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Preparation and fitting (on Training Set) (MLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d4864b8ac9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'value' is not defined"
     ]
    }
   ],
   "source": [
    "def show_falses():\n",
    "    for key, value in y_train_s():\n",
    "        if y_train_s.loc[i] != 1 and y_train_s.loc[i] != 0: \n",
    "            return(y_train_s, key)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-edd5916b73c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Multiple Log. Regression (with all n best features chosen in Chapter 2 in the feature selection process)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogReg_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m         bnryfit = super(Logit, self).fit(start_params=start_params,\n\u001b[1;32m   1376\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m         mlefit = super(DiscreteModel, self).fit(start_params=start_params,\n\u001b[1;32m    203\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m \u001b[0;31m# up to subclasses to wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mHinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hessian'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "## Multiple Log. Regression (with all n best features chosen in Chapter 2 in the feature selection process)\n",
    "logReg_m = sm.Logit(endog = y_train_s, exog = sm.add_constant(X_train_s)).fit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Summary (MLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "print(\"Multiple Logistic Regression with all selected features\")\n",
    "print(\"\")\n",
    "\n",
    "# Workaround solution for error (\"AttributeError: module 'scipy.stats' has no attribute 'chisqprob'\")\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "\n",
    "# Run Multiple Logistic Regression\n",
    "print(logReg_m.summary().tables[0])\n",
    "print(logReg_m.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Assessing Output (MLR1)\n",
    "\n",
    "### Hypothesis testing / Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_level = 0.01\n",
    "\n",
    "# Print Confidence Interval with Title\n",
    "print(\"\")\n",
    "print(str(int(100 - significance_level*100)) + '% Confidence Interval (Significance Level ' \n",
    "      + str(int(significance_level*100)) + '%)')\n",
    "display(logReg_m.conf_int(alpha=significance_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_m.pred_table(threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. Prediction (MLR1)\n",
    "Multiple Logistic Regression 1 (pre-selected features with RandomForest in Chapter 2) \n",
    "\n",
    "### A: In-sample Prediction of probability for returns going UP in the next period (predict y_train)\n",
    "\n",
    "#### For whole Training Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "\n",
    "# Get the probability of 'UP' (=1) for the whole training set\n",
    "pred_train_all = logReg_m.predict(sm.add_constant(X_train_s))\n",
    "\n",
    "# Print Prediction and Response Vector, with Title\n",
    "print(\"\")\n",
    "print('Predicted probabilities of price going UP for whole Feature Set (Train) are: ')\n",
    "display(pred_train_all[0:3])\n",
    "print(\"\")\n",
    "print('Response Vector (Train): ')\n",
    "display(y_train_s[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: New-sample Prediction of probability for returns going UP in the next period (predict y_test)\n",
    "\n",
    "#### For whole Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print('Features Selected with ' + str(sel_feat))\n",
    "print('Version ' + str(_VERSION_) + '; ' + str(sel_version))\n",
    "print(\"\")\n",
    "\n",
    "# Get the probability of 'UP' (=1) for the whole test set\n",
    "pred_test_all = logReg_m.predict(sm.add_constant(X_test_s))\n",
    "\n",
    "# Print Prediction and Response Vector, with Title\n",
    "print(\"\")\n",
    "print('Predicted probability of price going UP for whole Feature Set (Test) is: ')\n",
    "display(pred_test_all.head(3))\n",
    "print(\"\")\n",
    "print('Response Vector (Test): ')\n",
    "display(y_test_s.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg with only one feature as exogen variable & LogReg 1 \n",
    "# (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non significant values (p-value > 0.05) and the Log-Likelihood value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Multiple Logistic Regression with only significant features (MLR2)\n",
    "\n",
    "Apply an other multiple logistic regression on a transformed dataset with only all significant values from LogReg_m (above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Extract significant features (MLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting significant features with an alpha-boundery of 0.05\n",
    "\n",
    "if _SELECTION_ == 'RF':\n",
    "    sign_features = (X_train_s.columns.values[np.where(logReg_m.pvalues < 0.05)])\n",
    "    print(\"\")\n",
    "    print('Features that were significant in the previous MLR in chapter 3.3.:')\n",
    "    print(\"\")\n",
    "    print(list(sign_features))\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('PCA: gives \"IndexError: index 10 is out of bounds for axis 1 with size 10\"')\n",
    "else: raise ValueError('_SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. Preparation and fitting (on Training Set) (MLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Log. Regression (with significant features from logreg above)\n",
    "# Assign features to X and response vector y\n",
    "if _SELECTION_ == 'RF':\n",
    "    logReg_mm = sm.Logit(endog = y_train_s, exog=sm.add_constant(X_train_s[sign_features])).fit()\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('PCA: could not define sign_features above')\n",
    "else: raise ValueError('_SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3. Summary (MLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _SELECTION_ == 'RF':\n",
    "    print(\"\")\n",
    "    print(\"Multiple Logistic Regression with selected significant features\")\n",
    "    print(\"\")\n",
    "    print(logReg_mm.summary().tables[0])\n",
    "    print(logReg_mm.summary().tables[1])\n",
    "elif _SELECTION_ == 'PCA':\n",
    "    print('PCA: could not define sign_features above')\n",
    "else: raise ValueError('_SELECTION_ must be either RF or PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg 1 & 2 (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the logistic regression support our choice in feature selection (with random forest)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE DIRECTLY COPIED FROM STEFANIE FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Multiple Logistic Regression with all selected features (for dataset number 2, because error message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Log. Regression (tried with all 15 features from feature selection, but it gives an error because it seems that\n",
    "# there are dependent columns)\n",
    "# Assign features to X and response vector y\n",
    "#X = sm.add_constant(X2_train_s)\n",
    "#y = y2_train\n",
    "\n",
    "# check for all independent columns\n",
    "import sympy \n",
    "reduced_form, inds = sympy.Matrix(X2_train_s.values).rref()\n",
    "reduced_form\n",
    "\n",
    "# independent columns\n",
    "inds\n",
    "\n",
    "# Assign features to X and response vector y-> because of inds only until column 14\n",
    "X = sm.add_constant(X2_train_s.iloc[:, 0:14])\n",
    "y = y2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg A\n",
    "print(\"Multiple Logistic Regression with all selected features\")\n",
    "print(78*\"_\")\n",
    "print(\"\")\n",
    "# Run Log.Reg\n",
    "logRegA = sm.Logit(endog = y, exog= X).fit()\n",
    "print(logRegA.summary().tables[0])\n",
    "print(logRegA.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg with only one feature as exogen variable & LogReg A \n",
    "# (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))\n",
    "\n",
    "# Check for non significant values (p-value > 0.05) and the Log-Likelihood value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Multiple Logistic Regression with only significant features (for dataset number 2, because error message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting significant features with an alpha-boundery of 0.05\n",
    "sign_features = (colNms_X2_train[np.where(logReg.pvalues < 0.05)])\n",
    "print(sign_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Log. Regression (with significant features from logreg above)\n",
    "# Assign features to X and response vector y\n",
    "X = sm.add_constant(X2_train_s[sign_features])\n",
    "y = y2_train\n",
    "logReg = sm.Logit(endog = y, exog=X).fit()\n",
    "\n",
    "# LogReg B\n",
    "print(\"Multiple Logistic Regression with selected significant features\")\n",
    "print(78*\"_\")\n",
    "print(\"\")\n",
    "print(logReg.summary().tables[0])\n",
    "print(logReg.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg A & B (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))\n",
    "# Does the logistic regression support our choice in feature selection (with random forest)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Version 1 with best LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = LogisticRegression()\n",
    "modelA.fit(X1_train_s, y1_train)\n",
    "\n",
    "expected = y1_test\n",
    "predicted = modelA.predict(X1_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loglikelihood for \"regression\" of predicted on expected\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Version 2 with best LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB = LogisticRegression()\n",
    "modelB.fit(X2_train_s, y2_train)\n",
    "\n",
    "expected = y2_test\n",
    "predicted = modelB.predict(X2_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loglikelihood for \"regression\" of predicted on expected\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(expected, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
