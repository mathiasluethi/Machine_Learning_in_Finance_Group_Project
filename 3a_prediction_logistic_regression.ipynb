{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, UZH 2018, Group Project\n",
    "### Group 2: Barbara Capl, Mathias LÃ¼thi, Pamela Matias, Stefanie Rentsch\n",
    "##       \n",
    "# 3. Prediction with Multiple Logistic Regression\n",
    "\n",
    "In this section we use the feature matrices and response vectors with features selected in chapter 2.  \n",
    "\n",
    "#### We use two different versions (created in chapter 1, features-selected in chapter 2):\n",
    "Version 1: Feature Matrix consists only of the Ratios                                                                        \n",
    "Version 2: Feature Matrix consists of Ratios + dummy variables for seasonality + other market data\n",
    "####  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide unnecessary warnings (\"depreciation\" of packages etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Choose which Feature Matrix (Version 1 or 2) you want to load in by choosing the Case\n",
    "### Available are: Case 1 and Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If case = 1, Feature Matrix Version 1 is used (see description above below title)\n",
    "# If case = 2, feature matrix Version 2 is used (see description above below title)\n",
    "\n",
    "_CASE_ = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Import the Response Vector and the Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Data (already splitted to train/test-data and selected features-> bc_randomforest_feature_selection)\n",
    "if _CASE_ == 1:\n",
    "    X_train_s = pd.read_csv('Data/generated_splits/X1_train_s.csv', sep=',', header=0)\n",
    "    X_test_s = pd.read_csv('Data/generated_splits/X1_test_s.csv', sep=',', header=0)\n",
    "    y_train_s = pd.read_csv('Data/generated_splits/y1_train_s.csv', sep=',', header=0)\n",
    "    y_test_s = pd.read_csv('Data/generated_splits/y1_test_s.csv', sep=',', header=0)\n",
    "elif _CASE_ == 2:\n",
    "    X_train_s = pd.read_csv('Data/generated_splits/X2_train_s.csv', sep=',', header=0)\n",
    "    X_test_s = pd.read_csv('Data/generated_splits/X2_test_s.csv', sep=',', header=0)\n",
    "    y_train_s = pd.read_csv('Data/generated_splits/y2_train_s.csv', sep=',', header=0)\n",
    "    y_test_s = pd.read_csv('Data/generated_splits/y2_test_s.csv', sep=',', header=0)\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Print out Shape and Form of Feature Matrix and Response Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Train), Case 1  = (2836, 15)\n",
      "\n",
      "\n",
      "Feature Matrix X (Train) with selected Features, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>pcf</th>\n",
       "      <th>divyield</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>evm</th>\n",
       "      <th>bm</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>ptb</th>\n",
       "      <th>aftret_equity</th>\n",
       "      <th>accrual</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>fcf_ocf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.773</td>\n",
       "      <td>9.957</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>18.484</td>\n",
       "      <td>10.644</td>\n",
       "      <td>0.547</td>\n",
       "      <td>15.633</td>\n",
       "      <td>5.963</td>\n",
       "      <td>15.468</td>\n",
       "      <td>1.811</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.048</td>\n",
       "      <td>18.484</td>\n",
       "      <td>13.678</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.089</td>\n",
       "      <td>8.509</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>39.232</td>\n",
       "      <td>9.246</td>\n",
       "      <td>0.461</td>\n",
       "      <td>17.296</td>\n",
       "      <td>5.702</td>\n",
       "      <td>17.203</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.047</td>\n",
       "      <td>39.232</td>\n",
       "      <td>1.521</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.337</td>\n",
       "      <td>1.993</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>13.062</td>\n",
       "      <td>12.474</td>\n",
       "      <td>0.911</td>\n",
       "      <td>9.209</td>\n",
       "      <td>2.248</td>\n",
       "      <td>9.135</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.038</td>\n",
       "      <td>13.062</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CAPEI    pcf  divyield  pe_inc     evm     bm  pe_op_dil  PEG_ltgforward  \\\n",
       "0  20.773  9.957    0.0354  18.484  10.644  0.547     15.633           5.963   \n",
       "1  25.089  8.509    0.0398  39.232   9.246  0.461     17.296           5.702   \n",
       "2  12.337  1.993    0.0268  13.062  12.474  0.911      9.209           2.248   \n",
       "\n",
       "   pe_op_basic    ptb  aftret_equity  accrual  pe_exi  PEG_1yrforward  fcf_ocf  \n",
       "0       15.468  1.811          0.134    0.048  18.484          13.678    0.932  \n",
       "1       17.203  2.189          0.058    0.047  39.232           1.521    0.441  \n",
       "2        9.135  1.076          0.086    0.038  13.062           0.380    1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Train) after Feature Selection, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Shape (rows, columns) of Feature Matrix X (Train), Case ' + str(_CASE_), ' = ' + str(X_train_s.shape))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print('Feature Matrix X (Train) with selected Features, Case ' + str(_CASE_))\n",
    "display(X_train_s.head(3))\n",
    "print(\"\")\n",
    "print('Response Vector y (Train) after Feature Selection, Case ' + str(_CASE_))\n",
    "display(y_train_s.head(3))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape (rows, columns) of Feature Matrix X (Test), Case 1  = (710, 15)\n",
      "\n",
      "Feature Matrix X (Test) with selected Features, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>pcf</th>\n",
       "      <th>divyield</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>evm</th>\n",
       "      <th>bm</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>ptb</th>\n",
       "      <th>aftret_equity</th>\n",
       "      <th>accrual</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>fcf_ocf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.983</td>\n",
       "      <td>10.484</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>16.224</td>\n",
       "      <td>8.585</td>\n",
       "      <td>0.254</td>\n",
       "      <td>16.224</td>\n",
       "      <td>1.330</td>\n",
       "      <td>16.127</td>\n",
       "      <td>4.189</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.084</td>\n",
       "      <td>16.224</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.663</td>\n",
       "      <td>7.709</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>18.555</td>\n",
       "      <td>13.619</td>\n",
       "      <td>0.235</td>\n",
       "      <td>16.489</td>\n",
       "      <td>1.572</td>\n",
       "      <td>16.311</td>\n",
       "      <td>4.281</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.039</td>\n",
       "      <td>18.555</td>\n",
       "      <td>1.737</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.327</td>\n",
       "      <td>8.490</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>15.550</td>\n",
       "      <td>6.716</td>\n",
       "      <td>0.513</td>\n",
       "      <td>9.520</td>\n",
       "      <td>6.149</td>\n",
       "      <td>9.520</td>\n",
       "      <td>2.198</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.077</td>\n",
       "      <td>15.681</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CAPEI     pcf  divyield  pe_inc     evm     bm  pe_op_dil  PEG_ltgforward  \\\n",
       "0  20.983  10.484    0.0187  16.224   8.585  0.254     16.224           1.330   \n",
       "1  21.663   7.709    0.0122  18.555  13.619  0.235     16.489           1.572   \n",
       "2  16.327   8.490    0.0343  15.550   6.716  0.513      9.520           6.149   \n",
       "\n",
       "   pe_op_basic    ptb  aftret_equity  accrual  pe_exi  PEG_1yrforward  fcf_ocf  \n",
       "0       16.127  4.189          0.310    0.084  16.224           1.414    0.863  \n",
       "1       16.311  4.281          0.238    0.039  18.555           1.737    0.902  \n",
       "2        9.520  2.198          0.130    0.077  15.681          -0.973    0.934  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Vector y (Test) after Feature Selection, Case 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('Shape (rows, columns) of Feature Matrix X (Test), Case ' + str(_CASE_), ' = ' + str(X_test_s.shape))\n",
    "print(\"\")\n",
    "print('Feature Matrix X (Test) with selected Features, Case ' + str(_CASE_))\n",
    "display(X_test_s.head(3))\n",
    "print(\"\")\n",
    "print('Response Vector y (Test) after Feature Selection, Case ' + str(_CASE_))\n",
    "display(y_test_s.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Simple Logistic Regression (statsmodels) (SLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Preparation and fitting (on Training Set) (SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.685746\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression (with the most important feature from feature selection)\n",
    "# Assign \"best_feature\" to matrix X and response to y\n",
    "if _CASE_ == 1:\n",
    "    best_feature = 'CAPEI'\n",
    "elif _CASE_ == 2:\n",
    "    best_feature = 'RET'\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n",
    "\n",
    "logReg = sm.Logit(endog = y_train_s, exog= sm.add_constant(X_train_s[[best_feature]])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround solution for error (\"AttributeError: module 'scipy.stats' has no attribute 'chisqprob'\")\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Summary (SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      0   No. Observations:                 2836\n",
      "Model:                          Logit   Df Residuals:                     2834\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 09 Apr 2018   Pseudo R-squ.:               0.0005333\n",
      "Time:                        16:26:53   Log-Likelihood:                -1944.8\n",
      "converged:                       True   LL-Null:                       -1945.8\n",
      "                                        LLR p-value:                    0.1497\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1839      0.055      3.349      0.001       0.076       0.291\n",
      "CAPEI          0.0027      0.002      1.363      0.173      -0.001       0.007\n",
      "==============================================================================\n",
      "\n",
      "logReg pvalues: \n",
      "\n",
      "const    0.000812\n",
      "CAPEI    0.172888\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# LogReg with only one feature as exogen variable\n",
    "print(logReg.summary())\n",
    "print(\"\")\n",
    "print('logReg pvalues: ')\n",
    "print(\"\")\n",
    "print(logReg.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Assessing Output (SLM)\n",
    "\n",
    "### Hypothesis testing / Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "99% Confidence Interval (Significance Level 1%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.042441</td>\n",
       "      <td>0.325312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAPEI</th>\n",
       "      <td>-0.002391</td>\n",
       "      <td>0.007766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "const  0.042441  0.325312\n",
       "CAPEI -0.002391  0.007766"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_level = 0.01\n",
    "\n",
    "print(\"\")\n",
    "print(str(int(100 - significance_level*100)) + '% Confidence Interval (Significance Level ' + str(int(significance_level*100)) + '%)')\n",
    "logReg.conf_int(alpha=significance_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0., 1250.],\n",
       "       [   2., 1584.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.pred_table(threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Prediction (SML)\n",
    "\n",
    "### A: In-sample Prediction of probability for returns going UP in the next period (predict y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For whole Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: Case 1\n",
      "\n",
      "Predicted probability of price going UP for whole Feature Train Set is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.559639\n",
       "1    0.562496\n",
       "2    0.554045\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if _CASE_ == 1:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "elif _CASE_ == 2:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n",
    "\n",
    "# X must include 1 in first column for intercept\n",
    "# we wish to get the probability of 'UP' (=1) for the whole test set\n",
    "print(\"\")\n",
    "print('Predicted probability of price going UP for whole Feature Train Set is: ')\n",
    "pred_train_all = logReg.predict(sm.add_constant(X_train_s[[best_feature]]))\n",
    "display(pred_train_all.head(3))\n",
    "display(y_train_s.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: New-sample Prediction of probability for returns going UP in the next period (predict y_test)\n",
    "\n",
    "#### For chosen value of predictive variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: Case 1\n",
      "Chosen best feature = CAPEI\n",
      "Chosen value of best feature = 15\n",
      "\n",
      "Predicted probability of price going UP with chosen CAPEI value is: 55.5813%\n",
      "Ratio of \"UP\" (Train)  =  55.9238%\n"
     ]
    }
   ],
   "source": [
    "if _CASE_ == 1:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "    print('Chosen best feature = ' + str(best_feature))\n",
    "    best_feature_value = 15\n",
    "    print('Chosen value of best feature = ' + str(best_feature_value))\n",
    "elif _CASE_ == 2:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "    print('Chosen best feature = ' + str(best_feature))\n",
    "    best_feature_value = 0.02\n",
    "    print('Chosen value of best feature = ' + str(best_feature_value))\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n",
    "\n",
    "# X must include 1 in first column for intercept\n",
    "# we wish to get the probability of 'UP' (=1) for a best_feature_value of USD 15\n",
    "pred_test_one = logReg.predict([1, best_feature_value])\n",
    "ratio_response_train = y_train_s.sum() / y_train_s.size\n",
    "\n",
    "print(\"\")\n",
    "print('Predicted probability of price going UP with chosen ' + str(best_feature) + ' value is: ' \n",
    "      + str(\"%.4f\" % round(float(pred_test_one*100),4)) + '%')\n",
    "print('Ratio of \"UP\" (Train)  =  ' + str(\"%.4f\" % round(float(ratio_response_train*100),4)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For whole Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: Case 1\n",
      "\n",
      "Predicted probability of price going UP for whole Feature Test Set is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.559778\n",
       "1    0.560229\n",
       "2    0.556693\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if _CASE_ == 1:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "elif _CASE_ == 2:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n",
    "\n",
    "# we wish to get the probability of 'UP' (=1) for the whole test set\n",
    "pred_test_all = logReg.predict(sm.add_constant(X_test_s[[best_feature]]))\n",
    "\n",
    "print(\"\")\n",
    "print('Predicted probability of price going UP for whole Feature Test Set is: ')\n",
    "display(pred_test_all.head(3))\n",
    "display(y_test_s.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Plot Results (SLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen best feature for CASE 1 is: CAPEI\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83716b43c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Chosen best feature for CASE ' + str(_CASE_) + ' is: ' + str(best_feature))\n",
    "print(\"\")\n",
    "  \n",
    "# Transfer best_feature column an prediction for response vector in a newly made dataframe \"res\"\n",
    "res = pd.DataFrame()\n",
    "res['best_feature'] = X_train_s[best_feature]\n",
    "res['pred'] = logReg.predict()\n",
    "\n",
    "# Sort results by values of the best_feature column\n",
    "res = res.sort_values('best_feature')\n",
    "\n",
    "# Plot scatter and log.Reg\n",
    "plt.figure(figsize =(8,5))\n",
    "plt.scatter(X_train_s[best_feature], y_train_s, marker ='.')\n",
    "plt.plot(res.best_feature, res.pred, c = 'k')\n",
    "plt.axhline(y=0, color = \"gray\", linestyle = \"dashed\")\n",
    "plt.axhline(y=1, color = \"gray\", linestyle = \"dashed\")\n",
    "plt.ylabel(\"Probability of UP (=1)\", fontsize =12)\n",
    "plt.xlabel(str(best_feature), fontsize =12)\n",
    "plt.title(str(best_feature) + ' vs. probability of returns going UP in the next period');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Multiple Logistic Regression with n pre-selected features (MLR1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Preparation and fitting (on Training Set) (MLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669582\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "## Multiple Log. Regression (with all n best features chosen in Chapter 2 in the feature selection process)\n",
    "logReg_m = sm.Logit(endog = y_train_s, exog=sm.add_constant(X_train_s)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Summary (MLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple Logistic Regression with all selected features\n",
      "______________________________________________________________________________\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      0   No. Observations:                 2836\n",
      "Model:                          Logit   Df Residuals:                     2820\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 09 Apr 2018   Pseudo R-squ.:                 0.02409\n",
      "Time:                        16:31:44   Log-Likelihood:                -1898.9\n",
      "converged:                       True   LL-Null:                       -1945.8\n",
      "                                        LLR p-value:                 1.962e-13\n",
      "==============================================================================\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.0675      0.262     -0.258      0.797      -0.581       0.446\n",
      "CAPEI              0.0017      0.002      0.878      0.380      -0.002       0.005\n",
      "pcf                0.0091      0.004      2.112      0.035       0.001       0.018\n",
      "divyield         -19.3490      3.643     -5.312      0.000     -26.488     -12.210\n",
      "pe_inc            -0.0040      0.003     -1.151      0.250      -0.011       0.003\n",
      "evm               -0.0366      0.009     -4.027      0.000      -0.054      -0.019\n",
      "bm                 1.1044      0.236      4.684      0.000       0.642       1.566\n",
      "pe_op_dil         -0.0429      0.015     -2.792      0.005      -0.073      -0.013\n",
      "PEG_ltgforward     0.0089      0.013      0.695      0.487      -0.016       0.034\n",
      "pe_op_basic        0.0648      0.021      3.143      0.002       0.024       0.105\n",
      "ptb                0.1113      0.029      3.853      0.000       0.055       0.168\n",
      "aftret_equity     -0.5339      0.259     -2.058      0.040      -1.042      -0.025\n",
      "accrual            1.0114      1.146      0.883      0.377      -1.234       3.257\n",
      "pe_exi             0.0030      0.004      0.790      0.430      -0.004       0.010\n",
      "PEG_1yrforward     0.0097      0.006      1.518      0.129      -0.003       0.022\n",
      "fcf_ocf            0.0073      0.192      0.038      0.970      -0.370       0.384\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Multiple Logistic Regression with all selected features\")\n",
    "print(78*\"_\")  ##### <<== WAS?\n",
    "print(\"\")\n",
    "\n",
    "# Run Multiple Logistic Regression\n",
    "print(logReg_m.summary().tables[0])\n",
    "print(logReg_m.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Assessing Output (MLR1)\n",
    "\n",
    "### Hypothesis testing / Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "99% Confidence Interval (Significance Level 1%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-0.742602</td>\n",
       "      <td>0.607602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAPEI</th>\n",
       "      <td>-0.003235</td>\n",
       "      <td>0.006580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcf</th>\n",
       "      <td>-0.002001</td>\n",
       "      <td>0.020226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>divyield</th>\n",
       "      <td>-28.731549</td>\n",
       "      <td>-9.966473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe_inc</th>\n",
       "      <td>-0.012895</td>\n",
       "      <td>0.004930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evm</th>\n",
       "      <td>-0.060085</td>\n",
       "      <td>-0.013209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm</th>\n",
       "      <td>0.497128</td>\n",
       "      <td>1.711656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe_op_dil</th>\n",
       "      <td>-0.082555</td>\n",
       "      <td>-0.003318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEG_ltgforward</th>\n",
       "      <td>-0.024198</td>\n",
       "      <td>0.042092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe_op_basic</th>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.117929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptb</th>\n",
       "      <td>0.036891</td>\n",
       "      <td>0.185663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aftret_equity</th>\n",
       "      <td>-1.201977</td>\n",
       "      <td>0.134272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accrual</th>\n",
       "      <td>-1.940024</td>\n",
       "      <td>3.962762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe_exi</th>\n",
       "      <td>-0.006692</td>\n",
       "      <td>0.012609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <td>-0.006787</td>\n",
       "      <td>0.026281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fcf_ocf</th>\n",
       "      <td>-0.488421</td>\n",
       "      <td>0.502946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1\n",
       "const           -0.742602  0.607602\n",
       "CAPEI           -0.003235  0.006580\n",
       "pcf             -0.002001  0.020226\n",
       "divyield       -28.731549 -9.966473\n",
       "pe_inc          -0.012895  0.004930\n",
       "evm             -0.060085 -0.013209\n",
       "bm               0.497128  1.711656\n",
       "pe_op_dil       -0.082555 -0.003318\n",
       "PEG_ltgforward  -0.024198  0.042092\n",
       "pe_op_basic      0.011700  0.117929\n",
       "ptb              0.036891  0.185663\n",
       "aftret_equity   -1.201977  0.134272\n",
       "accrual         -1.940024  3.962762\n",
       "pe_exi          -0.006692  0.012609\n",
       "PEG_1yrforward  -0.006787  0.026281\n",
       "fcf_ocf         -0.488421  0.502946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significance_level = 0.01\n",
    "\n",
    "print(\"\")\n",
    "print(str(int(100 - significance_level*100)) + '% Confidence Interval (Significance Level ' + str(int(significance_level*100)) + '%)')\n",
    "display(logReg_m.conf_int(alpha=significance_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 349.,  901.],\n",
       "       [ 227., 1359.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg_m.pred_table(threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. Prediction (MLR1)\n",
    "Multiple Logistic Regression 1 (pre-selected features with RandomForest in Chapter 2) \n",
    "\n",
    "### A: In-sample Prediction of probability for returns going UP in the next period (predict y_train)\n",
    "\n",
    "#### For whole Training Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: Case 1\n",
      "\n",
      "Predicted probability of price going UP for whole Feature Train Set is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.567440\n",
       "1    0.528367\n",
       "2    0.581356\n",
       "3    0.631523\n",
       "4    0.600770\n",
       "5    0.491411\n",
       "6    0.561593\n",
       "7    0.653504\n",
       "8    0.243099\n",
       "9    0.530230\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1\n",
       "3  1\n",
       "4  1\n",
       "5  0\n",
       "6  0\n",
       "7  1\n",
       "8  0\n",
       "9  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if _CASE_ == 1:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "elif _CASE_ == 2:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n",
    "\n",
    "# we wish to get the probability of 'UP' (=1) for the whole training set\n",
    "pred_train_all = logReg_m.predict(sm.add_constant(X_train_s))\n",
    "\n",
    "print(\"\")\n",
    "print('Predicted probability of price going UP for whole Feature Train Set is: ')\n",
    "display(pred_train_all.head(10))\n",
    "display(y_train_s.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: New-sample Prediction of probability for returns going UP in the next period (predict y_test)\n",
    "\n",
    "#### For whole Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: Case 1\n",
      "\n",
      "Predicted probability of price going UP for whole Feature Test Set is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.602718\n",
       "1    0.579294\n",
       "2    0.547866\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if _CASE_ == 1:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "elif _CASE_ == 2:\n",
    "    print('Active: Case ' + str(_CASE_))\n",
    "else: raise ValueError('_CASE_ value must be either 1 or 2')\n",
    "\n",
    "# we wish to get the probability of 'UP' (=1) for the whole test set\n",
    "pred_test_all = logReg_m.predict(sm.add_constant(X_test_s))\n",
    "\n",
    "print(\"\")\n",
    "print('Predicted probability of price going UP for whole Feature Test Set is: ')\n",
    "display(pred_test_all.head(3))\n",
    "display(y_test_s.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg with only one feature as exogen variable & LogReg 1 \n",
    "# (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non significant values (p-value > 0.05) and the Log-Likelihood value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Multiple Logistic Regression with only significant features (MLR2)\n",
    "\n",
    "Apply an other multiple logistic regression on a transformed dataset with only all significant values from LogReg_m (above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Extract significant features (MLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features that were significant in the previous MLR in chapter 3.3.:\n",
      "\n",
      "['divyield', 'pe_inc', 'bm', 'pe_op_dil', 'PEG_ltgforward', 'ptb', 'aftret_equity', 'accrual']\n"
     ]
    }
   ],
   "source": [
    "# extracting significant features with an alpha-boundery of 0.05\n",
    "sign_features = (X_train_s.columns.values[np.where(logReg_m.pvalues < 0.05)])\n",
    "\n",
    "print(\"\")\n",
    "print('Features that were significant in the previous MLR in chapter 3.3.:')\n",
    "print(\"\")\n",
    "print(list(sign_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. Preparation and fitting (on Training Set) (MLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.675177\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "## Multiple Log. Regression (with significant features from logreg above)\n",
    "# Assign features to X and response vector y\n",
    "logReg_mm = sm.Logit(endog = y_train_s, exog=sm.add_constant(X_train_s[sign_features])).fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3. Summary (MLR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple Logistic Regression with selected significant features\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      0   No. Observations:                 2836\n",
      "Model:                          Logit   Df Residuals:                     2827\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 09 Apr 2018   Pseudo R-squ.:                 0.01594\n",
      "Time:                        16:58:47   Log-Likelihood:                -1914.8\n",
      "converged:                       True   LL-Null:                       -1945.8\n",
      "                                        LLR p-value:                 1.865e-10\n",
      "==============================================================================\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.0934      0.194     -0.481      0.631      -0.474       0.287\n",
      "divyield         -17.5726      3.449     -5.095      0.000     -24.333     -10.812\n",
      "pe_inc          2.847e-05      0.002      0.016      0.987      -0.003       0.004\n",
      "bm                 0.8337      0.226      3.683      0.000       0.390       1.277\n",
      "pe_op_dil          0.0082      0.005      1.761      0.078      -0.001       0.017\n",
      "PEG_ltgforward     0.0090      0.012      0.768      0.442      -0.014       0.032\n",
      "ptb                0.1039      0.028      3.735      0.000       0.049       0.158\n",
      "aftret_equity     -0.5273      0.254     -2.075      0.038      -1.025      -0.029\n",
      "accrual            1.7552      1.076      1.632      0.103      -0.353       3.863\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Multiple Logistic Regression with selected significant features\")\n",
    "print(\"\")\n",
    "print(logReg_mm.summary().tables[0])\n",
    "print(logReg_mm.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg 1 & 2 (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the logistic regression support our choice in feature selection (with random forest)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE DIRECTLY COPIED FROM STEFANIE FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Multiple Logistic Regression with all selected features (for dataset number 2, because error message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Log. Regression (tried with all 15 features from feature selection, but it gives an error because it seems that\n",
    "# there are dependent columns)\n",
    "# Assign features to X and response vector y\n",
    "#X = sm.add_constant(X2_train_s)\n",
    "#y = y2_train\n",
    "\n",
    "# check for all independent columns\n",
    "import sympy \n",
    "reduced_form, inds = sympy.Matrix(X2_train_s.values).rref()\n",
    "reduced_form\n",
    "\n",
    "# independent columns\n",
    "inds\n",
    "\n",
    "# Assign features to X and response vector y-> because of inds only until column 14\n",
    "X = sm.add_constant(X2_train_s.iloc[:, 0:14])\n",
    "y = y2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg A\n",
    "print(\"Multiple Logistic Regression with all selected features\")\n",
    "print(78*\"_\")\n",
    "print(\"\")\n",
    "# Run Log.Reg\n",
    "logRegA = sm.Logit(endog = y, exog= X).fit()\n",
    "print(logRegA.summary().tables[0])\n",
    "print(logRegA.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg with only one feature as exogen variable & LogReg A \n",
    "# (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))\n",
    "\n",
    "# Check for non significant values (p-value > 0.05) and the Log-Likelihood value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Multiple Logistic Regression with only significant features (for dataset number 2, because error message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting significant features with an alpha-boundery of 0.05\n",
    "sign_features = (colNms_X2_train[np.where(logReg.pvalues < 0.05)])\n",
    "print(sign_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Log. Regression (with significant features from logreg above)\n",
    "# Assign features to X and response vector y\n",
    "X = sm.add_constant(X2_train_s[sign_features])\n",
    "y = y2_train\n",
    "logReg = sm.Logit(endog = y, exog=X).fit()\n",
    "\n",
    "# LogReg B\n",
    "print(\"Multiple Logistic Regression with selected significant features\")\n",
    "print(78*\"_\")\n",
    "print(\"\")\n",
    "print(logReg.summary().tables[0])\n",
    "print(logReg.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LogReg A & B (explicitly Log-Likelihood values-> is there an improvement? (smaller values are prefered!))\n",
    "# Does the logistic regression support our choice in feature selection (with random forest)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Version 1 with best LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = LogisticRegression()\n",
    "modelA.fit(X1_train_s, y1_train)\n",
    "\n",
    "expected = y1_test\n",
    "predicted = modelA.predict(X1_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loglikelihood for \"regression\" of predicted on expected\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Version 2 with best LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB = LogisticRegression()\n",
    "modelB.fit(X2_train_s, y2_train)\n",
    "\n",
    "expected = y2_test\n",
    "predicted = modelB.predict(X2_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loglikelihood for \"regression\" of predicted on expected\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(expected, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
